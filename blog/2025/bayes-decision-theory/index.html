<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bayesian Decision Theory - Concepts and Recap | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?e68e4955e21b20101db6e28a5a50abec"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/bayes-decision-theory/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Bayesian Decision Theory - Concepts and Recap</h1> <p class="post-meta"> Created in January 28, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Bayesian decision theory is a powerful framework for making decisions under uncertainty. It provides a principled way to combine prior knowledge with observed data to make optimal choices. In this post, we’ll take a closer look at its key components, revisit Bayesian point estimation, and connect these ideas to classical probability modeling. Let’s dive in!</p> <hr> <h4 id="ingredients-of-bayesian-decision-theory"><strong>Ingredients of Bayesian Decision Theory</strong></h4> <p>At the heart of Bayesian decision theory lie several key components. First, we have the <strong>parameter space</strong>, denoted as \(\Theta\), which represents all possible values of the unknown parameter we aim to estimate or make decisions about. Next, we have the <strong>prior distribution</strong>, \(p(\theta)\), which encodes our beliefs about \(\theta\) before observing any data. This prior serves as a starting point in the Bayesian framework.</p> <p>Equally important is the <strong>action space</strong>, \(A\), which includes all possible actions we might take. To evaluate these actions, we rely on a <strong>loss function</strong>, \(\ell : A \times \Theta \to \mathbb{R}\), which quantifies the cost of taking a specific action \(a \in A\) when the true parameter value is \(\theta \in \Theta\).</p> <p>With these components, we can define the <strong>posterior risk</strong> of an action \(a \in A\), which represents the expected loss under the posterior distribution:</p> \[r(a) = \mathbb{E}[\ell(\theta, a) \mid D] = \int \ell(\theta, a) p(\theta \mid D) d\theta\] <p>The goal is to minimize this risk. The action that achieves this minimization is called the <strong>Bayes action</strong>, \(a^*\), which satisfies:</p> \[r(a^*) = \min_{a \in A} r(a)\] <h5 id="bayesian-point-estimation"><strong>Bayesian Point Estimation</strong></h5> <p>Bayesian point estimation builds upon this foundation. Imagine we have data \(D\) generated from some distribution \(p(y \mid \theta)\), where \(\theta \in \Theta\) is unknown. Our task is to find a single point estimate, \(\hat{\theta}\), that best represents \(\theta\).</p> <p>To do this, we first specify a prior distribution \(p(\theta)\) over \(\Theta\), which reflects our beliefs about \(\theta\) before observing the data. We then define a loss function, \(\ell(\hat{\theta}, \theta)\), to measure the cost of estimating \(\theta\) with \(\hat{\theta}\). Finally, we seek the point estimate \(\hat{\theta} \in \Theta\) that minimizes the posterior risk:</p> \[r(\hat{\theta}) = \mathbb{E}[\ell(\hat{\theta}, \theta) \mid D] = \int \ell(\hat{\theta}, \theta) p(\theta \mid D) d\theta.\] <h5 id="important-loss-functions-and-their-role"><strong>Important Loss Functions and Their Role</strong></h5> <p>The choice of loss function significantly influences the optimal estimate. Here are three commonly used loss functions and the corresponding Bayes actions:</p> <ul> <li> <p><strong>Squared Loss</strong>: \(\ell(\hat{\theta}, \theta) = (\theta - \hat{\theta})^2\).<br> For squared loss, the Bayes action is the <strong>posterior mean</strong>, \(\mathbb{E}[\theta \mid D]\).</p> </li> <li> <p><strong>Zero-One Loss</strong>: \(\ell(\hat{\theta}, \theta) = 1[\theta \neq \hat{\theta}]\).<br> For zero-one loss, the Bayes action is the <strong>posterior mode</strong>, the most probable value of \(\theta\) under the posterior.</p> </li> <li> <p><strong>Absolute Loss</strong>: \(\ell(\hat{\theta}, \theta) = |\theta - \hat{\theta}|\).<br> For absolute loss, the Bayes action is the <strong>posterior median</strong>, the value that splits the posterior distribution into two equal halves.</p> </li> </ul> <h5 id="example-card-drawing"><strong>Example: Card Drawing</strong></h5> <p>To see this in action, consider drawing a card from a deck consisting of the values \(\{2, 3, 3, 4, 4, 5, 5, 5\}\). Suppose you are asked to guess the value of the card. Based on the posterior distribution:</p> <ul> <li>The <strong>mean</strong> of the distribution is \(3.875\).</li> <li>The <strong>mode</strong> (most frequent value) is \(5\).</li> <li>The <strong>median</strong> (middle value) is \(4\).</li> </ul> <p>This simple example highlights how different loss functions lead to different optimal estimates.</p> <h5 id="bayesian-point-estimation-with-squared-loss"><strong>Bayesian Point Estimation with Squared Loss</strong></h5> <p>We seek an action \(\hat{\theta}\) that minimizes the <strong>posterior risk</strong>, given by:</p> \[r(\hat{\theta}) = \int (\theta - \hat{\theta})^2 p(\theta | \mathcal{D}) \, d\theta\] <p>To find the optimal \(\hat{\theta}\), we differentiate:</p> \[\frac{d r(\hat{\theta})}{d\hat{\theta}} = - \int 2 (\theta - \hat{\theta}) p(\theta | \mathcal{D}) \, d\theta\] <p>Rearranging,</p> \[= -2 \int \theta p(\theta | \mathcal{D}) \, d\theta + 2\hat{\theta} \int p(\theta | \mathcal{D}) \, d\theta\] <p>Since the total probability integrates to 1,</p> \[\int p(\theta | \mathcal{D}) \, d\theta = 1,\] <p>this simplifies to:</p> \[\frac{d r(\hat{\theta})}{d\hat{\theta}} = -2 \int \theta p(\theta | \mathcal{D}) \, d\theta + 2\hat{\theta}\] <p>Setting the derivative to zero,</p> \[-2 \int \theta p(\theta | \mathcal{D}) \, d\theta + 2\hat{\theta} = 0\] <p>Solving for \(\hat{\theta}\),</p> \[\hat{\theta} = \int \theta p(\theta \mid D) d\theta = \mathbb{E}[\theta \mid D]\] <p>Thus, under squared loss, the Bayes action is the <strong>posterior mean</strong>.</p> <hr> <h4 id="recap-and-interpretation"><strong>Recap and Interpretation</strong></h4> <p>Bayesian Decision Theory is built on a few core ideas that tie together probability, decision-making, and inference. Let’s revisit these concepts and unpack their meaning(again) all at once to gain the full picture.</p> <p><strong>Note:</strong> If you feel this isn’t necessary, feel free to skip it. However, I believe it’s helpful to reinforce these concepts periodically to build strong intuition and apply them effectively when needed.</p> <h5 id="the-prior-ptheta"><strong>The Prior (\(p(\theta)\))</strong></h5> <p>The prior represents our initial beliefs about the unknown parameter \(\theta\) before observing any data. It encapsulates what we know (or assume) about \(\theta\) based on prior knowledge, expert opinion, or historical data.</p> <p>For example, if \(\theta\) represents the probability of success in a coin toss, a reasonable prior might be a Beta distribution centered around 0.5, reflecting our belief that the coin is fair.</p> <h5 id="the-posterior-ptheta-mid-d"><strong>The Posterior (\(p(\theta \mid D)\))</strong></h5> <p>The posterior is the updated belief about \(\theta\) after observing the data \(D\). It combines the prior \(p(\theta)\) with the likelihood of the data \(p(D \mid \theta)\) using Bayes’ theorem:</p> \[p(\theta \mid D) = \frac{p(D \mid \theta) p(\theta)}{p(D)}\] <p>The posterior is the foundation of all Bayesian inference. It reflects how the data has rationally updated our initial beliefs.</p> <h5 id="inferences-and-actions"><strong>Inferences and Actions</strong></h5> <p>In the Bayesian framework, all inferences (e.g., estimating \(\theta\)) and actions (e.g., making decisions) are based on the posterior distribution. This is because the posterior contains all the information we have about \(\theta\), combining both prior knowledge and observed data.</p> <p>For example, if we want to estimate \(\theta\), we might compute the posterior mean, median, or mode, depending on the loss function we choose.</p> <h5 id="no-need-to-justify-an-estimator"><strong>No Need to Justify an Estimator</strong></h5> <p>In classical statistics, we often need to justify why a particular estimator (e.g., the sample mean) is a good choice. In Bayesian statistics, this issue doesn’t arise because the estimator is derived directly from the posterior distribution, which is fully determined by the prior and the data.</p> <p>The only choices we need to make are:</p> <ol> <li>The family of distributions (e.g., Gaussian, Beta) that model the data.</li> <li>The prior distribution on the parameter space \(\Theta\).</li> </ol> <p><strong>Role of the Loss Function</strong></p> <p>The loss function \(\ell(a, \theta)\) quantifies the cost of taking action \(a\) when the true parameter is \(\theta\). It bridges the gap between inference and decision-making.</p> <p>The optimal action \(a^*\) is the one that minimizes the posterior risk, which is the expected loss under the posterior distribution:</p> \[r(a) = \mathbb{E}[\ell(a, \theta) \mid D] = \int \ell(a, \theta) p(\theta \mid D) \, d\theta\] <p>Different loss functions lead to different optimal actions. For example:</p> <ul> <li> <strong>Squared loss</strong> leads to the posterior mean.</li> <li> <strong>Absolute loss</strong> leads to the posterior median.</li> <li> <strong>Zero-one loss</strong> leads to the posterior mode.</li> </ul> <h5 id="philosophical-interpretation"><strong>Philosophical Interpretation</strong></h5> <p>Bayesian Decision Theory is fundamentally about rational decision-making under uncertainty. It provides a coherent framework for updating beliefs and making decisions that minimize expected loss.</p> <p>Unlike frequentist methods, which focus on long-run properties of estimators, Bayesian methods focus on the current state of knowledge, as represented by the posterior distribution.</p> <h5 id="why-does-this-matter"><strong>Why Does This Matter?</strong></h5> <p>Understanding these concepts is crucial because they form the backbone of Bayesian thinking. Here’s why:</p> <ol> <li> <strong>Flexibility</strong>: The Bayesian approach allows us to incorporate prior knowledge into our analysis, which can be especially useful when data is limited.</li> <li> <strong>Transparency</strong>: All assumptions (e.g., the choice of prior) are explicitly stated, making the analysis transparent and interpretable.</li> <li> <strong>Decision-Oriented</strong>: By focusing on minimizing expected loss, Bayesian Decision Theory directly addresses the practical goal of making optimal decisions.</li> </ol> <h5 id="example-estimating-the-mean-of-a-normal-distribution"><strong>Example: Estimating the Mean of a Normal Distribution</strong></h5> <p>Suppose we want to estimate the mean \(\theta\) of a normal distribution based on observed data \(D\). Here’s how the Bayesian approach works:</p> <ol> <li> <strong>Prior</strong>: We choose a normal prior \(p(\theta) = N(\mu_0, \sigma_0^2)\), where \(\mu_0\) and \(\sigma_0^2\) reflect our initial beliefs about \(\theta\).</li> <li> <strong>Likelihood</strong>: The data \(D\) is modeled as \(p(D \mid \theta) = N(\theta, \sigma^2)\).</li> <li> <strong>Posterior</strong>: Using Bayes’ theorem, the posterior \(p(\theta \mid D)\) is also a normal distribution, with updated mean and variance that balance the prior and the data.</li> <li> <strong>Decision</strong>: If we use squared loss, the optimal estimate \(\hat{\theta}\) is the posterior mean.</li> </ol> <p>This example illustrates how the Bayesian approach seamlessly integrates prior knowledge with observed data to produce a rational and optimal estimate.</p> <h5 id="example-estimating-the-mean-of-a-normal-distribution-frequentist-approach"><strong>Example: Estimating the Mean of a Normal Distribution (Frequentist Approach)</strong></h5> <ol> <li> <p><strong>Model Assumption</strong>:<br> Assume the data \(D\) comes from a normal distribution: \(p(D \mid \theta) = N(\theta, \sigma^2),\)<br> where \(\theta\) is the unknown mean and \(\sigma^2\) is the known variance.</p> </li> <li> <p><strong>Estimator</strong>:<br> Use the sample mean: \(\bar{D} = \frac{1}{n} \sum_{i=1}^n D_i\)<br> as the estimator for \(\theta\). This is derived as the <strong>maximum likelihood estimator (MLE)</strong> because it maximizes the likelihood function:</p> \[L(\theta) = \prod_{i=1}^n p(D_i \mid \theta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(D_i - \theta)^2}{2\sigma^2}\right).\] </li> <li> <strong>Properties of the Estimator</strong>: <ul> <li>The sample mean \(\bar{D}\) is an <strong>unbiased estimator</strong> of \(\theta\), meaning: \(E[\bar{D}] = \theta.\)</li> <li>Its variance is: \(\text{Var}(\bar{D}) = \frac{\sigma^2}{n},\)<br> which decreases as the sample size \(n\) increases.</li> </ul> </li> <li> <strong>Decision</strong>:<br> The sample mean \(\bar{D}\) is reported as the estimate of \(\theta\). There is no explicit loss function in the frequentist framework; instead, the sample mean is justified by its desirable properties (e.g., unbiasedness, efficiency, and consistency).</li> </ol> <p><strong>Note:</strong> If you’re unsure about this derivation from MLE, check out this <a href="https://monishver11.github.io/blog/2025/NB-continuous-features/">link</a> for clarification.</p> <p><strong><mark>Key Takeaways</mark></strong></p> <ol> <li>The prior represents initial beliefs, the posterior represents updated beliefs, and the loss function guides decision-making.</li> <li>Bayesian methods are inherently decision-oriented, focusing on minimizing expected loss.</li> <li>The only choices we need to make are the family of distributions and the prior—everything else follows logically from these choices.</li> </ol> <hr> <p>A few follow-up questions you might have:</p> <h5 id="explanation-of-actionsdecision-making"><strong>Explanation of “Actions/Decision-Making”</strong></h5> <p>In the Bayesian framework, <strong>actions</strong> or <strong>decision-making</strong> refer to the choices or decisions we make based on the information encoded in the posterior distribution. These decisions could range from estimating a parameter to choosing between different courses of action based on the expected outcomes.</p> <p>For example:</p> <ul> <li>If you’re estimating a parameter \(\theta\), the <strong>action</strong> could be selecting the posterior mean, median, or mode as your estimate.</li> <li>If you’re deciding whether to launch a product, the <strong>action</strong> could involve calculating the probability of success using the posterior and deciding based on a predefined threshold.</li> <li>In medical diagnostics, the <strong>action</strong> could be choosing a treatment plan based on the likelihood of a disease inferred from the posterior.</li> </ul> <p>In essence, <strong>actions</strong> are the outcomes of the decision-making process, guided by the posterior distribution and a loss function that quantifies the cost of making an incorrect decision.</p> <h5 id="what-is-an-estimator-in-the-frequentist-approach"><strong>What is an “Estimator” in the frequentist approach?</strong></h5> <p>An <strong>estimator</strong> is a statistical function or rule used to estimate an unknown parameter \(\theta\) based on observed data. In frequentist statistics, estimators are often chosen based on their theoretical properties, such as:</p> <ul> <li> <strong>Unbiasedness</strong>: The estimator’s expected value equals the true parameter value.</li> <li> <strong>Efficiency</strong>: The estimator has the smallest possible variance among all unbiased estimators.</li> <li> <strong>Consistency</strong>: The estimator converges to the true parameter value as the sample size increases.</li> </ul> <p>For example:</p> <ul> <li>The <strong>sample mean</strong> is a common estimator for the population mean.</li> <li>The <strong>sample variance</strong> is an estimator for the population variance.</li> </ul> <p>In Bayesian statistics, however, the <strong>estimator</strong> is derived directly from the posterior distribution. For instance:</p> <ul> <li>The <strong>posterior mean</strong> minimizes squared error loss.</li> <li>The <strong>posterior median</strong> minimizes absolute error loss.</li> <li>The <strong>posterior mode</strong> corresponds to the most likely value of \(\theta\).</li> </ul> <p>The key difference is that Bayesian methods do not require separate justification for an estimator because the posterior distribution naturally incorporates both the prior beliefs and observed data, making the choice of estimator a consequence of the decision-making process.</p> <hr> <p>We’ve covered most of it, right? Now, let’s revisit the foundational concepts that underpin everything we’ve discussed so far, including conditional probability, the likelihood function, and MLE in a general sense.</p> <h5 id="conditional-probability-modeling"><strong>Conditional Probability Modeling</strong></h5> <p>In this context, we have:</p> <ul> <li>An <strong>input space</strong>, \(X\), which represents the features or predictors.</li> <li>An <strong>outcome space</strong>, \(Y\), which represents the possible outputs.</li> <li>An <strong>action space</strong>, \(A\), consisting of probability distributions on \(Y\).</li> </ul> <p>A prediction function \(f : X \to A\) maps each input \(x \in X\) to a distribution on \(Y\). This setup allows us to model the relationship between inputs and outputs probabilistically.</p> <p>In a parametric framework, we define a family of conditional densities:</p> \[\{p(y \mid x, \theta) : \theta \in \Theta\},\] <p>where \(p(y \mid x, \theta)\) is a density on \(Y\) for each \(x \in X\), and \(\theta\) is a parameter in the finite-dimensional space \(\Theta\). This is the common starting point for either classical or Bayesian regression.</p> <h5 id="classical-treatment-likelihood-function"><strong>Classical Treatment: Likelihood Function</strong></h5> <p>In the classical approach, we begin with data \(D = (y_1, \dots, y_n)\) and assume it is generated by the conditional density \(p(y \mid x, \theta)\). The probability of the data is:</p> \[p(D \mid x_1, \dots, x_n, \theta) = \prod_{i=1}^n p(y_i \mid x_i, \theta)\] <p>For fixed \(D\), the likelihood function is defined as:</p> \[L_D(\theta) = p(D \mid x, \theta),\] <p>where \(x = (x_1, \dots, x_n)\).</p> <h5 id="maximum-likelihood-estimator-mle"><strong>Maximum Likelihood Estimator (MLE)</strong></h5> <p>The <strong>Maximum Likelihood Estimator (MLE)</strong> for \(\theta\) is the value that maximizes the likelihood function:</p> \[\hat{\theta}_{\text{MLE}} = \arg\max_{\theta \in \Theta} L_D(\theta)\] <p>Interestingly, MLE corresponds to <strong>Empirical Risk Minimization (ERM)</strong> if we set the loss function to the negative log-likelihood. The resulting prediction function is:</p> \[\hat{f}(x) = p(y \mid x, \hat{\theta}_{\text{MLE}})\] <hr> <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>So, we’ve reached the end of this blog. I know it can be confusing at times—I’ve been confused too—but take your time to get a solid grasp on it. This is the foundation of Bayesian ML. In the past few blogs, we’ve discussed these concepts, but do you recall if we’ve applied them to any prediction tasks yet? The answer is no. In the next one, we’ll put them into practice through Bayesian conditional models.</p> <h5 id="references"><strong>References</strong></h5> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>