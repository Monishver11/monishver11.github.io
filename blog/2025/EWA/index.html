<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Exponential Weighted Average Algorithm | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%A5&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/EWA/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Exponential Weighted Average Algorithm</h1> <p class="post-meta"> Created in January 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/adv-ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ADV-ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>The <strong>Exponential Weighted Average Algorithm (EWAA)</strong> is an online learning algorithm that provides elegant guarantees for minimizing regret in adversarial settings. It extends the principles of the Weighted Majority Algorithm by incorporating exponential weight updates, making it particularly effective for handling convex loss functions.</p> <h4 id="how-the-exponential-weighted-average-algorithm-works"><strong>How the Exponential Weighted Average Algorithm Works</strong></h4> <p>At its core, the EWAA maintains and updates weights for a set of experts, similar to the Weighted Majority Algorithm. However, it uses an <strong>exponential weighting scheme</strong> to achieve better bounds on regret, especially for convex losses.</p> <h5 id="steps-of-the-algorithm"><strong>Steps of the Algorithm</strong></h5> <p><strong>Initialization</strong> Set initial weights for all \(N\) experts:</p> \[w_{1,i} = 1, \quad \forall i \in \{1, \dots, N\}\] <p><strong>Prediction at Round \(t\)</strong></p> <ul> <li>Observe the predictions \(\hat{y}_{t,i}\) from all experts.</li> <li>Compute the aggregate prediction as a weighted average:</li> </ul> \[\hat{y}_t = \frac{\sum_{i=1}^N w_{t,i} \cdot \hat{y}_{t,i}}{\sum_{i=1}^N w_{t,i}}\] <p><strong>Update Weights</strong></p> <ul> <li>After receiving the true outcome \(y_t\), update the weights for the next round:</li> </ul> \[w_{t+1,i} = w_{t,i} \cdot e^{-\eta L(\hat{y}_{t,i}, y_t)}\] <ul> <li>The weight update can also be expressed directly using the <strong>cumulative loss</strong> \(L_t(i)\) of expert \(i\) after \(t\) rounds:</li> </ul> \[w_{t+1,i} = e^{-\eta L_t(i)}\] <p><strong><mark>Key Points to Highlight:</mark></strong></p> <p><strong>Simplification of Weight Updates</strong> While the equation appears to involve \(w_{t,i}\) in the update, the final weight \(w_{t+1,i}\) depends only on the cumulative loss \(L_t(i)\) and not on previous weights.<br> This is why it shows \(w_{t+1,i} = e^{-\eta L_t(i)}\), as the weights can be normalized afterward.</p> <p><strong>Interpretation of \(e^{-x}\)</strong> The term \(e^{-\eta x}\) decreases exponentially as \(x\) (loss) increases.<br> This ensures poorly performing experts are rapidly down-weighted. A plot of \(e^{-x}\) can visually illustrate this decay.</p> <p>If you’re still unclear about the final weight update rule, keep reading — the explanation below should clarify things.</p> <hr> <p>We start from the original weight update equation and simplify it step by step to express it in terms of the <strong>cumulative loss</strong>.</p> <p><strong>1. Original Weight Update</strong> The weight update at time \(t+1\) is defined as:</p> \[w_{t+1,i} = w_{t,i} \cdot e^{-\eta L(\hat{y}_{t,i}, y_t)}\] <p><strong>2. Recursive Application</strong> Expanding the recursion over all previous rounds \(1, \dots, t\):</p> \[w_{t+1,i} = w_{1,i} \cdot e^{-\eta L(\hat{y}_{1,i}, y_1)} \cdot e^{-\eta L(\hat{y}_{2,i}, y_2)} \cdots e^{-\eta L(\hat{y}_{t,i}, y_t)}\] <p><strong>3. Simplify the Product</strong> Using the property of exponents \(a^x \cdot a^y = a^{x+y}\):</p> \[w_{t+1,i} = w_{1,i} \cdot e^{-\eta \sum_{s=1}^t L(\hat{y}_{s,i}, y_s)}\] <p><strong>4. Initial Weights</strong> Since the initial weights are set to \(w_{1,i} = 1\) for all experts, this simplifies to:</p> \[w_{t+1,i} = e^{-\eta \sum_{s=1}^t L(\hat{y}_{s,i}, y_s)}\] <p><strong>5. Cumulative Loss Definition</strong> Define the <strong>cumulative loss</strong> of expert \(i\) after \(t\) rounds as:</p> \[L_t(i) = \sum_{s=1}^t L(\hat{y}_{s,i}, y_s)\] <p><strong>6. Final Simplified Form</strong> Substituting \(L_t(i)\) into the equation gives the simplified weight update:</p> \[w_{t+1,i} = e^{-\eta L_t(i)}\] <p><strong><mark>Key Insight:</mark></strong></p> <ul> <li>The weight at time \(t+1\) depends only on the <strong>cumulative loss</strong> \(L_t(i)\), not on the individual losses at previous rounds or the intermediate weights.</li> <li>This simplification is possible because the update rule is <strong>multiplicative</strong>, and the cumulative loss naturally aggregates all penalties from previous rounds.</li> </ul> <hr> <h5 id="theorem-regret-bound-for-ewaa"><strong>Theorem: Regret Bound for EWAA</strong></h5> <p>Let \(L(y, y')\) be a convex loss function in its first argument, taking values in \([0, 1]\). For any \(\eta &gt; 0\) and any sequence of labels \(y_1, \dots, y_T \in \mathcal{Y}\), the regret of the Exponential Weighted Average Algorithm satisfies:</p> \[R_T \leq \frac{\log N}{\eta} + \frac{\eta T}{8}\] <p>Here, the regret is defined as the difference between the total loss of the algorithm and the loss of the best expert:</p> \[R_T = \sum_{t=1}^T L(\hat{y}_t, y_t) - \min_{i \in [N]} \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\] <p><strong>Optimized Learning Rate</strong></p> <p>By choosing \(\eta = \sqrt{\frac{8 \log N}{T}}\), we minimize the regret bound, resulting in: \(R_T \leq \sqrt{\frac{T}{2} \log N}\)</p> <p>This demonstrates that the regret grows logarithmically with the number of experts \(N\) and sublinearly with the number of time steps \(T\), indicating the efficiency of EWAA.</p> <p><strong>Convex Loss Function in Its First Argument</strong></p> <p>Before we dive deeper, let’s clarify what we mean by a <strong>convex loss function in its first argument</strong>. In this context, the phrase refers to the loss function \(L(y, y')\) being convex with respect to its first argument, \(y\) (which could be the true label or the model output).</p> <p>To break it down:</p> <ul> <li>The loss function \(L(y, y')\) measures the difference between the true label \(y\) and the predicted label \(y'\).</li> <li> <strong>Convexity in the first argument</strong> means that for any fixed value of \(y'\), the function \(L(y, y')\) is convex in \(y\). This implies that as you vary the predicted label \(y'\), the loss function increases in a “bowl-shaped” manner when considering its first argument \(y\). This property is important for optimization because convex functions are easier to minimize, ensuring that algorithms like EWAA can efficiently adjust to minimize cumulative loss over time.</li> </ul> <p>In mathematical terms, for any fixed \(y'\), the function \(L(y, y')\) satisfies the condition of convexity:</p> \[L(\lambda y_1 + (1-\lambda) y_2, y') \leq \lambda L(y_1, y') + (1-\lambda) L(y_2, y')\] <p>for any \(y_1, y_2 \in \mathcal{Y}\) and \(\lambda \in [0, 1]\).</p> <hr> <h4 id="proof-of-the-regret-bound"><strong>Proof of the Regret Bound</strong></h4> <p>Define the <strong>potential function</strong>:</p> \[\Phi_t = \log \left( \sum_{i=1}^N w_{t,i} \right)\] <p>The goal is to derive an upper bound and a lower bound for \(\Phi_t\), and then combine them to establish the regret bound.</p> <h5 id="upper-bound"><strong>Upper Bound</strong></h5> <p><strong>Step 1: Change in Potential Function</strong></p> <p>From the weight update rule:</p> \[w_{t+1,i} = w_{t,i} e^{-\eta L(\hat{y}_{t,i}, y_t)},\] <p>we can write the change in the potential function as:</p> \[\Phi_{t+1} - \Phi_t = \log \left( \frac{\sum_{i=1}^N w_{t,i} e^{-\eta L(\hat{y}_{t,i}, y_t)}}{\sum_{i=1}^N w_{t,i}} \right) = \log \left( \mathbb{E}_{p_t}[e^{-\eta X}] \right),\] <p>where \(X = -L(\hat{y}_{t,i}, y_t) \in [-1, 0]\) and \(p_t(i) = \frac{w_{t,i}}{\sum_{j=1}^N w_{t,j}}\) is the probability distribution over experts.</p> <p><strong>Step 2: Centering the Random Variable</strong></p> <p>Define \(X = -L(\hat{y}_{t,i}, y_t)\), where \(X \in [-1, 0]\). The expectation can be centered around its mean:</p> \[\mathbb{E}_{p_t} \left[ e^{-\eta L(\hat{y}_{t,i}, y_t)} \right] = \mathbb{E}_{p_t} \left[ e^{\eta (X - \mathbb{E}_{p_t}[X])} \right] e^{\eta \mathbb{E}_{p_t}[X]}\] <p>Substituting this back, we have:</p> \[\Phi_{t+1} - \Phi_t = \log \mathbb{E}_{p_t} \left[ e^{\eta (X - \mathbb{E}_{p_t}[X])} \right] + \eta \mathbb{E}_{p_t}[X]\] <p><strong>Step 3: Applying Hoeffding’s Lemma</strong></p> <p>By Hoeffding’s Lemma, for any centered random variable \(X - \mathbb{E}_{p_t}[X]\) bounded in \([-1, 0]\):</p> \[\log \mathbb{E}_{p_t} \left[ e^{\eta (X - \mathbb{E}_{p_t}[X])} \right] \leq \frac{\eta^2}{8}\] <p>Substituting this bound:</p> \[\Phi_{t+1} - \Phi_t \leq \eta \mathbb{E}_{p_t}[X] + \frac{\eta^2}{8}\] <p><strong>Step 4: Substituting \(X = -L(\hat{y}_{t,i}, y_t)\)</strong></p> <p>Recall that \(X = -L(\hat{y}_{t,i}, y_t)\), so \(\mathbb{E}_{p_t}[X] = -\mathbb{E}_{p_t}[L(\hat{y}_{t,i}, y_t)]\). Substituting:</p> \[\Phi_{t+1} - \Phi_t \leq -\eta \mathbb{E}_{p_t}[L(\hat{y}_{t,i}, y_t)] + \frac{\eta^2}{8}\] <p><strong>Step 5: Applying Convexity of \(L\)</strong></p> <p>By the convexity of \(L\) in its first argument:</p> \[\mathbb{E}_{p_t}[L(\hat{y}_{t,i}, y_t)] \geq L(\mathbb{E}_{p_t}[\hat{y}_{t,i}], y_t) = L(\hat{y}_t, y_t),\] <p>where \(\hat{y}_t = \mathbb{E}_{p_t}[\hat{y}_{t,i}]\) is the prediction of the algorithm. Using this:</p> \[\Phi_{t+1} - \Phi_t \leq -\eta L(\hat{y}_t, y_t) + \frac{\eta^2}{8}\] <p>[How? - Unclear]</p> <p><strong>Step 6: Summing Over \(t = 1, \dots, T\)</strong></p> <p>Summing this inequality over all time steps:</p> \[\sum_{t=1}^T (\Phi_{t+1} - \Phi_t) \leq -\eta \sum_{t=1}^T L(\hat{y}_t, y_t) + \frac{\eta^2 T}{8}\] <p>The left-hand side telescopes:</p> \[\Phi_{T+1} - \Phi_1 \leq -\eta \sum_{t=1}^T L(\hat{y}_t, y_t) + \frac{\eta^2 T}{8}\] <p><strong>Final Upper Bound</strong></p> <p>This establishes the <strong>upper bound</strong> for the change in potential:</p> \[\Phi_{T+1} - \Phi_1 \leq -\eta \sum_{t=1}^T L(\hat{y}_t, y_t) + \frac{\eta^2 T}{8}\] <hr> <h5 id="lower-bound"><strong>Lower Bound</strong></h5> <p><strong>Step 1: Potential Function at \(T+1\)</strong></p> <p>From the definition of the potential function:</p> \[\Phi_{T+1} = \log \left( \sum_{i=1}^N w_{T+1,i} \right),\] <p>where \(w_{T+1,i}\) is the weight of expert \(i\) at time \(T+1\).</p> <p><strong>Step 2: Weight Update Rule</strong></p> <p>Using the weight update rule:</p> \[w_{T+1,i} = e^{-\eta L_{T,i}},\] <p>where \(L_{T,i} = \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\) is the <strong>cumulative loss</strong> of expert \(i\) up to time \(T\).</p> <p>Substituting into the potential function:</p> \[\Phi_{T+1} = \log \left( \sum_{i=1}^N e^{-\eta L_{T,i}} \right).\] <p><strong>Step 3: Lower Bound for Log-Sum-Exp</strong></p> <p>Applying the <strong>lower bound for the log-sum-exp function</strong>:</p> \[\log \left( \sum_{i=1}^N e^{-\eta L_{T,i}} \right) \geq \max_{i \in [N]} \left( -\eta L_{T,i} \right) + \log N.\] <p>Rewriting:</p> \[\Phi_{T+1} \geq -\eta \min_{i \in [N]} L_{T,i} + \log N,\] <p>where \(\min_{i \in [N]} L_{T,i}\) is the smallest cumulative loss among all experts.</p> <p><strong>Note:</strong> If this isn’t clear, refer to the <a href="https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/" rel="external nofollow noopener" target="_blank">log-sum-exp</a> trick—it’s essentially the same approach we’ve used here.</p> <p><strong>Step 4: Initial Potential Function</strong></p> <p>From the initial condition, the potential function at \(t = 1\) is:</p> \[\Phi_1 = \log N\] <p><strong>Step 5: Combining Results</strong></p> <p>Combining the expressions for \(\Phi_{T+1}\) and \(\Phi_1\), we obtain:</p> \[\Phi_{T+1} - \Phi_1 \geq -\eta \min_{i \in [N]} L_{T,i}\] <p><strong>Final Lower Bound</strong></p> <p>Thus, the lower bound for the change in potential is:</p> \[\Phi_{T+1} - \Phi_1 \geq -\eta \min_{i \in [N]} L_{T,i}\] <hr> <h5 id="combining-bounds"><strong>Combining Bounds</strong></h5> <p>From the upper and lower bounds:</p> \[-\eta \min_{i \in [N]} L_{T,i} \leq -\eta \sum_{t=1}^T L(\hat{y}_t, y_t) + \frac{\eta^2 T}{8}\] <p>Rearranging terms:</p> \[\sum_{t=1}^T L(\hat{y}_t, y_t) - \min_{i \in [N]} L_{T,i} \leq \frac{\log N}{\eta} + \frac{\eta T}{8}\] <p>Thus, the regret satisfies:</p> \[R_T \leq \frac{\log N}{\eta} + \frac{\eta T}{8}\] <p><strong>Note:</strong> <strong>\(\min_{i \in [N]} L_{T,i}\) and Its Meaning</strong></p> <p>The term \(\min_{i \in [N]} L_{T,i}\) refers to the <strong>minimum cumulative loss</strong> among all the experts (or models) after \(T\) rounds. Specifically:</p> <ul> <li>\(L_{T,i}\) is the cumulative loss of expert (or model) \(i\) after \(T\) rounds.</li> <li>\(\min_{i \in [N]} L_{T,i}\) represents the smallest cumulative loss incurred by any expert over the \(T\) rounds.</li> </ul> <p>This is the term we need in our calculation to compute the regret, right!</p> <p><strong><mark>Key Takeaways:</mark></strong></p> <ul> <li>The <strong>regret bound</strong> of the EWAA is a function of both the learning rate \(\eta\) and the time horizon \(T\).</li> <li>By choosing \(\eta = \sqrt{\frac{8 \log N}{T}}\), the regret grows sublinearly with \(T\) and logarithmically with \(N\), ensuring the algorithm’s efficiency.</li> </ul> <hr> <h5 id="advantages-and-disadvantages-of-ewaa"><strong>Advantages and Disadvantages of EWAA</strong></h5> <p><strong>Advantages</strong></p> <ol> <li> <strong>Strong Theoretical Guarantees</strong>: <ul> <li>The regret bound for the <strong>(EWAA)</strong> is logarithmic in the number of experts \(N\) and sublinear in the number of time steps \(T\). This means that even as the number of experts or rounds increases, the regret grows slowly, offering a strong theoretical guarantee on performance. [Why? - Think]</li> </ul> </li> <li> <strong>Applicability to Convex Losses</strong>: <ul> <li>Unlike algorithms specifically tailored for binary losses, EWAA can handle <strong>convex loss functions</strong>. This makes it a more versatile algorithm since convex losses are more general and can cover a wider range of applications beyond binary classification.</li> </ul> </li> <li> <strong>Weight Adaptivity</strong>: <ul> <li>The <strong>exponential weight updates</strong> in EWAA ensure that poor-performing experts are penalized efficiently over time. This adaptive mechanism allows the algorithm to focus more on better-performing experts, while discouraging the influence of worse-performing ones, improving its overall performance.</li> </ul> </li> </ol> <p><strong>Disadvantages</strong></p> <ul> <li> <strong>Requires Knowledge of Horizon \(T\)</strong>: <ul> <li>A disadvantage of the EWAA is that it requires knowledge of the <strong>horizon</strong> \(T\), which refers to the total number of rounds or time steps the algorithm will run. Specifically, the learning rate \(\eta\) in the regret bound often depends on \(T\) (for example, \(\eta\) might be chosen as \(\frac{1}{\sqrt{T}}\)).</li> <li>This means that to optimize the regret bound, you need to have some insight or knowledge about the total number of rounds \(T\) in advance. This can be a significant limitation in practical applications, where \(T\) is not always known or fixed in advance. In real-world scenarios, you might need to adapt to changing environments without prior knowledge of how long the process will last, making it challenging to choose the best parameters like \(\eta\).</li> </ul> </li> </ul> <hr> <p>Before we wrap up, let’s take a step back and get a clearer picture of the whole thing:</p> <h5 id="why-convexity-helps-in-ewaa"><strong><mark>Why Convexity Helps in EWAA</mark></strong></h5> <ol> <li> <strong>Optimization and Regret Minimization</strong>: <ul> <li>The convexity of the loss function with respect to the predicted labels \(y\) (the first argument) ensures that the algorithm can effectively minimize cumulative loss. Since convex functions have a single global minimum, optimization is straightforward and guarantees convergence toward a solution with low regret.</li> </ul> </li> <li> <strong>Exponential Weight Updates</strong>: <ul> <li>In EWAA, the weight updates are based on the <strong>exponential</strong> of the loss, and convexity allows these updates to be well-behaved. Specifically, since the loss function increases in a convex manner as the difference between \(y\) and \(y'\) increases, the exponential weight updates ensure that poorly performing experts are penalized more heavily. This ensures that the algorithm focuses on the most promising experts while reducing the influence of poor ones.</li> </ul> </li> <li> <strong>Efficient Learning</strong>: <ul> <li>Convexity ensures that the loss function grows in a predictable manner, which helps in adjusting the weights efficiently across time steps. This is important for the overall performance of the algorithm, as it leads to effective adaptation and faster convergence to a good solution.</li> </ul> </li> <li> <strong>Theoretical Guarantees</strong>: <ul> <li>The convexity property allows the <strong>theoretical regret bounds</strong> for EWAA to be derived more easily. Since convex functions have well-defined gradients and curvature properties, we can make rigorous claims about the regret bound, such as the logarithmic growth in the number of experts \(N\) and sublinear growth in the number of time steps \(T\). Without convexity, such guarantees would not be as strong or as easily established.</li> </ul> </li> </ol> <p>And, If you’re unsure about the difference between linear and sublinear growth, here’s a quick clarification:</p> <ul> <li> <strong>Linear growth</strong> means the value grows at a constant rate (proportional to the parameter). Mathematically: \(f(x) = O(x)\).</li> <li> <strong>Sublinear growth</strong> means the value grows at a slower rate than the parameter, such that the output doesn’t keep up at the same pace. Mathematically: \(f(x) = O(x^a)\) where \(0 &lt; a &lt; 1\), or \(f(x) = O(\log(x))\).</li> </ul> <hr> <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>The Exponential Weighted Average Algorithm provides strong guarantees for regret minimization with convex loss functions. Its use of exponential weight updates makes it both adaptable and theoretically elegant, though its dependence on the time horizon \(T\) can present practical challenges.</p> <p>In the next post, we’ll dive into the doubling trick for selecting \(\eta\) and how it improves regret bounds. Stay tuned—see you in the next one!</p> <h5 id="references"><strong>References</strong></h5> <ul> <li><a href="https://people.eecs.berkeley.edu/~bartlett/courses/281b-sp08/21.pdf" rel="external nofollow noopener" target="_blank">Online Learning: Halving Algorithm and Exponential Weights(Notes)</a></li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>