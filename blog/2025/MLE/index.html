<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Generalized Linear Models Explained - Leveraging MLE for Regression and Classification | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?b337fdf3fe456a8da16aab16e9a00f8c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/MLE/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/thoughts/">Thoughts </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Generalized Linear Models Explained - Leveraging MLE for Regression and Classification</h1> <p class="post-meta"> Created in January 18, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>When building machine learning models, one of the most important tasks is estimating the parameters of a model in a way that best explains the observed data. This is where the principle of <strong>Maximum Likelihood Estimation (MLE)</strong> comes into play. MLE provides a rigorous framework for parameter estimation, grounded in probability theory, and is widely used across regression, classification, and beyond.</p> <p>Suppose we have a probabilistic model and a dataset \(D\). The central question is: how do we estimate the parameters \(\theta\) of the model? According to MLE, we should choose \(\theta\) to maximize the likelihood of the observed data. Formally, the likelihood function is defined as:</p> \[L(\theta) \stackrel{\text{def}}{=} p(D; \theta),\] <p>which captures how likely the dataset \(D\) is, given the model parameters \(\theta\).</p> <p>If the dataset consists of \(N\) independent and identically distributed (iid) examples, the likelihood simplifies to a product of individual data likelihoods:</p> \[L(\theta) = \prod_{n=1}^{N} p\left(y^{(n)} \mid x^{(n)}; \theta\right)\] <p>While this expression is mathematically correct, the product of many probabilities can be unwieldy. To simplify the computation, we typically work with the <strong>log-likelihood</strong>, \(\ell(\theta)\), which is simply the natural logarithm of the likelihood:</p> \[\ell(\theta) \stackrel{\text{def}}{=} \log L(\theta) = \sum_{n=1}^{N} \log p\left(y^{(n)} \mid x^{(n)}; \theta\right)\] <p>Maximizing \(\ell(\theta)\) is equivalent to maximizing \(L(\theta)\), as the logarithm is a monotonic function. Alternatively, minimizing the <strong>negative log-likelihood (NLL)</strong> is a common approach, as it frames the problem as a minimization task.</p> <hr> <h4 id="mle-for-linear-regression"><strong>MLE for Linear Regression</strong></h4> <p>To make these concepts more concrete, let’s see how MLE applies to a simple and widely known model: linear regression.</p> <p>In linear regression, we assume the output \(Y\) is conditionally Gaussian given the input \(X\). Specifically,</p> \[Y \mid X = x \sim \mathcal{N}(\theta^\top x, \sigma^2),\] <p>where \(\theta^\top x\) is the mean and \(\sigma^2\) is the variance of the Gaussian distribution.</p> <p>The log-likelihood for this model can be written as:</p> \[\ell(\theta) \stackrel{\text{def}}{=} \log L(\theta) = \log \prod_{n=1}^{N} p\left(y^{(n)} \mid x^{(n)}; \theta\right) = \sum_{n=1}^{N} \log p\left(y^{(n)} \mid x^{(n)};\theta\right)\] <p>Substituting the Gaussian probability density function into the equation, we get:</p> \[\ell(\theta) = \sum_{n=1}^{N} \log \left( \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left( -\frac{\left(y^{(n)} - \theta^\top x^{(n)}\right)^2}{2\sigma^2} \right) \right)\] <p>Simplifying further, the log-likelihood becomes:</p> \[\ell(\theta) = N \log \frac{1}{\sqrt{2\pi \sigma^2}} - \frac{1}{2\sigma^2} \sum_{n=1}^{N} \left(y^{(n)} - \theta^\top x^{(n)}\right)^2\] <p>Notice that the first term, \(N \log \frac{1}{\sqrt{2\pi \sigma^2}}\), is independent of \(\theta\). This means that to maximize \(\ell(\theta)\), we only need to minimize the second term, which is proportional to the sum of squared residuals.</p> <p>This brings us to an important insight: <strong>maximizing the log-likelihood in linear regression is equivalent to minimizing the squared error.</strong></p> <h5 id="deriving-the-gradient-of-the-log-likelihood"><strong>Deriving the Gradient of the Log-Likelihood</strong></h5> <p>To find the parameters that maximize the log-likelihood, we compute its gradient with respect to \(\theta\) and set it to zero. From our earlier expression for \(\ell(\theta)\):</p> \[\ell(\theta) = N \log \frac{1}{\sqrt{2\pi \sigma^2}} - \frac{1}{2\sigma^2} \sum_{n=1}^{N} \left(y^{(n)} - \theta^\top x^{(n)}\right)^2,\] <p>the gradient with respect to \(\theta_i\), the \(i\)-th parameter, is:</p> \[\frac{\partial \ell}{\partial \theta_i} = -\frac{1}{\sigma^2} \sum_{n=1}^{N} \left(y^{(n)} - \theta^\top x^{(n)}\right) x_i^{(n)}\] <p>Setting \(\frac{\partial \ell}{\partial \theta_i} = 0\) gives us the familiar <strong>normal equations</strong> for linear regression, which are typically solved to find the optimal \(\theta\).</p> <p>This yields:</p> \[-\frac{1}{\sigma^2} \sum_{n=1}^{N} \left(y^{(n)} - \theta^\top x^{(n)}\right) x_i^{(n)} = 0\] <p>Multiplying both sides by \(\sigma^2\) gives:</p> \[\sum_{n=1}^{N} \left(y^{(n)} - \theta^\top x^{(n)}\right) x_i^{(n)} = 0\] <p>We can write the equation in matrix form as:</p> \[\mathbf{X}^\top \left( \mathbf{y} - \mathbf{X} \theta \right) = 0\] <p>Rewriting the equation:</p> \[\mathbf{X}^\top \mathbf{y} - \mathbf{X}^\top \mathbf{X} \theta = 0\] <p>Rearranging gives the normal equation:</p> \[\mathbf{X}^\top \mathbf{X} \theta = \mathbf{X}^\top \mathbf{y}\] <p>Solving for \(\theta\):</p> \[\theta = \left( \mathbf{X}^\top \mathbf{X} \right)^{-1} \mathbf{X}^\top \mathbf{y}\] <p>Through this derivation, we’ve established a key connection between the probabilistic interpretation of linear regression and the classical squared error minimization. The principle of MLE not only provides a mathematically grounded way to estimate parameters but also reveals the assumptions underlying different models.</p> <p>What’s fascinating is that this approach generalizes beyond regression. For instance, in classification tasks, MLE leads to the cross-entropy loss. This will be the focus of the next section, where we’ll explore how MLE ties into classification problems and the role of log-loss in optimizing model parameters.</p> <hr> <h4 id="from-linear-to-logistic-regression-expanding-the-scope-of-mle"><strong>From Linear to Logistic Regression: Expanding the Scope of MLE</strong></h4> <p>In the previous section, we explored how the Maximum Likelihood Estimation (MLE) principle naturally connects with linear regression. We saw that linear regression assumes the target \(Y \vert X = x\) follows a Gaussian distribution, and maximizing the likelihood aligns with minimizing the squared loss.</p> <p>But is the Gaussian assumption always valid? Not necessarily. For example, in classification tasks where \(Y\) takes on discrete values (e.g., 0 or 1), assuming a Gaussian distribution is inappropriate. This raises an important question: <strong>can we use the same MLE-based modeling approach for tasks beyond regression?</strong></p> <p>The answer is yes, and this brings us to <strong>logistic regression</strong>, which is tailored for classification tasks.</p> <h4 id="logistic-regression-assumptions-and-foundations"><strong>Logistic Regression: Assumptions and Foundations</strong></h4> <p>Consider a binary classification problem where the target \(Y \in \{0, 1\}\). What should the conditional distribution of \(Y\) given \(X = x\) look like? For logistic regression, we model \(p(y \mid x)\) using a <strong>Bernoulli distribution</strong>:</p> \[p(y \mid x) = h(x)^y (1 - h(x))^{1-y},\] <p>where \(h(x) \in (0, 1)\) represents the probability \(p(y = 1 \mid x)\).</p> <h5 id="parameterizing-hx"><strong>Parameterizing \(h(x)\):</strong></h5> <p>In linear regression, the mean \(\mathbb{E}[Y \mid X = x]\) was parameterized as \(\theta^\top x\). However, for classification, \(h(x)\) must map the linear predictor \(\theta^\top x\) (which lies in \(\mathbb{R}\)) to the interval \((0, 1)\). To achieve this, we use the <strong>logistic function</strong>:</p> \[f(\eta) = \frac{1}{1 + e^{-\eta}}, \quad \text{where } \eta = \theta^\top x\] <p>Thus, the probability \(p(y \mid x)\) becomes:</p> \[p(y \mid x) = \text{Bernoulli}(f(\theta^\top x)),\] <p>or equivalently:</p> \[p(y = 1 \mid x) = f(\theta^\top x), \quad p(y = 0 \mid x) = 1 - f(\theta^\top x)\] <p>[any reason why bernoulli?]</p> <p><strong>Why do we use the Bernoulli distribution in logistic regression?</strong></p> <p>In logistic regression, the target variable \(Y\) is binary, taking values in \(\{0, 1\}\), making the <strong>Bernoulli distribution</strong> a natural choice. The Bernoulli distribution models the probability of success (1) or failure (0) in a single trial.</p> <p>We model the conditional probability \(p(y \mid x)\) using the logistic function, which ensures that the predicted probabilities lie in the interval \((0, 1)\):</p> \[p(y = 1 \mid x) = f(\theta^\top x), \quad p(y = 0 \mid x) = 1 - f(\theta^\top x),\] <p>where \(f(\eta) = \frac{1}{1 + e^{-\eta}}\) is the logistic function. The Bernoulli distribution is then used to model the binary outcomes given these probabilities.</p> <h5 id="interpreting-the-logistic-function"><strong>Interpreting the Logistic Function</strong></h5> <p>The logistic function is smooth and monotonically increasing, mapping any real-valued input to a value in the range \((0, 1)\). It has the characteristic “S-shape” and is particularly useful for modeling probabilities.</p> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Logistic_Fn-480.webp 480w,/assets/img/Logistic_Fn-800.webp 800w,/assets/img/Logistic_Fn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Logistic_Fn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Logistic_Fn" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>One interesting property of the logistic function is its connection to the <strong>log-odds</strong>. For logistic regression:</p> \[\log \frac{p(y = 1 \mid x)}{p(y = 0 \mid x)} = \theta^\top x\] <p>This shows that the log-odds (or logit) of \(y = 1\) depend linearly on the input \(x\). Moreover, the decision boundary, where \(p(y = 1 \mid x) = p(y = 0 \mid x) = 0.5\), is defined by \(\theta^\top x = 0\), making it a <strong>linear decision boundary</strong>.</p> <h5 id="mle-for-logistic-regression"><strong>MLE for Logistic Regression</strong></h5> <p>As with linear regression, the parameters \(\theta\) in logistic regression are estimated by maximizing the conditional log-likelihood:</p> \[\ell(\theta) = \sum_{n=1}^{N} \log p\left(y^{(n)} \mid x^{(n)}; \theta\right)\] <p>For a Bernoulli-distributed \(y\), substituting \(p(y \mid x)\):</p> \[\ell(\theta) = \sum_{n=1}^{N} \left[ y^{(n)} \log f(\theta^\top x^{(n)}) + (1 - y^{(n)}) \log (1 - f(\theta^\top x^{(n)})) \right]\] <p>Unlike linear regression, this log-likelihood does not have a closed-form solution for \(\theta\). However, it is <strong>concave</strong>, meaning that optimization techniques like gradient ascent can efficiently find the unique optimal solution.</p> <h5 id="gradient-ascent-for-logistic-regression"><strong>Gradient Ascent for Logistic Regression</strong></h5> <p>The gradient of the log-likelihood \(\ell(\theta)\) with respect to \(\theta_i\) (the \(i\)-th parameter) is given by:</p> \[\frac{\partial \ell}{\partial \theta_i} = \sum_{n=1}^{N} \left( y^{(n)} - f(\theta^\top x^{(n)}) \right) x_i^{(n)}\] <p><strong>Derivation of the above form:</strong></p> <p>Math Review: Chain Rule</p> <p>If \(z\) depends on \(y\), which itself depends on \(x\), e.g., \(z = (y(x))^2\), then:</p> \[\frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx}\] <p>Likelihood for a Single Example:</p> \[\ell^n = y^{(n)} \log f(\theta^\top x^{(n)}) + (1 - y^{(n)}) \log(1 - f(\theta^\top x^{(n)}))\] <p>The gradient with respect to \(\theta_i\) is:</p> \[\frac{\partial \ell^n}{\partial \theta_i} = \frac{\partial \ell^n}{\partial f^n} \frac{\partial f^n}{\partial \theta_i}\] <p>Using the chain rule:</p> \[= \left(\frac{y^{(n)}}{f^n} - \frac{1 - y^{(n)}}{1 - f^n}\right) \frac{\partial f^n}{\partial \theta_i}\] <p>Simplify:</p> \[= \left(\frac{y^{(n)}}{f^n} - \frac{1 - y^{(n)}}{1 - f^n}\right) \left(f^n (1 - f^n) x_i^{(n)}\right)\] \[= \left(y^{(n)} - f^n\right) x_i^{(n)}.\] <p>The full gradient is thus:</p> \[\frac{\partial \ell}{\partial \theta_i} = \sum_{n=1}^{N} \left(y^{(n)} - f(\theta^\top x^{(n)})\right) x_i^{(n)}.\] <p>This gradient looks strikingly similar to that of linear regression, except for the presence of the logistic function \(f(\cdot)\).</p> <p>Using this gradient, we iteratively update the parameters using gradient ascent:</p> \[\theta \leftarrow \theta + \alpha \nabla_\theta \ell(\theta),\] <p>where \(\alpha\) is the learning rate.</p> <p><strong>Note the distinction:</strong> since the function is concave, we apply gradient ascent rather than descent.</p> <h5 id="a-comparison-linear-vs-logistic-regression"><strong>A Comparison: Linear vs Logistic Regression</strong></h5> <p>Here’s a side-by-side comparison to highlight the similarities and differences:</p> <hr> <table> <thead> <tr> <th>Feature</th> <th>Linear Regression</th> <th>Logistic Regression</th> </tr> </thead> <tbody> <tr> <td>Input combination</td> <td>\(\theta^\top x\) (linear)</td> <td>\(\theta^\top x\) (linear)</td> </tr> <tr> <td>Output</td> <td>Real-valued</td> <td>Categorical (0 or 1)</td> </tr> <tr> <td>Conditional distribution</td> <td>Gaussian</td> <td>Bernoulli</td> </tr> <tr> <td>Transfer function \(f(\theta^\top x)\)</td> <td>Identity</td> <td>Logistic</td> </tr> <tr> <td>Mean \(\mathbb{E}[Y \mid X = x; \theta]\)</td> <td>\(f(\theta^\top x)\)</td> <td>\(f(\theta^\top x)\)</td> </tr> </tbody> </table> <hr> <p>The main difference lies in the conditional distribution of \(Y\) and the transfer function \(f(\cdot)\), which maps \(\theta^\top x\) to the appropriate range for each model.</p> <h4 id="generalizing-logistic-regression"><strong>Generalizing Logistic Regression</strong></h4> <p>The principles behind logistic regression can be extended to handle other types of outputs, such as counts or probabilities for multiple classes. This generalization leads to the broader family of <strong>generalized linear models (GLMs)</strong>.</p> <h5 id="steps-for-generalized-regression-models"><strong>Steps for Generalized Regression Models</strong></h5> <ol> <li> <strong>Task</strong>: Given \(x\), predict \(p(y \mid x)\).</li> <li> <strong>Modeling</strong>: <ul> <li>Choose a parametric family of distributions \(p(y; \theta)\) with parameters \(\theta \in \Theta\).</li> <li>Choose a transfer function that maps a linear predictor in \(\mathbb{R}\) to \(\Theta\):</li> </ul> \[x \in \mathbb{R}^d \mapsto w^\top x \in \mathbb{R} \mapsto f(w^\top x) = \theta \in \Theta\] </li> <li> <p><strong>Learning</strong>: Use MLE to estimate the parameters:</p> \[\hat{\theta} = \arg\max_\theta \log p(D; \hat{\theta})\] </li> <li> <p><strong>Inference</strong>: For prediction, map \(x\) through the learned transfer function:</p> \[x \mapsto f(w^\top x)\] </li> </ol> <p>In the next section, we’ll dive deeper into these generalized models, exploring their flexibility and application to diverse prediction tasks.</p> <hr> <h4 id="extending-generalized-linear-models-from-poisson-to-multinomial-logistic-regression"><strong>Extending Generalized Linear Models: From Poisson to Multinomial Logistic Regression</strong></h4> <p>In our journey through generalized linear models (GLMs), we’ve seen how logistic regression extends MLE principles to classification tasks. Now, let’s explore other use cases where GLMs shine, including <strong>Poisson regression</strong> for count-based predictions and <strong>multinomial logistic regression</strong> for multiclass classification.</p> <h4 id="example-poisson-regression"><strong>Example: Poisson Regression</strong></h4> <p>Imagine we want to predict the number of people entering a New York restaurant during lunchtime. What features could help? Time of day, day of the week, weather conditions, or nearby events might all be relevant. Importantly, the target variable \(Y\), representing the number of visitors, is a non-negative integer: \(Y \in \{0, 1, 2, \dots\}\).</p> <h5 id="why-use-the-poisson-distribution"><strong>Why Use the Poisson Distribution?</strong></h5> <p>The Poisson distribution is a natural choice for modeling count data. A random variable \(Y \sim \text{Poisson}(\lambda)\) has the probability mass function:</p> \[p(Y = k; \lambda) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k \in \{0, 1, 2, \dots\},\] <p>where \(\lambda &gt; 0\) is the rate parameter. The expected value \(\mathbb{E}[Y] = \lambda\), making \(\lambda\) both the mean and variance of \(Y\).</p> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Poisson_pmf.svg-480.webp 480w,/assets/img/Poisson_pmf.svg-800.webp 800w,/assets/img/Poisson_pmf.svg-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Poisson_pmf.svg.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Poisson_pmf" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h5 id="what-does-the-poisson-distribution-mean-intuitively"><strong>What Does the Poisson Distribution Mean, Intuitively?</strong></h5> <p>The Poisson distribution can be understood through a simple analogy: imagine standing at a bus stop.</p> <ol> <li> <strong>The Events</strong>: Each bus that arrives at the stop is an “event.”</li> <li> <strong>Constant Rate</strong>: On average, buses arrive every 10 minutes, meaning we expect about 6 buses per hour. This average rate, \(\lambda = 6\), is constant.</li> <li> <strong>Independence</strong>: The arrival of one bus doesn’t affect when the next one will come (events are independent).</li> </ol> <p>Now, if you wait at the bus stop for an hour, the Poisson distribution models the probability of seeing exactly 5, 6, or 7 buses in that time. While the average is 6 buses, randomness may cause the actual count to vary, with probabilities decreasing for more extreme deviations (e.g., 0 buses or 12 buses in an hour are unlikely).</p> <p>This shows how the Poisson distribution captures both the expected rate (\(\lambda\)) and the variability in the number of events.</p> <h5 id="constructing-the-poisson-regression-model"><strong>Constructing the Poisson Regression Model</strong></h5> <p>We assume \(Y \mid X = x \sim \text{Poisson}(\lambda)\). The challenge is to ensure \(\lambda\), the rate parameter, is positive. This is achieved using a transfer function \(f\):</p> \[x \mapsto w^\top x \quad \text{(linear predictor in } \mathbb{R} \text{)} \mapsto \lambda = f(w^\top x) \quad \text{(rate parameter in } (0, \infty) \text{)}.\] <p>The standard transfer function is the exponential function:</p> \[f(w^\top x) = e^{w^\top x}\] <h5 id="log-likelihood-for-poisson-regression"><strong>Log-Likelihood for Poisson Regression</strong></h5> <p>Given a dataset \(D = \{(x_1, y_1), \dots, (x_n, y_n)\}\), the log-likelihood is:</p> \[\log p(y_i; \lambda_i) = \left[y_i \log \lambda_i - \lambda_i - \log(y_i!)\right]\] \[\log p(D; w) = \sum_{i=1}^{n} \left[ y_i \log f(w^\top x_i) - f(w^\top x_i) - \log(y_i!) \right],\] <p>where \(f(w^\top x_i) = e^{w^\top x_i}\). Substituting \(\lambda_i\), we get:</p> \[\log p(D; w) = \sum_{i=1}^{n} \left[ y_i (w^\top x_i) - e^{w^\top x_i} - \log(y_i!) \right]\] <p>As with logistic regression, the likelihood is concave, so gradient-based methods can efficiently optimize \(w\).</p> <h5 id="gradient-for-poisson-regression"><strong>Gradient for Poisson Regression</strong></h5> <p>To optimize the log-likelihood, we compute its gradient with respect to the weight vector \(w\).</p> <p>The gradient is:</p> \[\frac{\partial \log p(D; w)}{\partial w} = \sum_{i=1}^{n} \left[ y_i x_i - e^{w^\top x_i} x_i \right]\] <p>Factoring out common terms, we get:</p> \[\frac{\partial \log p(D; w)}{\partial w} = \sum_{i=1}^{n} x_i \left[ y_i - e^{w^\top x_i} \right]\] <p>The gradient indicates the update direction for \(w\), with each term capturing the difference between the observed count \(y_i\) and the predicted count \(e^{w^\top x_i}\), weighted by the feature vector \(x_i\). Gradient ascent can then be used to maximize the log-likelihood, as the likelihood is concave for Poisson regression. Again, notice how similar the gradient is to the other problems we’ve explored so far—the transfer function differs in each case.</p> <hr> <h4 id="example-multinomial-logistic-regression"><strong>Example: Multinomial Logistic Regression</strong></h4> <p>Next, let’s tackle multiclass classification, where the target \(Y \in \{1, 2, \dots, k\}\) spans multiple categories. Logistic regression’s Bernoulli distribution extends to the <strong>categorical distribution</strong>, which is parameterized by a probability vector \(\theta = (\theta_1, \dots, \theta_k)\). For valid probabilities:</p> \[\sum_{i=1}^{k} \theta_i = 1, \quad \theta_i \geq 0 \text{ for all } i.\] <p>For a given \(y \in \{1, \dots, k\}\):</p> \[p(y) = \theta_y.\] <h5 id="what-does-the-categorical-distribution-mean-intuitively"><strong>What Does the Categorical Distribution Mean, Intuitively?</strong></h5> <p>The categorical distribution assigns a probability to each class. For a given input \(x\), we want to predict the probability of each class \(y\) belonging to the target set. The probability of the class \(y\) is \(\theta_y\), where \(\theta_y\) is the component of the probability vector corresponding to the class \(y\). This allows us to perform multiclass classification by selecting the class with the highest probability.</p> \[p(y) = \theta_y.\] <h5 id="constructing-the-multinomial-logistic-regression-model"><strong>Constructing the Multinomial Logistic Regression Model</strong></h5> <p>The key idea in multinomial logistic regression is to compute a linear score for each class. For a given input vector \(x\), we compute a vector of scores \(s \in \mathbb{R}^k\) for all classes:</p> \[s = (w_1^\top x, \dots, w_k^\top x),\] <p>where \(w_i\) represents the weight vector associated with class \(i\). These scores are then transformed using the <strong>softmax function</strong> to produce valid probabilities. The softmax function is defined as:</p> \[\text{softmax}(s)_i = \frac{e^{s_i}}{\sum_{j=1}^{k} e^{s_j}} \quad \text{for } i = 1, \dots, k.\] <p>The softmax function ensures that the resulting probabilities form a valid probability distribution, satisfying:</p> \[\sum_{i=1}^{k} \theta_i = 1, \quad \theta_i \geq 0 \text{ for all } i.\] <h5 id="log-likelihood-for-multinomial-logistic-regression"><strong>Log-Likelihood for Multinomial Logistic Regression</strong></h5> <p>Given a dataset \(D = \{(x_1, y_1), \dots, (x_n, y_n)\}\), the log-likelihood of the model is the sum of the log probabilities for the true classes. The log-likelihood is given by:</p> \[\log p(D; W) = \sum_{i=1}^{n} \log \theta_{y_i},\] <p>where \(\theta_{y_i} = \text{softmax}(W^\top x_i)_{y_i}\). The parameters \(W\) are learned by maximizing the log-likelihood using gradient-based optimization methods.</p> <p><strong>Note:</strong> Don’t be misled by the use of theta and softmax notations. The way this is mentioned can be confusing. For now, let’s proceed with caution.</p> <h5 id="gradient-for-multinomial-logistic-regression"><strong>Gradient for Multinomial Logistic Regression</strong></h5> <p>To optimize the parameters \(W\), we compute the gradient of the log-likelihood with respect to \(W\).</p> <h6 id="step-by-step-derivation"><strong>Step-by-Step Derivation</strong></h6> <ol> <li> <p><strong>Log-Likelihood for Multinomial Logistic Regression:</strong></p> <p>The log-likelihood for the dataset \(D = \{(x_1, y_1), \dots, (x_n, y_n)\}\) is:</p> \[\log p(D; W) = \sum_{i=1}^{n} \log \theta_{y_i},\] <p>where \(\theta_{y_i} = \text{softmax}(W^\top x_i)_{y_i}\) is the predicted probability of the true class \(y_i\) for the \(i\)-th data point.</p> </li> <li> <p><strong>Softmax Function:</strong></p> <p>The softmax function for class \(j\) is given by:</p> \[\theta_j(x_i; W) = \frac{e^{w_j^\top x_i}}{\sum_{k=1}^{k} e^{w_k^\top x_i}}.\] </li> <li> <p><strong>Log-Likelihood Expansion:</strong></p> <p>Substituting the softmax expression into the log-likelihood:</p> \[\log p(D; W) = \sum_{i=1}^{n} \log \left( \frac{e^{w_{y_i}^\top x_i}}{\sum_{k=1}^{k} e^{w_k^\top x_i}} \right),\] <p>which simplifies to:</p> \[\log p(D; W) = \sum_{i=1}^{n} \left( w_{y_i}^\top x_i - \log \left( \sum_{k=1}^{k} e^{w_k^\top x_i} \right) \right).\] </li> <li> <p><strong>Gradient of the Log-Likelihood:</strong></p> <p>The gradient of the log-likelihood with respect to the weight vector \(w_j\) is computed by differentiating each term in the log-likelihood expression:</p> <ul> <li> <p>The derivative of the first term, \(w_{y_i}^\top x_i\), with respect to \(w_j\) is simply \(x_i\) when \(y_i = j\) and 0 otherwise.</p> </li> <li> <p>The second term involves the <strong>log-sum-exp</strong>, and its derivative with respect to \(w_j\) is:</p> \[\nabla_{w_j} \log \left( \sum_{k=1}^{k} e^{w_k^\top x_i} \right) = \theta_j(x_i; W) \cdot x_i.\] </li> </ul> </li> <li> <p><strong>Final Gradient Expression:</strong></p> <p>Combining the two terms, the gradient of the log-likelihood with respect to \(w_j\) is:</p> \[\nabla_{w_j} \log p(D; W) = \sum_{i=1}^{n} \left( \mathbf{1}_{\{y_i = j\}} - \theta_j(x_i; W) \right) x_i,\] <p>where \(\mathbf{1}_{\{y_i = j\}}\) is the indicator function that is 1 if the true class \(y_i\) equals \(j\), and 0 otherwise.</p> </li> </ol> <p>This gradient is used to adjust the weight vectors during training to improve the model’s predictions.</p> <hr> <h4 id="review-recipe-for-conditional-models"><strong>Review: Recipe for Conditional Models</strong></h4> <p>GLMs provide a unified approach for constructing conditional models. Here’s a quick recipe:</p> <ol> <li> <strong>Define the Input and Output Space</strong>: Start with the features \(x\) and target \(y\).</li> <li> <strong>Choose an Output Distribution</strong>: Based on the nature of \(y\), select an appropriate probability distribution \(p(y \mid x; \theta)\).</li> <li> <strong>Select a Transfer Function</strong>: Map the linear predictor \(w^\top x\) into the required range of the distribution parameters.</li> <li> <strong>Optimize via MLE</strong>: Estimate \(\theta\) by maximizing the log-likelihood using gradient-based methods.</li> </ol> <p>This framework, called <strong>generalized linear models</strong>, can be adapted for a wide range of prediction tasks.</p> <hr> <p>Before we wrap up, did we overlook something? Ah, yes—let’s revisit the log-sum-exp function and its significance.</p> <h4 id="log-sum-exp-function"><strong>Log-Sum-Exp Function</strong></h4> <p>The <strong>log-sum-exp</strong> (LSE) function is a mathematical expression used frequently in machine learning and statistics, particularly in contexts involving probabilities and normalization. It is defined as:</p> \[\text{LSE}(s) = \log \left( \sum_{k=1}^K e^{s_k} \right),\] <p>where \(s = (s_1, s_2, \dots, s_K)\) is a vector of real-valued scores.</p> <h5 id="key-properties-of-log-sum-exp"><strong>Key Properties of Log-Sum-Exp</strong></h5> <ol> <li> <p><strong>Smooth Maximum Approximation</strong><br> The log-sum-exp function can be thought of as a “soft maximum” of the elements in \(s\) because, for large values of \(s_k\), the largest term dominates the sum:</p> \[\text{LSE}(s) \approx \max(s_k)\] </li> <li> <p><strong>Numerical Stability</strong><br> To ensure numerical stability when computing \(e^{s_k}\) for large values of \(s_k\), the log-sum-exp function is often rewritten as:</p> \[\text{LSE}(s) = \log \left( \sum_{k=1}^K e^{s_k - \max(s)} \right) + \max(s),\] <p>where \(\max(s)\) is the maximum value in \(s\). This adjustment ensures that the exponentials remain within a manageable range. Check why it’s written this way in the referenced resource; I highly recommend it.</p> </li> </ol> <h5 id="log-sum-exp-in-multinomial-logistic-regression"><strong>Log-Sum-Exp in Multinomial Logistic Regression</strong></h5> <p>In multinomial logistic regression, the log-sum-exp term naturally arises when computing the log-likelihood. The predicted probabilities are computed using the softmax function:</p> \[\theta_j(x_i; W) = \frac{e^{w_j^\top x_i}}{\sum_{k=1}^{K} e^{w_k^\top x_i}}\] <p>The denominator of the softmax involves a sum of exponentials. Taking the logarithm of the denominator gives the log-sum-exp term:</p> \[\log \left( \sum_{k=1}^K e^{w_k^\top x_i} \right)\] <p>This term normalizes the probabilities so that they sum to 1 across all classes.</p> <h5 id="derivative-of-log-sum-exp"><strong>Derivative of Log-Sum-Exp</strong></h5> <p>The derivative of the log-sum-exp function with respect to a specific score \(s_j\) is:</p> \[\frac{\partial}{\partial s_j} \log \left( \sum_{k=1}^K e^{s_k} \right) = \frac{e^{s_j}}{\sum_{k=1}^K e^{s_k}}\] <p>This is equivalent to the probability assigned to class \(j\) by the softmax function:</p> \[\frac{\partial}{\partial s_j} \log \left( \sum_{k=1}^K e^{s_k} \right) = \text{softmax}(s)_j.\] <p>In the case of multinomial logistic regression, where \(s_j = w_j^\top x_i\), the derivative with respect to \(w_j\) is:</p> \[\nabla_{w_j} \log \left( \sum_{k=1}^K e^{w_k^\top x_i} \right) = \theta_j(x_i; W) \cdot x_i,\] <p>where \(\theta_j(x_i; W) = \text{softmax}(W^\top x_i)_j\) is the predicted probability for class \(j\).</p> <h5 id="still-why-the-use-of-log-sum-exp"><strong>Still, Why the Use of Log-Sum-Exp</strong></h5> <p>In multinomial logistic regression, we use the <strong>softmax function</strong> to convert the raw class scores (logits) into probabilities. The softmax function itself involves summing the exponentials of the scores, not the log-sum-exp.</p> <p>However, when calculating the <strong>log-likelihood</strong> of the model during optimization, we encounter the <strong>log-sum-exp</strong> function. The log-sum-exp is used in the log-likelihood to handle the sum of the exponentials in a numerically stable way. It’s primarily used to:</p> <ol> <li> <strong>Avoid overflow and underflow</strong>: When working with large or small exponentiated values (as in the softmax function), exponentiation can cause numerical instability. The log-sum-exp helps stabilize these computations.</li> <li> <strong>Ensure proper normalization</strong>: In the context of the softmax function, it ensures the sum of the probabilities is 1, making them valid probabilities for classification.</li> </ol> <p>In summary, while softmax uses the sum of exponentials, the <strong>log-sum-exp</strong> appears in the log-likelihood computation to stabilize the logarithmic transformation, enabling proper optimization.</p> <h5 id="analogy-for-the-log-sum-exp-function"><strong>Analogy for the Log-Sum-Exp Function</strong></h5> <p>Imagine you’re at a sports competition with several players, and their scores are exponentially amplified (think of \(e^{s_k}\) as the “hype” around each player’s performance). The log-sum-exp function acts like a judge summarizing all the scores into a single value that reflects the overall competition, but with a bias toward the top performers.</p> <ul> <li>The <strong>“log”</strong> compresses the scale, keeping the summary manageable.</li> <li>The <strong>“sum”</strong> captures the contributions of <em>all</em> players, not just the best one.</li> <li>The <strong>“exp”</strong> amplifies the impact of the highest scores, making it feel like a weighted average that leans toward the standout performers.</li> </ul> <p>In short, the <strong>log-sum-exp is like a “soft maximum”</strong>: it highlights the best, considers the rest, and ensures the result is stable and interpretable.</p> <p>If you’re having trouble with this analogy, go through the example in the reference. It’ll help clarify things.</p> <hr> <p>Alright, it’s time to wrap this up. In the next section, we’ll dive into another type of probabilistic modeling: generative models. We’ll explore what they are and how they work. Stay tuned, and see you there!</p> <h5 id="references"><strong>References</strong></h5> <ul> <li><a href="https://benhay.es/posts/exploring-distributions/" rel="external nofollow noopener" target="_blank">Exploring Probability Distributions</a></li> <li><a href="https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/" rel="external nofollow noopener" target="_blank">The Log-Sum-Exp Trick</a></li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-thoughts",title:"Thoughts",description:"",section:"Navigation",handler:()=>{window.location.href="/thoughts/"}},{id:"post-gradient-boosting-in-practice",title:"Gradient Boosting in Practice",description:"Practical insights and regularization techniques to make gradient boosting robust, efficient, and generalize well in real-world applications.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gb-in-practice/"}},{id:"post-binomialboost",title:"BinomialBoost",description:"See how the gradient boosting framework naturally extends to binary classification using the logistic loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/binomial-boost/"}},{id:"post-gradient-boosting-quot-anyboost-quot",title:"Gradient Boosting / &quot;Anyboost&quot;",description:"A clear and intuitive walkthrough of gradient boosting as functional gradient descent, with detailed explanations of residuals, step directions, and algorithmic structure.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gradient-boosting/"}},{id:"post-forward-stagewise-additive-modeling",title:"Forward Stagewise Additive Modeling",description:"A clear walkthrough of FSAM and its role in boosting with exponential loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FSAM/"}},{id:"post-introduction-to-gradient-boosting",title:"Introduction to Gradient Boosting",description:"A beginner-friendly introduction to gradient boosting, connecting empirical risk minimization, adaptive basis functions, and the challenges of non-differentiable models like decision trees.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-gradient-boosting/"}},{id:"post-boosting-and-adaboost",title:"Boosting and AdaBoost",description:"This blog post provides an in-depth overview of boosting techniques, focusing on AdaBoost, explaining its key concepts, algorithm steps, and real-world applications in classification tasks.",section:"Posts",handler:()=>{window.location.href="/blog/2025/adaboost/"}},{id:"post-random-forests",title:"Random Forests",description:"Explore how Random Forests enhance Bagging by introducing randomness at each tree split, reducing correlation, and increasing diversity to build more accurate and stable prediction models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/random-forest/"}},{id:"post-bagging-bootstrap-aggregation",title:"Bagging - Bootstrap Aggregation",description:"Bagging (Bootstrap Aggregating) combines multiple high-variance models trained on different bootstrap samples to create a more stable, accurate, and lower-variance ensemble predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bagging/"}},{id:"post-introduction-to-ensemble-methods",title:"Introduction to Ensemble Methods",description:"A beginner&#39;s guide to ensemble methods in machine learning, explaining how averaging and bootstrapping reduce variance and improve model performance.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-to-ensemble-methods/"}},{id:"post-decision-trees-for-classification",title:"Decision Trees for Classification",description:"Explains what makes a good split, how impurity is quantified using Gini, Entropy, and misclassification error, and why trees are both powerful and interpretable.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees-classification/"}},{id:"post-decision-trees-our-first-non-linear-classifier",title:"Decision Trees - Our First Non-Linear Classifier",description:"Learn how decision trees work for regression, including split criteria, overfitting control, and intuitive examples.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees/"}},{id:"post-structured-perceptron-amp-structured-svm",title:"Structured Perceptron &amp; Structured SVM",description:"Understanding how Structured Perceptron and Structured SVM learn to predict structured outputs with interdependent components.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-perceptron-svm/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"news-sharing-personal-reflections-thoughts-tab-thoughts",title:"Sharing personal reflections - [Thoughts Tab](/thoughts/)",description:"",section:"News"},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-gaze-guided-reinforcement-learning-for-visual-search",title:"Gaze-Guided Reinforcement Learning for Visual Search",description:"Discover how gaze prediction from human eye-tracking enhances AI agents in object search tasks. By integrating visual attention into reinforcement learning through three novel methods, our approach enables faster, more effective navigation in simulated environments.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>