<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Forward Stagewise Additive Modeling | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="A clear walkthrough of FSAM and its role in boosting with exponential loss."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?b337fdf3fe456a8da16aab16e9a00f8c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/FSAM/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item "> <a class="nav-link" href="/thoughts/">Thoughts </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Forward Stagewise Additive Modeling</h1> <p class="post-meta"> Created in May 04, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In the previous post, we saw how learning both the weights and basis functions gives rise to adaptive models — and how neural networks and decision trees fit into this framework. Now, we dive into <strong>Forward Stagewise Additive Modeling (FSAM)</strong>, a greedy algorithm that forms the foundation of <strong>Gradient Boosting</strong>.</p> <hr> <h5 id="what-is-fsam"><strong>What is FSAM?</strong></h5> <p>Our goal is to fit a model of the form:</p> \[f(x) = \sum_{m=1}^M v_m h_m(x)\] <p>where each \(h_m \in \mathcal{H}\) is a basis function, and \(v_m\) is its weight. The key idea is to <strong>greedily</strong> fit one function at a time without changing previously fitted ones. That’s why it’s called <strong>forward stagewise</strong>.</p> <p>After \(m - 1\) steps, we have:</p> \[f_{m-1}(x) = \sum_{i=1}^{m-1} v_i h_i(x)\] <p>At step \(m\), we select a new basis function \(h_m \in \mathcal{H}\) and weight \(v_m &gt; 0\) to form:</p> \[f_m(x) = \underbrace{ f_{m-1}(x) }_{\text{fixed}} + v_m h_m(x)\] <p>We choose \((v_m, h_m)\) to minimize the loss as much as possible.</p> <h5 id="fsam-for-empirical-risk-minimization-erm"><strong>FSAM for Empirical Risk Minimization (ERM)</strong></h5> <p>Let’s apply FSAM to an ERM objective. We proceed as follows:</p> <ol> <li> <p><strong>Initialize:</strong></p> \[f_0(x) = 0\] </li> <li> <strong>For</strong> \(m = 1\) to \(M\): <ul> <li> <p>Compute:</p> \[(v_m, h_m) = \arg\min_{v \in \mathbb{R}, h \in \mathcal{H}} \frac{1}{n} \sum_{i=1}^n \ell\left(y_i, f_{m-1}(x_i) + v h(x_i)\right)\] </li> <li> <p>Update:</p> \[f_m(x) = f_{m-1}(x) + v_m h_m(x)\] </li> </ul> </li> <li> <strong>Return</strong> \(f_M\)</li> </ol> <hr> <h5 id="exponential-loss"><strong>Exponential Loss</strong></h5> <p>Let’s use the <strong>exponential loss</strong>:</p> \[\ell(y, f(x)) = \exp\left( -y f(x) \right)\] <p>This loss function is margin-based, it penalizes examples based on how confidently they are classified.</p> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gb-2-480.webp 480w,/assets/img/gb-2-800.webp 800w,/assets/img/gb-2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gb-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="gb-2" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h5 id="fsam-with-exponential-loss"><strong>FSAM with Exponential Loss</strong></h5> <p>Apply the FSAM steps using exponential loss:</p> <ol> <li> <p><strong>Initialize:</strong></p> \[f_0(x) = 0\] </li> <li> <strong>For</strong> \(m = 1\) to \(M\): <ul> <li> <p>Compute:</p> \[(v_m, h_m) = \arg\min_{v \in \mathbb{R}, h \in \mathcal{H}} \frac{1}{n} \sum_{i=1}^n \exp\left(-y_i \left( f_{m-1}(x_i) + \overbrace{v h(x_i)}^{\text{new piece}} \right)\right)\] </li> <li> <p>Update:</p> \[f_m(x) = f_{m-1}(x) + v_m h_m(x)\] </li> </ul> </li> <li> <strong>Return</strong> \(f_M\)</li> </ol> <hr> <h5 id="fsam-with-exponential-loss-basis-function"><strong>FSAM with Exponential Loss: Basis Function</strong></h5> <p>We assume the base hypothesis space is:</p> \[\mathcal{H} = \left\{ h : \mathcal{X} \to \{-1, 1\} \right\}\] <p>At the \(m^\text{th}\) round, our goal is to choose \(v\) and \(h\) to minimize the following objective:</p> \[J(v, h) = \sum_{i=1}^n \exp\left[ -y_i \left( f_{m-1}(x_i) + v h(x_i) \right) \right]\] <p>We define:</p> \[w_i^m \triangleq \exp\left( -y_i f_{m-1}(x_i) \right)\] <p>This lets us re-express the objective as:</p> \[J(v, h) = \sum_{i=1}^n w_i^m \exp\left( -y_i v h(x_i) \right)\] <p>Now, because \(h(x_i) \in \{-1, 1\}\), we can split the expression into cases:</p> \[J(v, h) = \sum_{i=1}^n w_i^m \left[ \mathbb{I}(y_i = h(x_i)) e^{-v} + \mathbb{I}(y_i \ne h(x_i)) e^{v} \right]\] <p>Recall that:</p> \[\mathbb{I}(y_i = h(x_i)) = 1 - \mathbb{I}(y_i \ne h(x_i))\] <p>Using this identity, we can further simplify:</p> \[J(v, h) = \sum_{i=1}^n w_i^m \left[ (e^v - e^{-v}) \mathbb{I}(y_i \ne h(x_i)) + e^{-v} \right]\] <p>At this point, we’re ready to decide how to pick the best \(h\).</p> <p>Note that the second term of the objective function, \(e^{-v}\) is constant with respect to \(h\), and if \(v &gt; 0\), the term \(e^v - e^{-v}\) is positive. Therefore, minimizing \(J(v, h)\) is equivalent to minimizing:</p> \[\arg \min_{h \in \mathcal{H}} \sum_{i=1}^n w_i^m \mathbb{I}(y_i \ne h(x_i))\] <p>This leads to:</p> \[h_m = \arg \min_{h \in \mathcal{H}} \sum_{i=1}^n w_i^m \mathbb{I}(y_i \ne h(x_i))\] <p>We can also write this as a weighted classification error:</p> \[h_m = \arg \min_{h \in \mathcal{H}} \frac{1}{\sum_{i=1}^n w_i^m} \sum_{i=1}^n w_i^m \mathbb{I}(y_i \ne h(x_i))\] <p>In other words, \(h_m\) is the classifier that minimizes the <strong>weighted zero-one loss</strong>.</p> <hr> <h5 id="fsam-with-exponential-loss-classifier-weights"><strong>FSAM with Exponential Loss: Classifier Weights</strong></h5> <p>Now that we’ve selected the best basis function \(h_m\), let’s figure out how to choose the best weight \(v_m\) for it.</p> <p>We define the <strong>weighted zero-one error</strong> at round \(m\) as:</p> \[\text{err}_m = \frac{\sum_{i=1}^n w_i^m \mathbb{I}(y_i \ne h(x_i))}{\sum_{i=1}^n w_i^m}\] <p>This error measures how poorly the current hypothesis \(h\) is doing, taking into account the importance (weights) of each example.</p> <p>Then, it can be shown that the optimal value for \(v_m\) — the coefficient for the current basis function is:</p> \[v_m = \frac{1}{2} \log \frac{1 - \text{err}_m}{\text{err}_m} \tag{14}\] <p>This is exactly the same form as the weight update in AdaBoost (just scaled differently). Note that if \(\text{err}_m &lt; 0.5\) — that is, our current classifier is better than random guessing — then \(v_m &gt; 0\), meaning it contributes positively.</p> <hr> <p><strong>Derivation of the expression for the optimal classifier weights</strong></p> <p>To justify this expression for the optimal coefficient \(v_m\), recall that our goal at each round is to minimize the exponential loss objective:</p> \[J(v, h) = \sum_{i=1}^n w_i^m \left[ \exp(-v) \cdot \mathbb{I}(y_i = h(x_i)) + \exp(v) \cdot \mathbb{I}(y_i \ne h(x_i)) \right]\] <p>We can rewrite this as:</p> \[J(v, h) = \exp(-v) \sum_{i: y_i = h(x_i)} w_i^m + \exp(v) \sum_{i: y_i \ne h(x_i)} w_i^m\] <p>Define the <strong>weighted error</strong> of hypothesis \(h\) as:</p> \[\text{err}_m = \frac{\sum_{i=1}^n w_i^m \mathbb{I}(y_i \ne h(x_i))}{\sum_{i=1}^n w_i^m}\] <p>Let:</p> <ul> <li>\(W^{+} = \sum_{i: y_i = h(x_i)} w_i^m\) (correctly classified)</li> <li>\(W^{-} = \sum_{i: y_i \ne h(x_i)} w_i^m\) (misclassified)</li> </ul> <p>So the objective becomes:</p> \[J(v, h) = W^+ \exp(-v) + W^- \exp(v)\] <p>To find the optimal \(v = v_m\) for a fixed \(h = h_m\), we differentiate with respect to \(v\) and set to zero:</p> \[\frac{dJ}{dv} = -W^+ \exp(-v) + W^- \exp(v) = 0\] <p>Solving:</p> \[W^- \exp(v) = W^+ \exp(-v) \\ \Rightarrow \frac{W^-}{W^+} = \exp(-2v) \\ \Rightarrow -2v = \log\left( \frac{W^-}{W^+} \right) \\ \Rightarrow v = \frac{1}{2} \log\left( \frac{W^+}{W^-} \right)\] <p>Since:</p> \[\text{err}_m = \frac{W^-}{W^- + W^+} \quad \text{and} \quad 1 - \text{err}_m = \frac{W^+}{W^- + W^+}\] <p>We get:</p> \[\frac{W^+}{W^-} = \frac{1 - \text{err}_m}{\text{err}_m}\] <p>Therefore, the optimal weight for classifier \(h_m\) is:</p> \[v_m = \frac{1}{2} \log\left( \frac{1 - \text{err}_m}{\text{err}_m} \right) \tag{14}\] <p>This result balances the classifier’s confidence based on how well it performs: higher confidence (larger \(v_m\)) when error is low, and lower confidence when error is close to 0.5.</p> <hr> <h5 id="fsam-with-exponential-loss-updating-example-weights"><strong>FSAM with Exponential Loss: Updating Example Weights</strong></h5> <p>After choosing the best classifier \(h_m\) and its corresponding weight \(v_m\), we now update the example weights for the next round.</p> <p>The weights at round \(m+1\) are defined as:</p> \[w_i^{m+1} \overset{\text{def}}{=} \exp\left( -y_i f_m(x_i) \right) \tag{15}\] <p>Recall that the updated model at round \(m\) is:</p> \[f_m(x_i) = f_{m-1}(x_i) + v_m h_m(x_i) \tag{16}\] <p>Substituting this into the definition of the new weights:</p> \[w_i^{m+1} = \exp\left( -y_i (f_{m-1}(x_i) + v_m h_m(x_i)) \right) \\ = \exp\left( -y_i f_{m-1}(x_i) \right) \cdot \exp\left( -y_i v_m h_m(x_i) \right) \\ = w_i^m \cdot \exp\left( -y_i v_m h_m(x_i) \right) \tag{17}\] <p>This form shows how the current round’s prediction (\(h_m(x_i)\)) affects the weight of example \(i\) moving forward.</p> <p>Let’s interpret this based on classification correctness:</p> <ul> <li> <p>If \(y_i = h_m(x_i)\) (i.e., correctly classified), then:</p> \[-y_i v_m h_m(x_i) = -v_m \cdot 1 = -v_m\] </li> <li> <p>If \(y_i \ne h_m(x_i)\) (i.e., misclassified), since both \(y_i\) and \(h_m(x_i)\) are in \(\{-1, 1\}\):</p> \[-y_i v_m h_m(x_i) = -v_m \cdot (-1) = +v_m\] </li> </ul> <p>We can now re-express the update in terms of the indicator function:</p> \[w_i^{m+1} = w_i^m \cdot \exp\left( 2v_m \mathbb{I}(y_i \ne h_m(x_i)) \right) \cdot \underbrace{\exp(-v_m)}_{\text{constant scaler}} \tag{18}\] <p>This is because:</p> <ul> <li>When \(y_i = h_m(x_i)\), \(\mathbb{I}(y_i \ne h_m(x_i)) = 0\), so the exponent is \(0\) and we just get \(w_i^m \cdot \exp(-v_m)\).</li> <li>When \(y_i \ne h_m(x_i)\), \(\mathbb{I}(y_i \ne h_m(x_i)) = 1\), so the exponent is \(2v_m\), and the weight becomes \(w_i^m \cdot \exp(v_m)\).</li> </ul> <p><strong>Interpretation</strong></p> <ul> <li> <strong>Correct classification</strong>: the weight gets multiplied by \(\exp(-v_m)\) → the example becomes <strong>less important</strong>.</li> <li> <strong>Misclassification</strong>: the weight gets multiplied by \(\exp(v_m)\) → the example becomes <strong>more important</strong>.</li> </ul> <p>This mechanism focuses the learner on harder examples in future rounds, by increasing their influence.</p> <blockquote> <p>The constant factor \(\exp(-v_m)\) appears in all weights and <strong>cancels out during normalization</strong>. So only the relative importance matters.</p> </blockquote> <p><strong>Connection to AdaBoost</strong></p> <p>Observe that:</p> \[2v_m = \alpha_m\] <p>This matches the AdaBoost formulation, where \(\alpha_m\) is the weight assigned to the classifier at round \(m\).</p> <p>Hence, <strong>FSAM with exponential loss recovers AdaBoost’s update rule</strong>, making it a principled derivation from a loss minimization perspective.</p> <hr> <h5 id="why-use-exponential-loss"><strong>Why Use Exponential Loss?</strong></h5> <p>The exponential loss function is given by:</p> \[\ell_{\text{exp}}(y, f(x)) = \exp(-y f(x))\] <p>This loss has an elegant statistical interpretation. Specifically, it turns out that minimizing the expected exponential loss leads to a prediction function that estimates the <strong>log-odds</strong> of the label being positive:</p> \[f^*(x) = \frac{1}{2} \log \left( \frac{p(y = 1 \mid x)}{p(y = -1 \mid x)} \right)\] <p>This result aligns with the principle behind <strong>logistic regression</strong>, where the model estimates the log-odds of class membership. Here’s how we can justify it:</p> <p><strong>Derivation Sketch</strong></p> <p>We seek the function \(f^*(x)\) that minimizes the expected exponential loss:</p> \[\mathbb{E}_{y \sim p(y \mid x)}\left[ \exp(-y f(x)) \right] = p(y = 1 \mid x) \exp(-f(x)) + p(y = -1 \mid x) \exp(f(x))\] <p>Define:</p> <ul> <li> \[p_+ = p(y = 1 \mid x)\] </li> <li> \[p_- = p(y = -1 \mid x) = 1 - p_+\] </li> </ul> <p>So, the expected loss becomes:</p> \[L(f) = p_+ \exp(-f) + p_- \exp(f)\] <p>Take the derivative w.r.t. \(f\) and set to zero:</p> \[\frac{dL}{df} = -p_+ \exp(-f) + p_- \exp(f) = 0 \\ \Rightarrow p_- \exp(f) = p_+ \exp(-f) \\ \Rightarrow \frac{p_-}{p_+} = \exp(-2f) \\ \Rightarrow f^*(x) = \frac{1}{2} \log \left( \frac{p_+}{p_-} \right)\] <p>Thus,</p> \[f^*(x) = \frac{1}{2} \log \left( \frac{p(y = 1 \mid x)}{p(y = -1 \mid x)} \right)\] <p><strong>Interpretation</strong></p> <p>The exponential loss encourages predictions that align with the <strong>log-odds ratio</strong>. This makes it a natural choice for binary classification problems where confidence is important, and it helps explain why AdaBoost, which minimizes exponential loss, is such a powerful classifier.</p> <hr> <h5 id="adaboost-and-exponential-loss-robustness-issues"><strong>AdaBoost and Exponential Loss: Robustness Issues</strong></h5> <p>While exponential loss has nice theoretical and computational properties, it comes with a key drawback — <strong>lack of robustness</strong>.</p> <p>Recall that the exponential loss is:</p> \[\ell_{\text{exp}}(y, f(x)) = \exp(-y f(x))\] <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gb-2-480.webp 480w,/assets/img/gb-2-800.webp 800w,/assets/img/gb-2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gb-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="gb-2" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>This function grows <strong>exponentially</strong> as the margin \(y f(x)\) becomes more negative. So:</p> <ul> <li> <strong>Misclassified examples</strong> (where \(y f(x) &lt; 0\)) incur <strong>very high penalties</strong>.</li> <li>As a result, <strong>outliers</strong> or <strong>noisy labels</strong> can dominate the loss and heavily influence the model.</li> </ul> <p><strong>Practical Consequences</strong></p> <ul> <li>AdaBoost (which minimizes exponential loss) tends to <strong>over-focus on misclassified points</strong>, even if they are noisy or mislabeled.</li> <li>This leads to <strong>degraded performance</strong> in datasets with: <ul> <li>High <strong>Bayes error rate</strong> (i.e., intrinsic label uncertainty),</li> <li>Significant <strong>label noise</strong>.</li> </ul> </li> </ul> <p>In contrast, <strong>logistic loss</strong> (or log-loss), used in <strong>Logistic Regression</strong>, penalizes mistakes more <strong>gradually</strong> and is <strong>more robust</strong> in such settings.</p> <p><strong>Why Still Use Exponential Loss?</strong></p> <p>Despite these robustness concerns, exponential loss has some <strong>computational advantages</strong>:</p> <ul> <li>It leads to <strong>simpler update rules</strong> (as seen in AdaBoost),</li> <li>The math works out cleanly in boosting settings,</li> <li>It’s easy to implement and analyze.</li> </ul> <p>So in summary:</p> <blockquote> <p><strong>Exponential loss</strong> is powerful and efficient but sensitive to outliers.<br> <strong>Logistic loss</strong> is more robust, especially when the data is noisy or inherently uncertain.</p> </blockquote> <hr> <h5 id="wrapping-up"><strong>Wrapping up</strong></h5> <p>In this post, we’ve unpacked how <strong>Forward Stagewise Additive Modeling (FSAM)</strong> builds models by greedily adding base learners — and how, when paired with the <strong>exponential loss</strong>, it naturally recovers the well-known <strong>AdaBoost</strong> algorithm.</p> <p>Key takeaways:</p> <ul> <li>FSAM provides a clean, iterative framework for model building.</li> <li>The <strong>exponential loss</strong> leads to a simple and elegant form of weight updates.</li> <li>AdaBoost emerges as a special case of FSAM with exponential loss, emphasizing misclassified examples via <strong>weighted classification error</strong> and <strong>adaptive reweighting</strong>.</li> </ul> <p>However, this formulation is limited to specific loss functions like the exponential loss.</p> <p><strong>What’s next?</strong><br> In the upcoming post, we’ll generalize this framework to work with <strong>any differentiable loss function</strong>, leading to the powerful and flexible family of models known as <strong>Gradient Boosted Machines (GBMs)</strong>.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-resume",title:"Resume",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-thoughts",title:"Thoughts",description:"",section:"Navigation",handler:()=>{window.location.href="/thoughts/"}},{id:"post-hbase",title:"HBase",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 7",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-8-hbase/"}},{id:"post-hive-amp-trino",title:"Hive &amp; Trino",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 6",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-7-hive/"}},{id:"post-mapreduce-design-patterns",title:"MapReduce Design Patterns",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 5",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-5-mr-dp/"}},{id:"post-big-data-processing-concepts-amp-mapreduce",title:"Big Data Processing Concepts &amp; MapReduce",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 4",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-4-mapreduce/"}},{id:"post-hadoop-distributed-file-system-hdfs",title:"Hadoop Distributed File System (HDFS)",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 3",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-3-hdfs/"}},{id:"post-reading-notes-from-aleksa-gordic-39-s-gpu-blogpost",title:"Reading Notes from Aleksa Gordic&#39;s GPU BlogPost",description:"Reading notes for my reference from Aleksa Gordic&#39;s GPU BlogPost",section:"Posts",handler:()=>{window.location.href="/blog/2025/aleksagordic-gpu-blog-notes/"}},{id:"post-mlp-standard-derivatives-derivation",title:"MLP Standard Derivatives Derivation",description:"MLP Standard Derivatives Derivation",section:"Posts",handler:()=>{window.location.href="/blog/2025/mlp-derivatives/"}},{id:"post-simple-mlp-forward-and-backward-pass-with-einsum-derivation",title:"Simple MLP - Forward and Backward Pass (With Einsum) Derivation",description:"Simple MLP - Forward and Backward Pass Derivation",section:"Posts",handler:()=>{window.location.href="/blog/2025/mlp-fw-bwd/"}},{id:"post-gpu-notes",title:"GPU Notes",description:"GPU Architecture and Programming Course at NYU Courant - Lecture and Conceptual Notes",section:"Posts",handler:()=>{window.location.href="/blog/2025/gpu-notes/"}},{id:"post-big-data-storage",title:"Big Data Storage",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 2",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-2-storage/"}},{id:"post-introduction-to-realtime-and-big-data-analytics",title:"Introduction to Realtime and Big Data Analytics",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 1",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-1-intro/"}},{id:"post-gpu-essentials-a-concise-technical-guide",title:"GPU Essentials - A Concise Technical Guide",description:"A concise, technical guide to GPU architecture and CUDA, showing how massive parallelism is achieved through threads, blocks, SMs, and memory hierarchies.",section:"Posts",handler:()=>{window.location.href="/blog/2025/GPU-Intro/"}},{id:"post-wrapping-up-our-ml-foundations-journey",title:"Wrapping Up Our ML Foundations Journey",description:"A reflection on our exploration of machine learning fundamentals, from mathematical prerequisites to gradient boosting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/wrapping-ml-basics/"}},{id:"post-gradient-boosting-in-practice",title:"Gradient Boosting in Practice",description:"Practical insights and regularization techniques to make gradient boosting robust, efficient, and generalize well in real-world applications.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gb-in-practice/"}},{id:"post-binomialboost",title:"BinomialBoost",description:"See how the gradient boosting framework naturally extends to binary classification using the logistic loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/binomial-boost/"}},{id:"post-gradient-boosting-quot-anyboost-quot",title:"Gradient Boosting / &quot;Anyboost&quot;",description:"A clear and intuitive walkthrough of gradient boosting as functional gradient descent, with detailed explanations of residuals, step directions, and algorithmic structure.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gradient-boosting/"}},{id:"post-forward-stagewise-additive-modeling",title:"Forward Stagewise Additive Modeling",description:"A clear walkthrough of FSAM and its role in boosting with exponential loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FSAM/"}},{id:"post-introduction-to-gradient-boosting",title:"Introduction to Gradient Boosting",description:"A beginner-friendly introduction to gradient boosting, connecting empirical risk minimization, adaptive basis functions, and the challenges of non-differentiable models like decision trees.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-gradient-boosting/"}},{id:"post-boosting-and-adaboost",title:"Boosting and AdaBoost",description:"This blog post provides an in-depth overview of boosting techniques, focusing on AdaBoost, explaining its key concepts, algorithm steps, and real-world applications in classification tasks.",section:"Posts",handler:()=>{window.location.href="/blog/2025/adaboost/"}},{id:"post-random-forests",title:"Random Forests",description:"Explore how Random Forests enhance Bagging by introducing randomness at each tree split, reducing correlation, and increasing diversity to build more accurate and stable prediction models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/random-forest/"}},{id:"post-bagging-bootstrap-aggregation",title:"Bagging - Bootstrap Aggregation",description:"Bagging (Bootstrap Aggregating) combines multiple high-variance models trained on different bootstrap samples to create a more stable, accurate, and lower-variance ensemble predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bagging/"}},{id:"post-introduction-to-ensemble-methods",title:"Introduction to Ensemble Methods",description:"A beginner&#39;s guide to ensemble methods in machine learning, explaining how averaging and bootstrapping reduce variance and improve model performance.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-to-ensemble-methods/"}},{id:"post-decision-trees-for-classification",title:"Decision Trees for Classification",description:"Explains what makes a good split, how impurity is quantified using Gini, Entropy, and misclassification error, and why trees are both powerful and interpretable.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees-classification/"}},{id:"post-decision-trees-our-first-non-linear-classifier",title:"Decision Trees - Our First Non-Linear Classifier",description:"Learn how decision trees work for regression, including split criteria, overfitting control, and intuitive examples.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees/"}},{id:"post-structured-perceptron-amp-structured-svm",title:"Structured Perceptron &amp; Structured SVM",description:"Understanding how Structured Perceptron and Structured SVM learn to predict structured outputs with interdependent components.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-perceptron-svm/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"news-sharing-personal-reflections-thoughts-tab-thoughts",title:"Sharing personal reflections - [Thoughts Tab](/thoughts/)",description:"",section:"News"},{id:"news-wrapping-up-our-ml-foundations-journey-blog-2025-wrapping-ml-basics",title:"[Wrapping Up Our ML Foundations Journey](/blog/2025/wrapping-ml-basics/)",description:"",section:"News"},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-gaze-guided-reinforcement-learning-for-visual-search",title:"Gaze-Guided Reinforcement Learning for Visual Search",description:"Discover how gaze prediction from human eye-tracking enhances AI agents in object search tasks. By integrating visual attention into reinforcement learning through three novel methods, our approach enables faster, more effective navigation in simulated environments.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-understanding-swap-regret-2-0",title:"Understanding Swap Regret 2.0",description:"This blog post unpacks the &quot;Swap Regret 2.0&quot; paper through slide-by-slide insights, showing how the TreeSwap algorithm closes the gap between external and swap regret, advancing equilibrium computation in game theory and reinforcement learning.",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>