<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Online Learning in ML - A Beginner’s Guide to Adaptive Learning | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?e68e4955e21b20101db6e28a5a50abec"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/Online-Learning/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Online Learning in ML - A Beginner’s Guide to Adaptive Learning</h1> <p class="post-meta"> Created in January 23, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/adv-ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ADV-ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In this post, we’ll dive into one of the foundational topics that was discussed in the first class of my advanced machine learning course: online learning. This course is centered on theoretical insights and encourages students to think critically, experiment fearlessly, and embrace confusion as a stepping stone toward innovation. Let’s explore how online learning fits into the broader landscape of machine learning and why it’s such a powerful concept.</p> <h5 id="the-advanced-ml-course-a-brief-overview"><strong>The Advanced ML Course: A Brief Overview</strong></h5> <p>The course takes a deeply theoretical approach, focusing on critical analysis and research to build innovative machine learning algorithms. It’s not just about solving problems but about challenging established ideas, learning from mistakes, and having the courage to be wrong. Confusion, in this context, is not a roadblock—it’s a catalyst for deeper thinking.</p> <p>Two primary domains form the core of present ML/AI space:</p> <ol> <li> <strong>Neural Networks</strong>: The cornerstone of modern machine learning.</li> <li> <strong>Online Learning</strong>: A versatile and influential approach with deep connections to game theory and optimization.</li> </ol> <h4 id="what-is-online-learning"><strong>What is Online Learning?</strong></h4> <p>Online learning stands out as an area of machine learning with rich literature and numerous practical applications. It bridges the gap between supervised learning and game-theoretic optimization while offering efficient solutions for large-scale problems.</p> <p>Unlike traditional batch learning, where algorithms process the entire dataset at once, online learning operates iteratively, processing one sample at a time. This makes it computationally efficient and ideal for large datasets. Moreover, online learning does not rely on the common assumption that data points are independent and identically distributed (i.i.d.). Instead, it is designed to handle adversarial scenarios, making it incredibly flexible and applicable to situations where data distributions are unknown or variable.</p> <p>Even though these algorithms are inherently designed for adversarial settings, they can, under specific conditions, yield accurate predictions in scenarios where data does follow a distribution.</p> <p><strong>What do we mean by adversarial in the context of online learning?</strong></p> <p>In online learning, “adversarial” refers to settings where data is not assumed to follow a fixed probabilistic distribution. Instead, the data sequence might be unpredictable, dependent, or deliberately chosen to challenge the algorithm. This flexibility makes online learning particularly robust in real-world applications.</p> <ul> <li> <strong>Real-world Examples</strong>: <ul> <li> <strong>Financial Models</strong>: Adapting to volatile or externally influenced stock price movements.</li> <li> <strong>Recommendation Systems</strong>: Managing biased or strategically influenced user feedback.</li> <li> <strong>Security Systems</strong>: Responding to data manipulations or malicious attacks.</li> </ul> </li> </ul> <p>By focusing on resilience and adaptability, online learning algorithms excel in handling evolving data and challenging environments, making them indispensable for a wide range of applications.</p> <h5 id="why-online-learning"><strong>Why Online Learning?</strong></h5> <p>Traditional machine learning approaches often rely on the PAC (Probably Approximately Correct) framework, where:</p> <ul> <li>The data distribution remains fixed over time.</li> <li>Both training and testing data are assumed to follow the same i.i.d. distribution.</li> </ul> <p><strong>What is the PAC Learning Framework?</strong></p> <p>The PAC learning framework provides a theoretical foundation for understanding the feasibility of learning in a probabilistic setting. Under this framework:</p> <ul> <li>The algorithm’s goal is to find a hypothesis that is <em>probably approximately correct</em>, meaning it performs well on the training data and generalizes to unseen data with high probability.</li> <li>It assumes that data points are drawn independently and identically distributed (i.i.d.) from a fixed, unknown distribution.</li> <li>Key metrics include the error rate of the hypothesis on future samples and its convergence to the true distribution as more data is provided.</li> </ul> <p>While this framework is powerful for traditional batch learning, it relies on strong assumptions about the stability and predictability of the data distribution, making it less suitable for dynamic or adversarial scenarios.</p> <p>In contrast, online learning assumes no such distributional stability. It operates under the following key principles:</p> <ul> <li> <strong>No Assumptions on Data Distribution</strong>: The data can follow any sequence, including adversarially generated ones. This flexibility allows online learning to adapt to real-world scenarios where data patterns may shift unpredictably.</li> <li> <strong>Mixed Training and Testing</strong>: Training and testing are not separate phases but occur simultaneously, enabling the algorithm to continuously learn and improve from new data.</li> <li> <strong>Worst-Case Analysis</strong>: Algorithms are designed to perform well even under the most challenging conditions, ensuring robustness in unpredictable environments.</li> <li> <strong>Performance Metrics</strong>: Instead of accuracy or loss functions commonly used in batch learning, online learning evaluates performance using measures like: <ul> <li> <strong><em>Mistake Model</em></strong>: The total number of incorrect predictions made during the learning process.</li> <li> <strong><em>Regret</em></strong>: The difference between the cumulative loss of the algorithm and the loss of the best possible strategy in hindsight.</li> </ul> </li> </ul> <p><strong>What are some practical applications of online learning?</strong></p> <p>Online learning has proven invaluable in a variety of real-world domains where data is dynamic, unpredictable, or arrives sequentially:</p> <ol> <li> <strong>Stock Market Predictions</strong>: Continuously adapting to ever-changing financial data, helping traders and financial systems make real-time decisions.</li> <li> <strong>Online Advertising</strong>: Personalizing ads based on user behavior that evolves with every click or interaction.</li> <li> <strong>Recommendation Systems</strong>: Adapting suggestions in real time as users interact with platforms like Netflix, Amazon, or YouTube.</li> <li> <strong>Autonomous Systems</strong>: Enabling self-driving cars or robots to learn and adapt to new scenarios as they encounter them.</li> <li> <strong>Spam Filtering</strong>: Continuously updating filters to catch new spam types as they emerge.</li> <li> <strong>Security Systems</strong>: Responding to cyberattacks or new threats by learning and adapting on the fly.</li> </ol> <p>This shift in perspective allows online learning to address a broader range of real-world problems. For now, if all of this feels a bit abstract, don’t worry—hang tight! We’ll dive deeper and make sure to explore it thoroughly, leaving no stone unturned.</p> <h4 id="the-general-online-learning-framework"><strong>The General Online Learning Framework</strong></h4> <p>The online learning process follows a simple yet powerful framework. At each step:</p> <ol> <li>The algorithm receives an instance, denoted as \(x_t\).</li> <li>It makes a prediction, \(\hat{y}_t\).</li> <li>The true label, \(y_t\), is revealed.</li> <li>A loss is incurred, calculated as \(L(\hat{y}_t, y_t)\), which quantifies the prediction error.</li> </ol> <p>The overarching goal of online learning is to minimize the total loss over a sequence of predictions: \(\sum_{t=1}^T L(\hat{y}_t, y_t)\)</p> <p>For classification tasks, a common choice of loss is the 0-1 loss: \(L(\hat{y}_t, y_t) = \mathbb{1}(\hat{y}_t \neq y_t) \; or \; \vert \hat{y}_t - y_t \vert\) For regression tasks, the squared loss is often used: \(L(\hat{y}_t, y_t) = (\hat{y}_t - y_t)^2\)</p> <hr> <h4 id="prediction-with-expert-advice"><strong>Prediction with Expert Advice</strong></h4> <p>One particularly compelling framework in online learning is <strong>Prediction with Expert Advice</strong>. Imagine you have multiple “experts,” each providing advice on how to predict the label for a given instance. The challenge lies in aggregating their advice to make accurate predictions while minimizing the regret associated with poor decisions.</p> <p>The process unfolds as follows:</p> <ol> <li>At each time step, the algorithm receives an instance, \(x_t\), and predictions from \(N\) experts, \(\{y_{t,1}, y_{t,2}, \dots, y_{t,N}\}\).</li> <li>Based on this advice, the algorithm predicts \(\hat{y}_t\).</li> <li>The true label, \(y_t\), is revealed, and the loss, \(L(\hat{y}_t, y_t)\), is incurred.</li> </ol> <p>The performance of the algorithm is measured by its <strong><em>regret</em></strong>, which is the difference between the total loss incurred by the algorithm and the total loss of the best-performing expert:</p> \[\text{Regret}(T) = \sum_{t=1}^T L(\hat{y}_t, y_t) - \min_{i=1, \dots, N} \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\] <p>Minimizing regret ensures that the algorithm’s predictions improve over time and closely approximate the performance of the best expert.</p> <p><strong>What does the regret equation convey and how do we interpret it?</strong></p> <p>The regret equation provides a way to evaluate the algorithm’s performance in hindsight by comparing it to the best expert. Here’s what each term means:</p> <ol> <li> <p><strong>Algorithm’s Loss</strong> (\(\sum_{t=1}^T L(\hat{y}_t, y_t)\)):<br> This is the cumulative loss incurred by the algorithm over \(T\) time steps. It reflects how well the algorithm performs when making predictions based on the aggregated advice of all experts.</p> </li> <li> <p><strong>Best Expert’s Loss</strong> (\(\min_{i=1, \dots, N} \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\)):<br> This represents the cumulative loss of the single best-performing expert in hindsight. Note that the best expert is identified after observing all \(T\) instances, which gives it an advantage over the algorithm that has to predict in real time.</p> </li> <li> <p><strong>Regret</strong>:<br> The difference between these two terms quantifies how much worse the algorithm performs compared to the best expert.</p> <ul> <li> <strong>Low regret</strong> indicates that the algorithm’s predictions are close to those of the best expert, demonstrating effective learning.</li> <li> <strong>High regret</strong> suggests that the algorithm is failing to learn effectively from the experts’ advice.</li> </ul> </li> </ol> <p><strong>Why is regret important?</strong></p> <p>Regret is a crucial metric in online learning because:</p> <ul> <li>It provides a measure of how well the algorithm adapts to the expert advice over time.</li> <li>It ensures that, as the number of time steps \(T\) increases, the algorithm’s performance converges to that of the best expert (ideally achieving sublinear regret, such as \(O(\sqrt{T})\) or better).</li> <li>It accounts for the dynamic nature of predictions, focusing on learning improvement rather than static accuracy.</li> </ul> <p>A few more questions to make our understadning better.</p> <p><strong>How to Calculate the Best Expert’s Loss?</strong></p> <p>The <strong>Best Expert’s Loss</strong> is the cumulative loss of the single expert that performs best over the entire sequence of predictions, \(T\). Here’s how to calculate it:</p> <ol> <li> <p><strong>Track each expert’s cumulative loss</strong>:<br> For each expert \(i\), maintain a running sum of their losses over the rounds:</p> \[L_{\text{expert } i} = \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\] <p>Here, \(\hat{y}_{t,i}\) is the prediction made by expert \(i\) at time \(t\), and \(y_t\) is the true label. \(L\) could represent any loss function, such as zero-one loss or squared loss.</p> </li> <li> <p><strong>Find the expert with the minimum cumulative loss</strong>:<br> After summing the losses for all \(N\) experts over \(T\) rounds, identify the expert whose cumulative loss is the smallest:</p> \[\min_{i=1, \dots, N} \sum_{t=1}^T L(\hat{y}_{t,i}, y_t)\] <p>This value represents the <strong>Best Expert’s Loss</strong>, which serves as the benchmark for evaluating the algorithm’s regret.</p> </li> </ol> <p><strong>Do We Pick the Best Expert After Each Round?</strong></p> <p>No, the <strong>Best Expert’s Loss</strong> is determined in hindsight, <strong><em>after</em></strong> observing the entire sequence of \(T\) rounds. The algorithm does not know in advance which expert is the best. Instead, it aggregates predictions from all experts during the process (e.g., using techniques like weighted averaging).</p> <ul> <li>The <strong>best expert</strong> is identified retrospectively after all rounds.</li> <li>The cumulative loss of this best expert is used to compute regret.</li> </ul> <p><strong>Example:</strong></p> <p>Suppose we have 3 experts, and their losses over 5 rounds are:</p> <table> <thead> <tr> <th>Round (t)</th> <th>Expert 1 Loss</th> <th>Expert 2 Loss</th> <th>Expert 3 Loss</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>0.2</td> <td>0.3</td> <td>0.1</td> </tr> <tr> <td>2</td> <td>0.1</td> <td>0.4</td> <td>0.2</td> </tr> <tr> <td>3</td> <td>0.3</td> <td>0.2</td> <td>0.3</td> </tr> <tr> <td>4</td> <td>0.4</td> <td>0.1</td> <td>0.3</td> </tr> <tr> <td>5</td> <td>0.2</td> <td>0.5</td> <td>0.1</td> </tr> </tbody> </table> <ol> <li> <strong>Calculate the cumulative loss for each expert</strong>: <ul> <li> <strong>Expert 1</strong>: \(0.2 + 0.1 + 0.3 + 0.4 + 0.2 = 1.2\)</li> <li> <strong>Expert 2</strong>: \(0.3 + 0.4 + 0.2 + 0.1 + 0.5 = 1.5\)</li> <li> <strong>Expert 3</strong>: \(0.1 + 0.2 + 0.3 + 0.3 + 0.1 = 1.0\)</li> </ul> </li> <li> <p><strong>Find the minimum cumulative loss</strong>: \(\min(1.2, 1.5, 1.0) = 1.0\)</p> <p>Hence, the <strong>Best Expert’s Loss</strong> is <strong>1.0</strong>, achieved by Expert 3.</p> </li> </ol> <p>Prediction with Expert Advice is a powerful framework for dynamic environments where multiple sources of information or strategies need to be combined effectively. It ensures robustness and adaptability by iteratively improving predictions while minimizing regret.</p> <hr> <h4 id="the-halving-algorithm-simple-and-powerful"><strong>The Halving Algorithm: Simple and Powerful</strong></h4> <p>The <strong>Halving Algorithm</strong> is a simple yet effective online learning algorithm designed to minimize mistakes. It works by maintaining a set of hypotheses (or experts) and systematically eliminating those that make incorrect predictions.</p> <p>Here’s how it works:</p> <ol> <li> <strong>Initialization</strong>: Start with a set of hypotheses, \(H_1 = H\).</li> <li> <strong>Iteration</strong>: At each time step, \(t\): <ul> <li>Receive an instance, \(x_t\).</li> <li>Predict the label, \(\hat{y}_t\), using majority voting among the hypotheses in \(H_t\).</li> <li>Receive the true label, \(y_t\).</li> <li>If \(\hat{y}_t \neq y_t\), update the hypothesis set: \(H_{t+1} = \{h \in H_t : h(x_t) = y_t\}\)</li> </ul> </li> <li> <strong>Termination</strong>: After all iterations, return the final hypothesis set, \(H_{T+1}\).</li> </ol> <h5 id="mistake-bound-for-the-halving-algorithm"><strong>Mistake Bound for the Halving Algorithm</strong></h5> <p><strong>Theorem</strong>: If the initial hypothesis set \(H\) is finite, the number of mistakes made by the Halving Algorithm is bounded by:</p> \[M_{Halving(H)} \leq \log_2 |H|\] <p><strong>Proof Outline</strong>:</p> <ul> <li>Each mistake reduces the size of the hypothesis set by at least half: \(|H_{t+1}| \leq \frac{|H_t|}{2}\)</li> <li>Initially, \(|H_1| = |H|\). After \(M\) mistakes: \(|H_{M+1}| \leq \frac{|H|}{2^M}\)</li> <li>To ensure \(|H_{M+1}| \geq 1\) (at least one hypothesis remains), we require: \(M \leq \log_2 |H|\)</li> </ul> <p>This logarithmic bound demonstrates the efficiency of the Halving Algorithm, even in adversarial settings.</p> <hr> <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>Online learning offers a powerful framework for making predictions in dynamic and adversarial environments. Its ability to adapt, operate under minimal assumptions, and deliver robust performance makes it a cornerstone of modern machine learning research. The Halving Algorithm provides a concrete example of how online learning methods can be both intuitive and theoretically grounded.</p> <p>In upcoming posts, we’ll delve deeper into other online learning algorithms and explore their theoretical guarantees, practical applications, and connections to broader machine learning principles. Stay tuned!</p> <h5 id="references"><strong>References</strong></h5> <ul> <li><a href="https://www.cs.utexas.edu/~klivans/f06lec2.pdf" rel="external nofollow noopener" target="_blank">The PAC Learning Model</a></li> <li> <a href="https://arxiv.org/pdf/1912.13213" rel="external nofollow noopener" target="_blank">A Modern Introduction to Online Learning</a> [To Check]</li> <li> <a href="https://haipeng-luo.net/courses/CSCI659/2022_fall/lectures/lecture1.pdf" rel="external nofollow noopener" target="_blank">Overview of Online Learning</a> [To Read]</li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-structured-perceptron-amp-structured-svm",title:"Structured Perceptron &amp; Structured SVM",description:"Understanding how Structured Perceptron and Structured SVM learn to predict structured outputs with interdependent components.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-perceptron-svm/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>