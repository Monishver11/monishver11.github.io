<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> An Introduction to Generative Models - Naive Bayes for Binary Features | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%A5&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/generative-models/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">An Introduction to Generative Models - Naive Bayes for Binary Features</h1> <p class="post-meta"> Created in January 20, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Generative models represent a powerful class of machine learning techniques. Unlike methods that directly map inputs \(x\) to outputs \(y\), such as generalized linear models or perceptrons, generative models take a broader approach. They aim to model the <strong>joint distribution</strong> \(p(x, y; \theta)\), which allows us to capture the underlying relationships between inputs and outputs in a holistic manner.</p> <h4 id="generalized-linear-models-vs-generative-models"><strong>Generalized Linear Models vs. Generative Models</strong></h4> <p>To recall, generalized linear models focus on the conditional distribution \(p(y \mid x; \theta)\). By contrast, generative models model \(p(x, y; \theta)\). Once we have the joint distribution, we can predict labels for new data by leveraging the following rule:</p> \[\hat{y} = \arg\max_{y \in \mathcal{Y}} p(x, y; \theta)\] <p>This prediction process connects naturally to conditional distributions. Using <strong>Bayes’ Rule</strong>, we can rewrite \(p(y \mid x)\) as:</p> \[p(y \mid x) = \frac{p(x \mid y) p(y)}{p(x)}\] <p>In practice, we often bypass computing \(p(x)\), as it is independent of \(y\). Instead, predictions simplify to:</p> \[\hat{y} = \arg\max_{y} p(y \mid x) = \arg\max_{y} p(x \mid y) p(y)\] <p>With this foundation, let us explore one of the most straightforward and widely used generative models: <strong>Naive Bayes (NB)</strong>.</p> <p>If you’re unable to follow the above formulation, here’s a quick refresher on Bayes’ Rule to help you out.</p> <p>Bayes’ Rule relates conditional probabilities to joint and marginal probabilities. It can be expressed as:</p> \[p(y \mid x) = \frac{p(x, y)}{p(x)} = \frac{p(x \mid y) p(y)}{p(x)},\] <p>where:</p> <ul> <li>\(p(y \mid x)\): Posterior probability of \(y\) given \(x\),</li> <li>\(p(x, y)\): Joint probability of \(x\) and \(y\),</li> <li>\(p(x \mid y)\): Likelihood of \(x\) given \(y\),</li> <li>\(p(y)\): Prior probability of \(y\),</li> <li>\(p(x)\): Marginal probability of \(x\), which ensures proper normalization.</li> </ul> <hr> <h4 id="naive-bayes-a-simple-and-effective-generative-model"><strong>Naive Bayes: A Simple and Effective Generative Model</strong></h4> <p>To understand Naive Bayes, consider a simple yet practical problem: binary text classification. Imagine we want to classify a document as either a <strong>fake review</strong> or a <strong>genuine review</strong>. This setup offers a clear context to explore the mechanics of generative modeling.</p> <h5 id="representing-documents-as-features"><strong>Representing Documents as Features</strong></h5> <p>To make this task computationally feasible, we use a <strong>bag-of-words representation</strong>. A document is expressed as a binary vector \(x\), where:</p> \[x = [x_1, x_2, \dots, x_d].\] <p>Here, \(d\) represents the vocabulary size, and each \(x_i\) indicates whether the \(i\)-th word in the vocabulary exists in the document (\(x_i = 1\)) or not (\(x_i = 0\)).</p> <h5 id="modeling-the-joint-probability-of-documents-and-labels"><strong>Modeling the Joint Probability of Documents and Labels</strong></h5> <p>For a document \(x\) with label \(y\), the joint probability \(p(x, y)\) can be expressed using the <strong>chain rule of probability</strong>:</p> \[p(x \mid y) = p(x_1, x_2, \dots, x_d \mid y) = p(x_1 \mid y) p(x_2 \mid y, x_1) \cdots p(x_d \mid y, x_{d-1}, \dots, x_1).\] \[p(x \mid y) = \prod_{i=1}^d p(x_i \mid y, x_{&lt;i}),\] <p>However, modeling the dependencies between features (\(x_1, x_2, \dots, x_d\)) becomes intractable as the number of features grows and hard to estimate. This is where Naive Bayes introduces its defining assumption.</p> <h5 id="the-naive-bayes-assumption"><strong>The Naive Bayes Assumption</strong></h5> <p>Naive Bayes simplifies the problem by assuming that <strong>features are conditionally independent given the label \(y\)</strong>. Mathematically, this means:</p> \[p(x \mid y) = \prod_{i=1}^d p(x_i \mid y)\] <p>This assumption significantly reduces computational complexity while often delivering excellent results in practice. While the assumption of conditional independence may not hold in all cases, it is surprisingly effective in many real-world applications.</p> <hr> <h4 id="parameterizing-the-naive-bayes-model"><strong>Parameterizing the Naive Bayes Model</strong></h4> <p>To make predictions, we need to parameterize the probabilities \(p(x_i \mid y)\) and \(p(y)\).</p> <p><strong><em>Why?</em></strong> Parameterizing these distributions allows us to learn the necessary values (e.g., \(\theta\)) from data in a structured way.</p> <h5 id="binary-features"><strong>Binary Features</strong></h5> <p>For simplicity, let us assume the features \(x_i\) are binary (\(x_i \in \{0, 1\}\)). We model \(p(x_i \mid y)\) as Bernoulli distributions:</p> \[p(x_i = 1 \mid y = 1) = \theta_{i,1}, \quad p(x_i = 1 \mid y = 0) = \theta_{i,0}\] <p>Similarly, the label distribution is modeled as:</p> \[p(y = 1) = \theta_0\] <p><strong><em>How do we arrive at these definitions?</em></strong> These definitions arise from the following assumptions and modeling principles:</p> <ol> <li> <strong>Binary Nature of Features</strong>: Since the features \(x_i\) are binary (\(x_i \in \{0, 1\}\)), we need a probability distribution that models the likelihood of binary outcomes. The Bernoulli distribution is a natural choice for this.</li> <li> <strong>Parameterization with Bernoulli Distributions</strong>: <ul> <li>For \(p(x_i \mid y)\), the Bernoulli distribution models the probability that \(x_i = 1\) for each possible value of \(y\).</li> <li>We introduce parameters \(\theta_{i,1}\) and \(\theta_{i,0}\), which represent the probability of \(x_i = 1\) given \(y = 1\) and \(y = 0\), respectively.</li> </ul> </li> <li> <strong>Label Distribution \(p(y)\)</strong>: <ul> <li>The label \(y\) is also binary (\(y \in \{0, 1\}\)), so we model \(p(y)\) using a Bernoulli distribution with a single parameter \(\theta_0\), where \(\theta_0 = p(y = 1)\).</li> <li>This parameter reflects the prior probability of the positive class.</li> </ul> </li> <li> <strong>Learning from Data</strong>: These parameters (\(\theta_{i,1}, \theta_{i,0}, \theta_0\)) are learned from data using methods like Maximum Likelihood Estimation (MLE), ensuring that the model reflects the observed distribution of features and labels in the dataset.</li> </ol> <p>Thus, the definitions provide a straightforward and interpretable way to model binary features and labels within the Naive Bayes framework.</p> <p>With these definitions, the joint probability \(p(x, y)\) can be written as (<strong>with NB assumption</strong>):</p> \[p(x, y) = p(y) \prod_{i=1}^d p(x_i \mid y)\] <p>Substituting the probabilities for binary features:</p> \[p(x, y) = p(y) \prod_{i=1}^d \theta_{i,y}{\mathbb{I}\{x_i = 1\}} + (1 - \theta_{i,y}){\mathbb{I}\{x_i = 0\}}\] <p>Here, \(\mathbb{I}\{\text{condition}\}\) is an indicator function that evaluates to 1 if the condition is true and 0 otherwise.</p> <p><strong><em>How to intuitively understand this equation?</em></strong> This equation represents the joint probability \(p(x, y)\) by combining the prior probability \(p(y)\) with the product of the individual probabilities \(p(x_i \mid y)\) for each feature \(x_i\). Here:</p> <ol> <li>For each feature \(x_i\), the term \(\mathbb{I}\{x_i = 1\}\) ensures that the corresponding parameter \(\theta_{i,y}\) is used if \(x_i = 1\), while \(\mathbb{I}\{x_i = 0\}\) ensures that \((1 - \theta_{i,y})\) is used if \(x_i = 0\).</li> <li>The product \(\prod_{i=1}^d\) combines the contributions of all features under the Naive Bayes assumption of conditional independence.</li> <li>Finally, multiplying by \(p(y)\) incorporates the prior belief about the label \(y\), providing the full joint distribution \(p(x, y)\).</li> </ol> <p>By this decomposition, we can efficiently compute \(p(x, y)\) for classification tasks.</p> <hr> <h4 id="learning-parameters-with-maximum-likelihood-estimation-mle"><strong>Learning Parameters with Maximum Likelihood Estimation (MLE)</strong></h4> <p>The parameters \(\theta\) of the Naive Bayes model are learned by maximizing the likelihood of the observed data. Given a dataset of \(N\) labeled examples \(\{(x^{(n)}, y^{(n)})\}_{n=1}^N\), the likelihood of the data is:</p> \[\prod_{n=1}^N p_\theta(x^{(n)}, y^{(n)})\] <p>Taking the logarithm of the likelihood to simplify optimization, we obtain the log-likelihood:</p> \[\ell(\theta) = \sum_{n=1}^N \log p_\theta(x^{(n)}, y^{(n)})\] <p>For binary features, substituting the joint probability \(p_\theta(x, y)\) (as defined earlier) gives:</p> \[\ell(\theta) = \sum_{n=1}^N \left[ \sum_{i=1}^d \log ( \mathbb{I}\{x_i^{(n)} = 1\} \theta_{i,y^{(n)}} + \mathbb{I}\{x_i^{(n)} = 0\} (1 - \theta_{i,y^{(n)}}) ) \right] + \log p_\theta(y^{(n)})\] <p>Focusing on a specific feature \(x_j\) and label \(y = 1\), the relevant portion of the log-likelihood is:</p> \[\ell(\theta) = \sum_{n=1}^N \log \left[ \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\} \theta_{j,1} + \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 0\} (1 - \theta_{j,1}) \right] \tag{1}\] <p><strong>Step 1: Derivative of the Log-Likelihood</strong></p> <p>Taking the derivative of the log-likelihood with respect to \(\theta_{j,1}\):</p> \[\frac{\partial \ell}{\partial \theta_{j,1}} = \sum_{n=1}^N \left[ \frac{\mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\}}{\theta_{j,1}} - \frac{\mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 0\}}{1 - \theta_{j,1}} \right] \tag{2}\] <p><strong>Did you follow the derivative?</strong> You might be wondering how derivative \(\log(a + b)\) can be written as \(\frac{1}{a} + \frac{1}{b}\), right? If so, that’s a completely valid question — I had the same thought myself. Here’s the explanation.</p> <p>The transition from equation (1) to equation (2) involves taking the derivative of the log-likelihood with respect to \(\theta_{j,1}\). Let’s break it down:</p> \[\frac{\partial}{\partial \theta_{j,1}} \ell = \frac{\partial}{\partial \theta_{j,1}} \sum_{n=1}^{N} \left[ \log \left( \theta_{j,1} I\{ x_j(n) = 1 \} + (1 - \theta_{j,1}) I\{ x_j(n) = 0 \} \right) \right]\] <p>Here, the derivative is applied to the logarithm term. Using the chain rule, we first compute the derivative of the logarithm, which is:</p> \[\frac{\partial}{\partial \theta_{j,1}} \log(f(\theta_{j,1})) = \frac{1}{f(\theta_{j,1})} \cdot \frac{\partial f(\theta_{j,1})}{\partial \theta_{j,1}},\] <p>where</p> \[f(\theta_{j,1}) = \theta_{j,1} I\{ x_j(n) = 1 \} + (1 - \theta_{j,1}) I\{ x_j(n) = 0 \}.\] <p>For a single \(n\), the term inside the logarithm is:</p> \[f(\theta_{j,1}) = \begin{cases} \theta_{j,1}, &amp; \text{if } x_j(n) = 1, \\ 1 - \theta_{j,1}, &amp; \text{if } x_j(n) = 0. \end{cases}\] <p>The derivative of \(f(\theta_{j,1})\) with respect to \(\theta_{j,1}\) is:</p> \[\frac{\partial f(\theta_{j,1})}{\partial \theta_{j,1}} = \begin{cases} 1, &amp; \text{if } x_j(n) = 1, \\ -1, &amp; \text{if } x_j(n) = 0. \end{cases}\] <p>Using the chain rule:</p> \[\frac{\partial}{\partial \theta_{j,1}} \log(f(\theta_{j,1})) = \begin{cases} \frac{1}{\theta_{j,1}}, &amp; \text{if } x_j(n) = 1, \\ \frac{-1}{1 - \theta_{j,1}}, &amp; \text{if } x_j(n) = 0. \end{cases}\] <p>Applying this to the summation over \(N\):</p> \[\frac{\partial}{\partial \theta_{j,1}} \ell = \sum_{n=1}^{N} \left[ I\{ y(n) = 1 \land x_j(n) = 1 \} \frac{1}{\theta_{j,1}} - I\{ y(n) = 1 \land x_j(n) = 0 \} \frac{1}{1 - \theta_{j,1}} \right].\] <p>This is exactly what equation (48) represents, showing the decomposition of the derivative into two terms for \(x_j(n) = 1\) and \(x_j(n) = 0\).</p> <p>The simplification uses the indicator functions \(I\) to select the appropriate cases, where:</p> \[I\{ x_j(n) = 1 \} \quad \text{contributes} \quad \frac{1}{\theta_{j,1}},\] <p>and</p> \[I\{ x_j(n) = 0 \} \quad \text{contributes} \quad \frac{1}{1 - \theta_{j,1}}.\] <p><strong>Key Insight:</strong></p> <p>At each step of the derivation, we are dealing with a <strong>single term</strong> inside the logarithm. As a result, when we take the derivative of the logarithm, the result is simply \(\frac{1}{\text{term}}\), where the term is either \(\theta_{j,1}\) or \(1 - \theta_{j,1}\), depending on the value of \(x_j(n)\).</p> <ul> <li>If \(x_j(n) = 1\), the term inside the log is \(\theta_{j,1}\), and its derivative is \(\frac{1}{\theta_{j,1}}\).</li> <li>If \(x_j(n) = 0\), the term inside the log is \(1 - \theta_{j,1}\), and its derivative is \(\frac{-1}{1 - \theta_{j,1}}\).</li> </ul> <p>Thus, at each \(n\), we compute the derivative as \(\frac{1}{\text{term}}\), with the specific term depending on the value of \(x_j(n)\). This makes the process more straightforward as we apply it term by term across all \(N\) data points.</p> <p>I hope that makes sense now. Let’s continue.</p> <p><strong>Step 2: Setting the Derivative to Zero</strong></p> <p>To find the maximum likelihood estimate, we set the derivative to zero:</p> \[\sum_{n=1}^N \left[ \frac{\mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\}}{\theta_{j,1}} \right] = \sum_{n=1}^N \left[ \frac{\mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 0\}}{1 - \theta_{j,1}} \right]\] <p>Simplifying:</p> \[\theta_{j,1} \sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \} = \sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\}\] <p>The above simplification is quite straightforward. I encourage you to write it out for yourself and work through the steps. Simply <strong>multiply both sides</strong> by \(\theta_{j,1}(1 - \theta_{j,1})\) to eliminate the denominators, then expand both sides and <strong>isolate</strong> \(\theta_{j,1}\).</p> <p><strong>Note</strong>:</p> \[\sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\} + \sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 0\} = \sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \}\] <p><strong>Step 3: Solving for \(\theta_{j,1}\)</strong></p> <p>Rearranging to isolate \(\theta_{j,1}\):</p> \[\theta_{j,1} = \frac{\sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1 \wedge x_j^{(n)} = 1\}}{\sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1\}}\] <p><strong>Interpretation:</strong> This estimate corresponds to the fraction of examples with \(y = 1\) in which the \(j\)-th feature \(x_j\) is active (i.e., \(x_j = 1\)). Intuitively, it represents the conditional probability \(p(x_j = 1 \mid y = 1)\) under the Naive Bayes assumption.</p> <hr> <h5 id="next-steps"><strong>Next Steps:</strong></h5> <ol> <li> <p><strong>Compute the other \(\theta_{i,y}\) values</strong>: You should calculate the parameters for all other features in the model (for example, \(\theta_{i,0}\) and \(\theta_{i,1}\) for binary features). These values represent the probability of a feature given a class, so you’ll continue by maximizing the likelihood for each \(i\) and class \(y\) to estimate these parameters.</p> </li> <li> <p><strong>Estimate \(p(y)\)</strong>: You’ll also need to compute the class prior probability \(p(y)\), which is simply the proportion of each class in the training data. This can be done by counting how many times each class label appears and normalizing by the total number of examples.</p> </li> </ol> \[\theta_0 = \frac{\sum_{n=1}^N \mathbb{I}\{y^{(n)} = 1\}}{N}\] <ul> <li>\(\theta_0\) is the proportion of samples in the dataset that belong to the class \(y = 1\).</li> <li>It serves as the prior probability of \(y = 1\).</li> </ul> <p><strong>Substituting the Probabilities for Binary Features:</strong></p> <p>The likelihood of the joint probability \(p(x, y)\) can be expressed as:</p> \[p(x, y) = p(y) \prod_{i=1}^d \theta_{i,y} {\mathbb{I}\{x_i = 1\}} + (1 - \theta_{i,y}) {\mathbb{I}\{x_i = 0\}}\] <p>Where \(\mathbb{I}\{x_i = 1\}\) is an indicator function that equals 1 when \(x_i = 1\), and \(\mathbb{I}\{x_i = 0\}\) equals 1 when \(x_i = 0\).</p> <p><strong>Remember this equation; it’s the one we started with.</strong></p> <p>Once all parameters are estimated, you will have a fully parameterized Naive Bayes model. The model can then be used for prediction by computing the posterior probabilities for each class \(y\) given an input \(x\). For prediction, you would use the formula:</p> \[\hat{y} = \arg\max_{y \in Y} p(y) \prod_{i=1}^d p(x_i \mid y)\] <p>Where \(p(x_i \mid y)\) are the feature likelihoods, and \(p(y)\) is the class prior. The class with the highest posterior probability is chosen as the predicted label. This approach allows Naive Bayes to make efficient, probabilistic predictions based on the learned parameters.</p> <p><strong>So, the fundamental idea is:</strong></p> <p>You are estimating the parameters \(\theta\) for all possible features and classes. Once the parameters are learned, you apply Bayes’ rule to compute the posterior probability for each class \(y\). Finally, you take the class that maximizes the posterior probability using:</p> \[\hat{y} = \arg\max_y p(y \mid x)\] <p>This gives you the predicted class \(\hat{y}\), based on the learned parameters from the training data.</p> <hr> <h5 id="recipe-for-learning-a-naive-bayes-model"><strong>Recipe for Learning a Naive Bayes Model:</strong></h5> <ol> <li> <strong>Choose \(p(x_i \mid y)\)</strong>: Select an appropriate distribution for the features, e.g., Bernoulli distribution for binary features \(x_i\).</li> <li> <strong>Choose \(p(y)\)</strong>: Typically, use a categorical distribution for the class labels.</li> <li> <strong>Estimate Parameters by MLE</strong>: Use Maximum Likelihood Estimation (MLE) to estimate the parameters, following the same strategy used in conditional models.</li> </ol> <h5 id="where-do-we-go-from-here"><strong>Where Do We Go From Here?</strong></h5> <p>So far, we have focused on modeling binary features. However, many real-world datasets involve continuous features. How can Naive Bayes be extended to handle such cases? In the next blog, we’ll explore Naive Bayes for continuous features and see how this simple model adapts to more complex data types. See you there!</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>