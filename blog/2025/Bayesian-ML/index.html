<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bayesian Machine Learning - Mathematical Foundations | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?e68e4955e21b20101db6e28a5a50abec"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/Bayesian-ML/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Bayesian Machine Learning - Mathematical Foundations</h1> <p class="post-meta"> Created in January 24, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> ¬† ¬∑ ¬† <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a> ¬† <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a> ¬† ¬∑ ¬† <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>When working with machine learning models, it‚Äôs crucial to understand the underlying statistical principles that drive our methods. Whether you‚Äôre a frequentist or a Bayesian, the starting point often involves a <strong>parametric family of densities</strong>. This concept forms the foundation for inference and is used to model the data we observe.</p> <h4 id="parametric-family-of-densities"><strong>Parametric Family of Densities</strong></h4> <p>A <strong>parametric family of densities</strong> is defined as a set</p> \[\{p(y \mid \theta) : \theta \in \Theta\},\] <p>where \(p(y \mid \theta)\) is a density function over some sample space \(Y\), and \(\theta\) represents a parameter in a finite-dimensional parameter space \(\Theta\).</p> <p>In simpler terms, this is a collection of probability distributions, each associated with a specific value of the parameter \(\theta\). When we refer to ‚Äúdensity,‚Äù it‚Äôs worth noting that this can be replaced with ‚Äúmass function‚Äù if we‚Äôre dealing with discrete random variables. Similarly, integrals can be replaced with summations in such cases.</p> <p>This framework is the common starting point for both <strong>classical statistics</strong> and <strong>Bayesian statistics</strong>, as it provides a structured way to think about modeling the data.</p> <h5 id="frequentist-or-classical-statistics"><strong>Frequentist or ‚ÄúClassical‚Äù Statistics</strong></h5> <p>In frequentist statistics, we also work with the parametric family of densities \(\{p(y \mid \theta) : \theta \in \Theta\}\), assuming that the true distribution \(p(y \mid \theta)\) governs the world we observe. This means there exists some unknown parameter \(\theta \in \Theta\) that determines the true nature of the data.</p> <p>If we had direct access to this true parameter \(\theta\), we wouldn‚Äôt need statistics at all! However, in practice, we only have a dataset, denoted as</p> \[D = \{y_1, y_2, \dots, y_n\},\] <p>where each \(y_i\) is sampled independently from the true distribution \(p(y \mid \theta)\).</p> <p>This brings us to the heart of statistics: <strong>how do we make inferences about the unknown parameter \(\theta\) using only the observed data \(D\)?</strong></p> <h5 id="point-estimation"><strong>Point Estimation</strong></h5> <p>One fundamental problem in statistics is <strong>point estimation</strong>, where the goal is to estimate the true value of the parameter \(\theta\) as accurately as possible.</p> <p>To do this, we use a <strong>statistic</strong>, denoted as \(s = s(D)\), which is simply a function of the observed data. When this statistic is designed to estimate \(\theta\), we call it a <strong>point estimator</strong>, represented as \(\hat{\theta} = \hat{\theta}(D)\).</p> <p>A <strong>good point estimator</strong> is one that is both:</p> <ul> <li> <strong>Consistent</strong>: As the sample size \(n\) grows larger, the estimator \(\hat{\theta}_n\) converges to the true parameter \(\theta\).</li> <li> <strong>Efficient</strong>: The estimator \(\hat{\theta}_n\) extracts the maximum amount of information about \(\theta\) from the data, achieving the best possible accuracy for a given sample size.</li> </ul> <p>One of the most popular methods for point estimation is the <strong>maximum likelihood estimator (MLE)</strong>. While we‚Äôve already covered it, let‚Äôs revisit it through a concrete example to reinforce our understanding.</p> <h5 id="example-coin-flipping-and-maximum-likelihood-estimation"><strong>Example: Coin Flipping and Maximum Likelihood Estimation</strong></h5> <p>Let‚Äôs consider the simple yet illustrative problem of estimating the probability of a coin landing on heads.</p> <p>Here, the parametric family of mass functions is given by:</p> \[p(\text{Heads} \mid \theta) = \theta, \quad \text{where } \theta \in \Theta = (0, 1).\] <p>The parameter \(\theta\) represents the probability of the coin landing on heads. Our goal is to estimate this parameter based on observed data.</p> <p>If this seems a bit confusing, seeing \(\theta\) in two places, let‚Äôs clarify it first.</p> <p>Imagine you have a coin, and you‚Äôre curious about how ‚Äúfair‚Äù it is. A perfectly fair coin has a 50% chance of landing heads or tails, but your coin might be biased. To capture this bias mathematically, you introduce a parameter, \(\theta\), which represents the probability of the coin landing on heads.</p> <p>We write this as:</p> \[p(\text{Heads} \mid \theta) = \theta\] <p>Let‚Äôs break this down with intuition:</p> <ol> <li> <strong>What does \(\theta\) mean?</strong><br> \(\theta\) is the coin‚Äôs ‚Äúpersonality.‚Äù For example: <ul> <li>If \(\theta = 0.8\), it means the coin ‚Äúloves‚Äù heads, and there‚Äôs an 80% chance it will land heads on any given flip.</li> <li>If \(\theta = 0.3\), the coin is biased toward tails, and there‚Äôs only a 30% chance of heads.</li> </ul> </li> <li> <p><strong>What does \(p(\text{Heads} \mid \theta) = \theta\) mean?</strong><br> This equation ties the probability of getting heads to the parameter \(\theta\). It‚Äôs like saying: ‚ÄúThe parameter \(\theta\) <em>is</em> the probability of heads.‚Äù For every coin flip, \(\theta\) directly determines the likelihood of heads.</p> </li> <li> <strong>Why is this useful?</strong><br> It simplifies modeling. Instead of treating each flip as random and unconnected, we assume there‚Äôs a fixed bias, \(\theta\), that governs the coin‚Äôs behavior. Once we observe enough flips (data), we can estimate \(\theta\) and predict future outcomes.</li> </ol> <p><strong>A relatable example might be‚Ä¶</strong></p> <p>Imagine a factory making coins with varying biases. Each coin is labeled with its bias, \(\theta\), ranging between 0 (always tails) and 1 (always heads). If you‚Äôre handed a coin without a label, your job is to figure out its bias by flipping it multiple times and observing the outcomes.</p> <p>This is the setup for the equation \(p(\text{Heads} \mid \theta) = \theta\). It tells us the coin‚Äôs behavior is entirely controlled by its bias, \(\theta\), and allows us to estimate it from observed data. <strong>Data and Likelihood Function</strong></p> <p>I hope that clears things up, and we‚Äôre good to proceed!</p> <hr> <p>Suppose we observe the outcomes of \(n\) independent coin flips, represented as:</p> \[D = (\text{H, H, T, T, T, T, T, H, ... , T}),\] <p>where \(n_h\) is the number of heads, and \(n_t\) is the number of tails. Since each flip is independent, the likelihood function for the observed data is:</p> \[L_D(\theta) = p(D \mid \theta) = \theta^{n_h} (1 - \theta)^{n_t}.\] <p><strong>Log-Likelihood and Optimization</strong></p> <p>Rather than working directly with the likelihood function, which involves products and can become cumbersome, we typically maximize the <strong>log-likelihood function</strong> for computational simplicity. The log-likelihood is:</p> \[\log L_D(\theta) = n_h \log \theta + n_t \log (1 - \theta).\] <p>The <strong>maximum likelihood estimate (MLE)</strong> of \(\theta\) is the value that maximizes this log-likelihood:</p> \[\hat{\theta}_{\text{MLE}} = \underset{\theta \in \Theta}{\text{argmax}} \, \log L_D(\theta).\] <p><strong>Derivation of the MLE</strong></p> <p>To find the MLE, we compute the derivative of the log-likelihood with respect to \(\theta\), set it to zero, and solve for \(\theta\):</p> \[\frac{\partial}{\partial \theta} \big[ n_h \log \theta + n_t \log (1 - \theta) \big] = \frac{n_h}{\theta} - \frac{n_t}{1 - \theta}.\] <p>Setting this derivative to zero:</p> \[\frac{n_h}{\theta} = \frac{n_t}{1 - \theta}.\] <p>Simplifying this equation gives:</p> \[\theta = \frac{n_h}{n_h + n_t}.\] <p>Thus, the MLE for \(\theta\) is:</p> \[\hat{\theta}_{\text{MLE}} = \frac{n_h}{n_h + n_t}.\] <p><strong>Intuition Behind the MLE</strong></p> <p>The result makes intuitive sense: the MLE simply calculates the proportion of heads observed in the data. It uses the empirical frequency as the best estimate of the true probability of heads, given the observed outcomes.</p> <hr> <p>While frequentist approaches like MLE provide a single ‚Äúbest‚Äù estimate for \(\theta\), Bayesian methods take a different perspective. Instead of finding a point estimate, Bayesian inference quantifies uncertainty about \(\theta\) using probability distributions. This leads to the concepts of <strong>prior distributions</strong> and <strong>posterior inference</strong>, which is what we‚Äôre going to explore next.</p> <h4 id="bayesian-statistics-an-introduction"><strong>Bayesian Statistics: An Introduction</strong></h4> <p>In the frequentist framework, the goal is to estimate the true parameter \(\theta\) using the observed data. However, <strong>Bayesian statistics</strong> takes a fundamentally different approach by introducing an important concept: the <strong>prior distribution</strong>. This addition allows us to explicitly incorporate prior beliefs about the parameter into our analysis and update them rationally as we observe new data.</p> <h5 id="the-prior-distribution-reflecting-prior-beliefs"><strong>The Prior Distribution: Reflecting Prior Beliefs</strong></h5> <p>A <strong>prior distribution</strong>, denoted as \(p(\theta)\), is a probability distribution over the parameter space \(\Theta\). It represents our belief about the value of \(\theta\) <strong>before</strong> observing any data. For instance, if we believe that \(\theta\) is more likely to lie in a specific range, we can encode this belief directly into the prior.</p> <h5 id="a-bayesian-model-combining-prior-and-data"><strong>A Bayesian Model: Combining Prior and Data</strong></h5> <p>A <strong>[parametric] Bayesian model</strong> is constructed from two key components:</p> <ol> <li>A <strong>parametric family of densities</strong> \(\{p(D \mid \theta) : \theta \in \Theta\}\) that models the likelihood of the observed data \(D\) given \(\theta\).</li> <li>A <strong>prior distribution</strong> \(p(\theta)\) on the parameter space \(\Theta\).</li> </ol> <p>These two components combine to form a <strong>joint density</strong> over \(\theta\) and \(D\):</p> \[p(D, \theta) = p(D \mid \theta) p(\theta).\] <p>This joint density encapsulates both the likelihood of the data and our prior beliefs about the parameter.</p> <h5 id="posterior-distribution-updating-beliefs"><strong>Posterior Distribution: Updating Beliefs</strong></h5> <p>The real power of Bayesian statistics lies in the ability to <strong>update prior beliefs</strong> after observing data. This is achieved through the <strong>posterior distribution</strong>, denoted as \(p(\theta \mid D)\).</p> <ul> <li>The <strong>prior distribution</strong> \(p(\theta)\) captures our initial beliefs about \(\theta\).</li> <li>The <strong>posterior distribution</strong> \(p(\theta \mid D)\) reflects our updated beliefs after observing the data \(D\).</li> </ul> <p>By applying <strong>Bayes‚Äô rule</strong>, we can express the posterior distribution as:</p> \[p(\theta \mid D) = \frac{p(D \mid \theta) p(\theta)}{p(D)},\] <p>where:</p> <ul> <li>\(p(D \mid \theta)\) is the <strong>likelihood</strong>, capturing how well \(\theta\) explains the observed data.</li> <li>\(p(\theta)\) is the <strong>prior</strong>, encoding our initial beliefs about \(\theta\).</li> <li>\(p(D)\) is a normalizing constant, ensuring the posterior integrates to 1.</li> </ul> <h5 id="simplifying-the-posterior"><strong>Simplifying the Posterior</strong></h5> <p>When analyzing the posterior distribution, we often focus on terms that depend on \(\theta\). Dropping constant factors that are independent of \(\theta\), we write:</p> \[p(\theta \mid D) \propto p(D \mid \theta) \cdot p(\theta),\] <p>where \(\propto\) denotes proportionality.</p> <p>In practice, this allows us to analyze and work with the posterior distribution more efficiently. For instance, the <strong>maximum a posteriori (MAP) estimate</strong> of \(\theta\) is given by:</p> \[\hat{\theta}_{\text{MAP}} = \underset{\theta \in \Theta}{\text{argmax}} \, p(\theta \mid D).\] <p><strong>A Way to Think About It:</strong></p> <p>A helpful way to think of Bayesian methods is to imagine you‚Äôre trying to predict the outcome of an event, but you have some prior knowledge (or beliefs) about it. For example, let‚Äôs say you‚Äôre predicting whether a student will pass an exam, and you have prior knowledge that most students in the class have been doing well. This prior belief can be represented as a probability distribution, which reflects how confident you are about the parameter (like the likelihood of passing).</p> <p>As you collect more data (say, the student‚Äôs past performance or study hours), Bayesian methods update your belief (the prior) to form a new, updated belief, called the <strong>posterior distribution</strong>. The more data you have, the more confident the posterior becomes about the true outcome.</p> <p>So, in essence:</p> <ul> <li> <strong>Prior distribution</strong> = What you believe before observing data (your initial guess).</li> <li> <strong>Likelihood</strong> = How the observed data might be related to your belief.</li> <li> <strong>Posterior distribution</strong> = Your updated belief after observing the data.</li> </ul> <p>In Bayesian inference, the goal is to calculate the posterior, which balances the prior belief with the observed data.</p> <hr> <h4 id="example-bayesian-coin-flipping"><strong>Example: Bayesian Coin Flipping</strong></h4> <p>Let‚Äôs revisit the coin-flipping example, but this time from a Bayesian perspective. We start with the parametric family of mass functions:</p> \[p(\text{Heads} \mid \theta) = \theta, \quad \text{where } \theta \in \Theta = (0, 1).\] <p>To complete our Bayesian model, we also need to specify a <strong>prior distribution</strong> over \(\theta\). One common choice is the <strong>Beta distribution</strong>, which is particularly convenient for this problem.</p> <h5 id="beta-prior-distribution"><strong>Beta Prior Distribution</strong></h5> <p>The Beta distribution, denoted as \(\text{Beta}(\alpha, \beta)\), is a flexible family of distributions defined on the interval \((0, 1)\). Its density function is:</p> \[p(\theta) \propto \theta^{\alpha - 1} (1 - \theta)^{\beta - 1}.\] <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Beta_Distribution-480.webp 480w,/assets/img/Beta_Distribution-800.webp 800w,/assets/img/Beta_Distribution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Beta_Distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Beta_Distribution" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>For our coin-flipping example, we can use:</p> \[p(\theta) \propto \theta^{h - 1} (1 - \theta)^{t - 1},\] <p>where \(h\) and \(t\) represent our prior ‚Äúcounts‚Äù of heads and tails, respectively.</p> <p>The <strong>mean</strong> of the Beta distribution is:</p> \[\mathbb{E}[\theta] = \frac{h}{h + t},\] <p>and its <strong>mode</strong> (for \(h, t &gt; 1\)) is:</p> \[\text{Mode} = \frac{h - 1}{h + t - 2}.\] <p><strong>A Way to Think of This Distribution:</strong></p> <p>Imagine you‚Äôre trying to estimate the probability of rain on a given day in a city you‚Äôve never visited. You don‚Äôt have any direct weather data yet, but you do have some general knowledge about the region. Based on this, you form an initial belief about how likely it is to rain‚Äîmaybe you‚Äôre unsure, so you assume it‚Äôs equally likely to rain or not, or maybe you‚Äôve heard that it‚Äôs usually dry there.</p> <ul> <li> <strong>The Beta distribution</strong> helps you represent this uncertainty. It‚Äôs like a flexible tool that encodes your prior beliefs about the probability of rain, and you can adjust these beliefs based on what you know or expect. <ul> <li>If you‚Äôre totally uncertain, you might use a <strong>uniform prior</strong> (where \(\alpha = \beta = 1\)), meaning you‚Äôre equally unsure whether rain is more likely or not.</li> <li>If you‚Äôve already heard that it tends to rain more often, say 70% of the time, you could choose \(\alpha = 7\) and \(\beta = 3\) to reflect this prior information.</li> </ul> </li> </ul> <p>As you gather more data‚Äîsay, after several days of weather observations‚Äîyou can update your beliefs about the likelihood of rain. Each new observation (rain or no rain) ‚Äúshapes‚Äù your distribution.</p> <ul> <li> <p><strong>The mean</strong> \(\mathbb{E}[\theta] = \frac{h}{h + t}\) represents the average likelihood of rain after considering all your prior knowledge and the observed days. This is your updated best guess about how likely it is to rain on any given day.</p> </li> <li> <p><strong>The mode</strong> \(\text{Mode} = \frac{h - 1}{h + t - 2}\), which reflects the most probable value of \(\theta\) after observing data, might give you a better estimate if the weather has shown a clear tendency over time (e.g., if it‚Äôs rained most days).</p> </li> </ul> <p>In essence, the Beta distribution allows you to start with an initial belief (or no belief) about the probability of rain, and as you observe more data, you continuously refine that belief. This is what makes Bayesian inference powerful‚Äîit enables you to <strong>update</strong> your beliefs rationally based on new evidence.</p> <p><strong>Why Use the Beta Prior Distribution in this Coin Flipping Problem?</strong></p> <p>The <strong>Beta distribution</strong> is particularly well-suited for modeling probabilities in Bayesian statistics, especially in problems like coin flipping. Here are a few reasons why it‚Äôs a good choice:</p> <ol> <li> <p><strong>Support on (0, 1):</strong> The Beta distribution is defined over the interval \(\theta \in (0, 1)\), which matches the range of possible values for \(\theta\) in the coin-flipping example. Since \(\theta\) represents the probability of getting heads, it must lie between 0 and 1.</p> </li> <li> <strong>Flexibility:</strong> The Beta distribution is very flexible in shaping its probability density. By adjusting the parameters \(\alpha\) and \(\beta\), we can model a wide variety of prior beliefs about \(\theta\): <ul> <li>When \(\alpha = \beta = 1\), the Beta distribution is uniform, indicating that we have no strong prior belief about whether heads or tails is more likely.</li> <li>When \(\alpha &gt; \beta\), the distribution is biased towards heads, and when \(\alpha &lt; \beta\), it is biased towards tails.</li> <li>The parameters can also reflect <strong>observed data</strong>: if you‚Äôve already seen \(h\) heads and \(t\) tails, the Beta distribution can be chosen with \(\alpha = h + 1\) and \(\beta = t + 1\), which matches the idea of ‚Äúupdating‚Äù your beliefs based on the data you observe.</li> </ul> </li> <li> <strong>Intuitive Interpretation:</strong> The Beta distribution is easy to interpret in terms of prior knowledge. The parameters \(\alpha\) and \(\beta\) can be seen as counts of prior observations of heads and tails, respectively. This makes it a natural choice when we have prior information or beliefs about the likelihood of different outcomes, and want to update them as new data comes in.</li> </ol> <p><strong>Note:</strong> I highly suggest taking a look at the Beta distribution graph. As \(\alpha\) increases, the distribution tends to skew towards higher values of \(\theta\) (closer to 1), reflecting a higher likelihood of success. On the other hand, as \(\beta\) increases, the distribution skews towards lower values of \(\theta\) (closer to 0), indicating a higher likelihood of failure. If \(\alpha\) and \(\beta\) are equal, the distribution is symmetric and uniform, reflecting no prior preference between the two outcomes.</p> <hr> <p>After observing data \(D = (\text{H, H, T, T, T, H, ...})\), where \(n_h\) is the number of heads and \(n_t\) is the number of tails, we combine the <strong>prior</strong> and <strong>likelihood</strong> to obtain the <strong>posterior distribution</strong>.</p> <p>The likelihood function, based on the observed data, is:</p> \[L(\theta) = p(D \mid \theta) = \theta^{n_h} (1 - \theta)^{n_t}.\] <p>Combining the prior and likelihood, the posterior density is:</p> \[p(\theta \mid D) \propto p(\theta) \cdot L(\theta),\] <p>which simplifies to:</p> \[p(\theta \mid D) \propto \theta^{h - 1} (1 - \theta)^{t - 1} \cdot \theta^{n_h} (1 - \theta)^{n_t}.\] <p>Simplifying further, we get:</p> \[p(\theta \mid D) \propto \theta^{h - 1 + n_h} (1 - \theta)^{t - 1 + n_t}.\] <p>This posterior distribution is also a Beta distribution:</p> \[\theta \mid D \sim \text{Beta}(h + n_h, t + n_t).\] <h5 id="interpreting-the-posterior"><strong>Interpreting the Posterior</strong></h5> <p>The posterior distribution shows how our prior beliefs are updated by the observed data:</p> <ul> <li>The prior \(\text{Beta}(h, t)\) initializes our counts with \(h\) heads and \(t\) tails.</li> <li>The posterior \(\text{Beta}(h + n_h, t + n_t)\) updates these counts by adding the observed \(n_h\) heads and \(n_t\) tails.</li> </ul> <p>For example, if our prior belief was \(\text{Beta}(2, 2)\) (a uniform prior), and we observed \(n_h = 3\) heads and \(n_t = 1\) tails, the posterior would be:</p> \[\text{Beta}(2 + 3, 2 + 1) = \text{Beta}(5, 3).\] <p>This reflects our updated belief about the probability of heads after observing the data.</p> <hr> <h5 id="wrapping-up"><strong>Wrapping Up</strong></h5> <p>In this blog, we explored the essence of Bayesian statistics, focusing on how priors, likelihoods, and posteriors interact to update our beliefs. Using the coin-flipping example, we demonstrated key Bayesian tools like the Beta distribution and how to compute posterior updates. Also, as we mentioned, there‚Äôs one more important reason for choosing the Beta distribution‚Äîits technical term is <strong>conjugate priors</strong>. In the next blog, we‚Äôll dive deeper into this concept and explore Bayesian point estimates, comparing them to the frequentist MLE estimate. Stay tuned as we continue to build intuition and delve further into Bayesian inference! üëã</p> <h5 id="references"><strong>References</strong></h5> <ul> <li>Bayesian Statistics</li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-structured-perceptron-amp-structured-svm",title:"Structured Perceptron &amp; Structured SVM",description:"Understanding how Structured Perceptron and Structured SVM learn to predict structured outputs with interdependent components.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-perceptron-svm/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>