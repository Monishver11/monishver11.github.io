<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bayesian Conditional Models | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?b337fdf3fe456a8da16aab16e9a00f8c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/bayes-conditional-models/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item "> <a class="nav-link" href="/thoughts/">Thoughts </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="font-weight: 400;">Bayesian Conditional Models</h1> <p class="post-meta"> Created in January 31, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> ¬† ¬∑ ¬† <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a> ¬† <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a> ¬† ¬∑ ¬† <a href="/blog/category/ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In machine learning, making predictions is not just about estimating the most likely outcome. It‚Äôs also about understanding <strong>uncertainty</strong> and making informed decisions based on available data. Traditional <strong>frequentist methods</strong> typically estimate a single best-fit parameter using approaches like Maximum Likelihood Estimation (MLE). While effective, this approach does not quantify the uncertainty in parameter estimates or predictions.</p> <p>Bayesian conditional models, on the other hand, take a <strong>probabilistic approach</strong>. Instead of committing to a single parameter estimate, they maintain a <strong>distribution over possible parameters</strong>. By incorporating prior beliefs and updating them as new data arrives, Bayesian models allow us to make <strong>predictions that inherently capture uncertainty</strong>. This is achieved through <strong>posterior predictive distributions</strong>, which average over all possible models rather than selecting just one.</p> <p>In this post, we will explore Bayesian conditional models in depth‚Äîhow they work, how they differ from frequentist approaches, and how they allow for <strong>more robust decision-making under uncertainty</strong>.</p> <h4 id="bayesian-conditional-models-the-basics"><strong>Bayesian Conditional Models: The Basics</strong></h4> <p>To set up the problem, consider the following:</p> <ul> <li> <strong>Input space</strong>: \(X = \mathbb{R}^d\), representing feature vectors.</li> <li> <strong>Outcome space</strong>: \(Y = \mathbb{R}\), representing target values.</li> </ul> <p>A <strong>Bayesian conditional model</strong> consists of two main components:</p> <ol> <li> <p>A <strong>parametric family</strong> of conditional probability densities:</p> \[\{ p(y \mid x, \theta) : \theta \in \Theta \}\] </li> <li> <p>A <strong>prior distribution</strong> \(p(\theta)\), which represents our beliefs about \(\theta\) before observing any data.</p> </li> </ol> <p>The prior acts as a <strong>regularization mechanism</strong>, preventing overfitting by incorporating external knowledge into our model. Once we observe data, we update this prior to obtain a <strong>posterior distribution</strong> over the parameters.</p> <hr> <p><strong>Q: How does the prior prevent overfitting?</strong><br> The prior \(p(\theta)\) assigns probability to different parameter values before seeing any data. This prevents the model from fitting noise in the data by <strong>restricting extreme values</strong> of \(\theta\). When combined with the likelihood, it balances between prior beliefs and observed data.</p> <p><strong>Q: Why does this help?</strong></p> <ul> <li>It <strong>controls model complexity</strong>, ensuring we don‚Äôt fit spurious patterns.</li> <li>It <strong>biases the model toward reasonable solutions</strong>, especially in low-data regimes.</li> <li>It <strong>smooths predictions</strong>, preventing sharp jumps caused by noisy observations.</li> </ul> <p><strong>Q: What happens after observing data?</strong><br> The prior is updated using Bayes‚Äô rule to form the <strong>posterior</strong>:</p> \[p(\theta \mid D) \propto p(D \mid \theta) p(\theta)\] <p>This posterior now reflects both the <strong>initial beliefs</strong> and the <strong>information from the data</strong>, striking a balance between flexibility and regularization.</p> <p><strong>Q: How is this similar to frequentist regularization?</strong><br> In frequentist methods, regularization terms (e.g., L2 in ridge regression) <strong>penalize large parameter values</strong>. Bayesian priors achieve a similar effect, but instead of a fixed penalty, they provide a <strong>probabilistic framework</strong> that adapts as more data is observed.</p> <p>Thus, the prior serves as a <strong>principled way to regularize models</strong>, ensuring robustness while allowing adaptation as more evidence accumulates.</p> <hr> <h5 id="the-posterior-distribution"><strong>The Posterior Distribution</strong></h5> <p>The <strong>posterior distribution</strong> is the foundation of Bayesian inference. It represents our updated belief about the parameter \(\theta\) after observing data \(D\). Using <strong>Bayes‚Äô theorem</strong>, we compute:</p> \[p(\theta \mid D, x) \propto p(D \mid \theta, x) p(\theta)\] <p>where:</p> <ul> <li>\(p(D \mid \theta, x)\) is the <strong>likelihood function</strong> \(L_D(\theta)\), describing how likely the data is given the parameter \(\theta\).</li> <li>\(p(\theta)\) is the <strong>prior</strong> distribution, encoding our prior knowledge about \(\theta\).</li> </ul> <p>This updated posterior distribution allows us to make <strong>probabilistically sound predictions</strong> while explicitly incorporating uncertainty.</p> <h5 id="estimating-parameters-point-estimates"><strong>Estimating Parameters: Point Estimates</strong></h5> <p>While Bayesian inference provides a full posterior distribution over \(\theta\), sometimes we may need a single point estimate. Different choices arise depending on the loss function we minimize:</p> <ul> <li> <p><strong>Posterior mean</strong>:</p> \[\hat{\theta} = \mathbb{E}[\theta \mid D, x]\] <p>This minimizes squared error loss.</p> </li> <li> <p><strong>Posterior median</strong>:</p> \[\hat{\theta} = \text{median}(\theta \mid D, x)\] <p>This minimizes absolute error loss.</p> </li> <li> <p><strong>Maximum a posteriori (MAP) estimate</strong>:</p> \[\hat{\theta} = \arg\max_{\theta \in \Theta} p(\theta \mid D, x)\] <p>This finds the most probable parameter value under the posterior.</p> </li> </ul> <p>Each approach has its advantages, and the choice depends on the <strong>application and the cost of different types of errors</strong>.</p> <h4 id="bayesian-prediction-function"><strong>Bayesian Prediction Function</strong></h4> <p>The goal of any supervised learning method is to learn a function that maps input \(x \in X\) to a distribution over outputs \(Y\). The key difference between frequentist and Bayesian approaches lies in how they achieve this.</p> <h5 id="frequentist-approach"><strong>Frequentist Approach</strong></h5> <p>In a frequentist framework:</p> <ol> <li>We choose a <strong>hypothesis space</strong>‚Äîa family of conditional probability densities.</li> <li>We estimate a single best-fit parameter \(\hat{\theta}(D)\) using MLE or another optimization method.</li> <li>We make predictions using \(p(y \mid x, \hat{\theta}(D))\), ignoring uncertainty in \(\theta\).</li> </ol> <h5 id="bayesian-approach"><strong>Bayesian Approach</strong></h5> <p>In contrast, Bayesian methods:</p> <ol> <li>Define a <strong>parametric family</strong> of conditional densities \(\{ p(y \mid x, \theta) : \theta \in \Theta \}\).</li> <li>Specify a <strong>prior distribution</strong> \(p(\theta)\).</li> <li>Instead of selecting a single best-fit \(\theta\), integrate over all possible parameters using the posterior.</li> </ol> <p>This results in a <strong>predictive distribution</strong> that <strong>preserves model uncertainty</strong> rather than discarding it.</p> <h5 id="the-prior-and-posterior-predictive-distributions"><strong>The Prior and Posterior Predictive Distributions</strong></h5> <p>Even before observing any data, we can make predictions using the <strong>prior predictive distribution</strong>:</p> \[p(y \mid x) = \int p(y \mid x, \theta) p(\theta) d\theta\] <p>This represents an average over all conditional densities, weighted by the prior \(p(\theta)\). Once we observe data \(D\), we compute the <strong>posterior predictive distribution</strong>:</p> \[p(y \mid x, D) = \int p(y \mid x, \theta) p(\theta \mid D) d\theta\] <p>This distribution takes into account both the likelihood and prior, providing <strong>updated predictions</strong> that reflect the data.</p> <p>[How to make intuitive sense of this? and What happens if we do this? and What if not?]</p> <hr> <p><strong>Q: How does the prior predictive distribution get its value? What does it mean to make predictions before observing data, and how does this function account for it?</strong></p> <p>The prior predictive distribution represents predictions before observing data, and it accounts for the uncertainty in the model parameters by averaging over all possible values of the parameters based on the prior distribution. It essentially captures the expected predictions by integrating over the entire parameter space, weighted by the prior beliefs about the parameters.</p> <p>Mathematically, the prior predictive distribution is given by: \(p(y \mid x) = \int p(y \mid x, \theta) p(\theta) d\theta\)</p> <p>Here‚Äôs how it works:</p> <ol> <li> <p><strong>Prior Distribution \(p(\theta)\):</strong><br> This reflects our beliefs about the parameters \(\theta\) before any data is observed. It could be based on prior knowledge or assumptions about the parameters‚Äô likely values.</p> </li> <li> <p><strong>Likelihood \(p(y \mid x, \theta)\):</strong><br> This describes the model that predicts the outcome \(y\) given the input data \(x\) and the parameters \(\theta\). It represents the relationship between the parameters and the predicted outcomes.</p> </li> <li> <p><strong>Prior Predictive Distribution:</strong><br> The integral sums over all possible values of \(\theta\), weighted by the prior distribution \(p(\theta)\), and gives the expected outcome \(y\). It represents predictions before any data is observed by averaging over the entire parameter space as described by the prior distribution.</p> </li> </ol> <p><strong>Conceptually:</strong></p> <ul> <li> <strong>Predictions before observing data</strong> means we are making predictions based on our beliefs about the parameters, without any data to inform us.</li> <li>The prior predictive distribution is essentially a <strong>preliminary prediction</strong> that incorporates uncertainty about the parameters, providing a forecast based on the prior assumptions, rather than the actual data.</li> </ul> <p><strong>Example:</strong></p> <p>If we were predicting the height of individuals based on age and gender, the prior predictive distribution would give us an expected distribution of heights based on our prior assumptions about average height and variation, before any actual data on height is observed.</p> <p><strong>Why is it useful?</strong></p> <p>The prior predictive distribution gives us an initial understanding of what predictions might look like before data is available, incorporating prior knowledge about the parameters. However, once data is observed, this prediction is updated using the posterior predictive distribution, which integrates both prior beliefs and observed data.</p> <p><strong>Q: Why use the posterior predictive distribution?</strong></p> <ul> <li>It refines predictions using observed data.</li> <li>It accounts for uncertainty by integrating over posterior \(p(\theta \mid D)\).</li> <li>It prevents overconfident predictions from a single parameter estimate.</li> </ul> <p><strong>Q: What if we don‚Äôt use it?</strong></p> <ul> <li>Using only the prior predictive distribution leads to uninformed predictions.</li> <li>Relying on a single \(\theta\) (e.g., MLE) ignores uncertainty, increasing overconfidence.</li> <li>Ignoring parameter uncertainty may lead to suboptimal decisions.</li> </ul> <p><strong>Q: Is Integrating Over \(\theta\) the Same as Marginalizing It?</strong></p> <p>Yes, integrating over \(\theta\) in Bayesian inference is effectively <strong>marginalizing</strong> it out. When computing the <strong>posterior predictive distribution</strong>,</p> \[p(y \mid x, D) = \int p(y \mid x, \theta) p(\theta \mid D) d\theta\] <p>we sum (integrate) over all possible values of \(\theta\), weighted by their posterior probability \(p(\theta \mid D)\). This removes \(\theta\) as an explicit parameter, ensuring predictions reflect all plausible values rather than relying on a single estimate. In contrast, frequentist methods select a single \(\hat{\theta}\) (e.g., MLE or MAP), which does not account for uncertainty in \(\theta\). By marginalizing \(\theta\), Bayesian inference naturally incorporates parameter uncertainty, leading to more robust and well-calibrated predictions.</p> <p><strong>Takeaway:</strong> The posterior predictive distribution provides well-calibrated, data-driven predictions while maintaining uncertainty estimates.</p> <blockquote> <p>Bayesian Analogy: A Detective Solving a Case</p> </blockquote> <h5 id="1-prior--what-you-know-before-the-investigation"><strong>1. Prior ‚Äì What You Know Before the Investigation</strong></h5> <p>Imagine you‚Äôre a detective assigned to a case. Before you‚Äôve looked at any clues or evidence (i.e., before observing any data), you have some <strong>prior beliefs</strong> based on your experience or intuition about the suspect.</p> <p>For example, maybe based on past cases, you believe the suspect is likely to be someone in their 30s (that‚Äôs your <strong>prior</strong> belief). It could be based on things like:</p> <ul> <li>Crime trends (e.g., most crimes in this area are committed by people in their 30s).</li> <li>Hunches or experience (e.g., in your line of work, you‚Äôve seen that younger suspects tend to get caught more easily, so older individuals are more likely to be the culprits).</li> </ul> <p>This <strong>prior belief</strong> about who the suspect might be is like the <strong>prior distribution</strong> in Bayesian statistics‚Äîit‚Äôs your <strong>best guess</strong> before you have any real evidence (data).</p> <h5 id="2-likelihood--how-the-clues-fit-the-suspect"><strong>2. Likelihood ‚Äì How the Clues Fit the Suspect</strong></h5> <p>Now, you start finding <strong>clues</strong> (data) that might suggest a certain suspect. The clues don‚Äôt give you the full picture, but they help you refine your guess.</p> <p>Let‚Äôs say you find a footprint at the crime scene, and based on your knowledge, the likelihood that someone in their 30s leaves this kind of print is relatively high. But the likelihood is not zero for other age groups either‚Äîit‚Äôs just higher for people in their 30s.</p> <p>In Bayesian terms, <strong>likelihood</strong> is how <strong>likely</strong> it is to see the data (e.g., the footprint) given different possible values for your parameters (e.g., the age of the suspect). You‚Äôre comparing the fit of each possible age (parameter) to the actual clue.</p> <h5 id="3-posterior--your-updated-belief-after-seeing-the-clues"><strong>3. Posterior ‚Äì Your Updated Belief After Seeing the Clues</strong></h5> <p>Once you have both your <strong>prior belief</strong> and the <strong>clues</strong>, you combine them to get a better sense of who the suspect might be. This process is called <strong>updating your belief</strong>.</p> <p>So, after considering the clue (e.g., the footprint), you revise your initial guess. Maybe, now that you know the footprint matches your original suspicion of a person in their 30s, you <strong>update</strong> your belief to make it even <strong>stronger</strong>.</p> <p>In Bayesian terms, this is the <strong>posterior distribution</strong>: it‚Äôs the updated belief about the parameters (e.g., the suspect‚Äôs age) <strong>after incorporating the new data (evidence)</strong>. The posterior combines your <strong>prior</strong> belief and the <strong>likelihood</strong> of the evidence, giving you a new <strong>posterior</strong> that reflects both.</p> <h5 id="4-integrating--considering-all-possibilities"><strong>4. Integrating ‚Äì Considering All Possibilities</strong></h5> <p>Finally, to update your belief, you need to <strong>integrate</strong> all the possibilities. For example, you might not be 100% sure that the suspect is in their 30s, but you know that they‚Äôre more likely to be in that age group than in their 40s or 20s. You <strong>integrate</strong> over all the possible ages by weighing them by how probable each one is (based on the prior belief and likelihood).</p> <p>This is where the <strong>integration</strong> comes in. In Bayesian terms, you‚Äôre averaging over all possible values (ages) to get the best <strong>overall</strong> estimate of the suspect‚Äôs age (which is the posterior). You‚Äôre not just picking the most likely answer; you‚Äôre considering all the possibilities and combining them in a way that incorporates both your prior and the evidence you‚Äôve gathered.</p> <hr> <h5 id="making-point-predictions-from-py-mid-x-d"><strong>Making Point Predictions from \(p(y \mid x, D)\)</strong></h5> <p>Once we have the full predictive distribution, we can extract <strong>point predictions</strong> depending on the loss function we wish to minimize:</p> <ul> <li> <p><strong>Mean prediction</strong> (minimizing squared error loss):</p> \[\mathbb{E}[y \mid x, D]\] </li> <li> <p><strong>Median prediction</strong> (minimizing absolute error loss):</p> \[\text{median}(y \mid x, D)\] </li> <li> <p><strong>Mode (MAP estimate of \(y\))</strong> (minimizing 0/1 loss):</p> \[\arg\max_{y \in Y} p(y \mid x, D)\] </li> </ul> <p>Each of these choices is derived directly from the <strong>posterior predictive distribution</strong>, making Bayesian methods highly flexible for different objectives.</p> <hr> <blockquote> <p>Okay, everything makes sense now‚Äîat least somewhat. But what‚Äôs the real difference between all these Bayesian concepts we‚Äôve covered?</p> </blockquote> <p>Bayesian Conditional Models, Bayes Point Estimation, and Bayesian Decision Theory are all part of the broader Bayesian framework, but they serve different purposes. Here‚Äôs how they differ:</p> <h5 id="1-bayesian-conditional-models-bcm--a-probabilistic-approach-to-prediction"><strong>1. Bayesian Conditional Models (BCM) ‚Äì A Probabilistic Approach to Prediction</strong></h5> <p>Bayesian Conditional Models focus on modeling <strong>conditional distributions</strong> of an outcome \(Y\) given an input \(X\). Instead of choosing a single best function or parameter, BCM maintains a <strong>distribution over possible models</strong> and integrates over uncertainty.</p> <ul> <li> <strong>Key Idea</strong>: Instead of selecting a fixed hypothesis (as in frequentist methods), we consider an entire <strong>distribution over models</strong> and use it for making predictions.</li> <li> <strong>Mathematical Formulation</strong>: <ul> <li> <p><strong>Prior Predictive Distribution</strong> (before observing data):</p> \[p(y | x) = \int p(y | x, \theta) p(\theta) d\theta\] </li> <li> <p><strong>Posterior Predictive Distribution</strong> (after observing data \(D\)):</p> \[p(y | x, D) = \int p(y | x, \theta) p(\theta | D) d\theta\] </li> </ul> </li> <li> <strong>Relation to Other Concepts</strong>: BCM extends Bayesian inference to <strong>predictive modeling</strong>, ensuring that uncertainty is incorporated directly into the predictions.</li> </ul> <h5 id="2-bayes-point-estimation-bpe--a-single-best-estimate-of-parameters"><strong>2. Bayes Point Estimation (BPE) ‚Äì A Single Best Estimate of Parameters</strong></h5> <p>Bayes Point Estimation, in contrast, is about finding a <strong>single ‚Äúbest‚Äù estimate</strong> for the model parameters \(\theta\), given the posterior distribution \(p(\theta \mid D)\). It‚Äôs a simplification of full Bayesian inference when we need a point estimate rather than an entire distribution.</p> <ul> <li> <strong>Key Idea</strong>: Instead of integrating over all possible parameters, we select a <strong>single representative parameter</strong> from the posterior.</li> <li> <strong>Common Choices</strong>: <ul> <li> <p><strong>Posterior Mean</strong>:</p> \[\hat{\theta} = \mathbb{E}[\theta \mid D]\] <p>(Minimizes squared error)</p> </li> <li> <p><strong>Posterior Median</strong>:</p> \[\hat{\theta} = \text{median}(\theta \mid D)\] <p>(Minimizes absolute error)</p> </li> <li> <p><strong>Maximum a Posteriori (MAP) Estimate</strong>:</p> \[\hat{\theta} = \arg\max_{\theta} p(\theta \mid D)\] <p>(Maximizes posterior probability)</p> </li> </ul> </li> <li> <strong>Difference from BCM</strong>: BCM keeps the full predictive distribution, while BPE collapses uncertainty into a single parameter choice.</li> </ul> <h5 id="3-bayesian-decision-theory-bdt--making-optimal-decisions-with-uncertainty"><strong>3. Bayesian Decision Theory (BDT) ‚Äì Making Optimal Decisions with Uncertainty</strong></h5> <p>Bayesian Decision Theory extends Bayesian inference to <strong>decision-making</strong>. It incorporates a <strong>loss function</strong> to determine the best action given uncertain outcomes.</p> <ul> <li> <strong>Key Idea</strong>: Instead of just estimating parameters, we aim to make an <strong>optimal decision</strong> that minimizes expected loss.</li> <li> <p><strong>Mathematical Formulation</strong>: Given a loss function \(L(a, y)\) for action \(a\) and outcome \(y\), the optimal action is:</p> \[a^* = \arg\min_a \mathbb{E}[L(a, Y) \mid D]\] </li> <li> <strong>Relation to BCM</strong>: <ul> <li>BCM provides a <strong>full predictive distribution</strong> of \(Y\), which is then used in BDT to make optimal decisions.</li> <li>If we only care about a <strong>single estimate</strong>, we apply Bayes Point Estimation within BDT.</li> </ul> </li> </ul> <h5 id="summary-of-differences"><strong>Summary of Differences</strong></h5> <hr> <table> <thead> <tr> <th>Concept</th> <th>Focus</th> <th>Key Idea</th> <th>Output</th> </tr> </thead> <tbody> <tr> <td><strong>Bayesian Conditional Models (BCM)</strong></td> <td>Predicting \(Y\) given \(X\)</td> <td>Maintain a <strong>distribution over possible models</strong> </td> <td>A full <strong>predictive distribution</strong> \(p(y \vert x, D)\)</td> </tr> <tr> <td><strong>Bayes Point Estimation (BPE)</strong></td> <td>Estimating model parameters \(\theta\)</td> <td>Choose a <strong>single best estimate</strong> from the posterior</td> <td>A point estimate \(\hat{\theta}\) (e.g., posterior mean, MAP)</td> </tr> <tr> <td><strong>Bayesian Decision Theory (BDT)</strong></td> <td>Making optimal decisions</td> <td>Select the <strong>best action</strong> based on a loss function</td> <td>An action \(a^*\) that minimizes expected loss</td> </tr> </tbody> </table> <hr> <p>So, <strong>Bayesian Conditional Models are a more general framework</strong> that encompasses both Bayesian Point Estimation and Bayesian Decision Theory as special cases when we either want a point estimate or a decision-making strategy.</p> <h5 id="practical-applications-of-bayesian-conditional-models"><strong>Practical Applications of Bayesian Conditional Models</strong></h5> <p>Bayesian conditional models are widely used in various fields where uncertainty plays a crucial role:</p> <ul> <li> <strong>Medical Diagnosis &amp; Healthcare</strong>: Bayesian models help in probabilistic disease prediction, patient risk assessment, and adaptive clinical trials where data is limited.</li> <li> <strong>Finance &amp; Risk Management</strong>: Used for credit scoring, fraud detection, and portfolio optimization, where uncertainty in market conditions needs to be modeled explicitly.</li> <li> <strong>Autonomous Systems &amp; Robotics</strong>: Bayesian approaches help robots and self-driving cars make <strong>decisions under uncertainty</strong>, such as obstacle avoidance and motion planning.</li> <li> <strong>Recommendation Systems</strong>: Bayesian methods improve user personalization by adapting to changing preferences with uncertainty-aware updates.</li> </ul> <blockquote> <p>Let‚Äôs tie it all together with a story to help us feel it.</p> </blockquote> <h5 id="1-bayesian-conditional-models-bcm--predicting-the-route"><strong>1. Bayesian Conditional Models (BCM) ‚Äì Predicting the Route</strong></h5> <p>Think of a scenario where you‚Äôre planning a trip, and you need to choose a route from a starting point (X) to your destination (Y). Instead of using just one route (which could be inaccurate), you take into account a variety of possible routes and factor in your <strong>uncertainty</strong> about traffic conditions, road closures, and construction. You create a model that looks at all the possible routes, weighing each of them based on how likely they are to be optimal given the current information.</p> <ul> <li> <p><strong>Intuition</strong>: BCM is like saying, ‚ÄúI‚Äôm not sure which exact route to take, so let‚Äôs consider all the possible routes and their chances of being optimal based on my prior knowledge of traffic and construction conditions.‚Äù</p> </li> <li> <p><strong>In Bayesian Terms</strong>: You‚Äôre integrating over all possible routes (models) to get a <strong>distribution of possible outcomes</strong> (where you might end up). You‚Äôre not just picking one route, but making an informed prediction that accounts for your uncertainty.</p> </li> </ul> <h5 id="2-bayes-point-estimation-bpe--choosing-the-best-route"><strong>2. Bayes Point Estimation (BPE) ‚Äì Choosing the Best Route</strong></h5> <p>Now imagine you‚Äôve gathered more information, such as current traffic reports and road conditions. You can now estimate the ‚Äúbest‚Äù route to take. Instead of considering every possible route, you choose the one that has the highest likelihood of being optimal given the current data.</p> <ul> <li> <p><strong>Intuition</strong>: BPE is like saying, ‚ÄúGiven what I know right now, the best choice is to take Route A. It might not be the perfect route, but it‚Äôs the one that seems most likely to get me to my destination quickly based on current data.‚Äù</p> </li> <li> <p><strong>In Bayesian Terms</strong>: You‚Äôre using the <strong>posterior distribution</strong> of routes and picking a <strong>single estimate</strong> (the route you think will be best). This is either the route with the <strong>posterior mean</strong>, the <strong>maximum a posteriori estimate (MAP)</strong>, or another representative value from the distribution.</p> </li> </ul> <h5 id="3-bayesian-decision-theory-bdt--choosing-the-optimal-action-based-on-costs"><strong>3. Bayesian Decision Theory (BDT) ‚Äì Choosing the Optimal Action Based on Costs</strong></h5> <p>Now, let‚Äôs introduce a <strong>cost</strong> to the decision-making. Imagine you‚Äôre trying to not only get to your destination as quickly as possible, but you also want to minimize costs‚Äîwhether that‚Äôs the cost of time, fuel, or stress. The optimal decision isn‚Äôt just about picking the quickest route, but about minimizing your <strong>expected cost</strong> (which could involve trade-offs, like a longer route with less traffic vs. a shorter one with more congestion).</p> <ul> <li> <p><strong>Intuition</strong>: BDT is like saying, ‚ÄúGiven that I want to minimize both my time and stress, I will pick the route that‚Äôs expected to cost me the least overall, even if it‚Äôs not the fastest.‚Äù</p> </li> <li> <p><strong>In Bayesian Terms</strong>: You‚Äôre using the <strong>predictive distribution</strong> (like BCM) to understand all possible outcomes, and then making a decision by minimizing the <strong>expected loss</strong> (cost) based on the uncertainty about your outcomes.</p> </li> </ul> <hr> <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>Bayesian conditional models provide a <strong>principled and uncertainty-aware</strong> approach to prediction. Unlike frequentist methods, which estimate a single best-fit parameter, Bayesian inference maintains <strong>a full distribution over parameters</strong> and updates beliefs as new data arrives. This allows for <strong>more robust, probabilistically grounded predictions</strong>, making Bayesian methods an essential tool in modern machine learning.</p> <p>By integrating over possible hypotheses rather than committing to one, Bayesian models naturally <strong>quantify uncertainty</strong> and adapt to new information, making them particularly useful in scenarios with limited data or high variability.</p> <p>Next up, we‚Äôll use all of this to tackle <strong>Gaussian linear regression</strong>. Stay tuned, and see you in the next oneüëã!</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2026 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-resume",title:"Resume",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-thoughts",title:"Thoughts",description:"",section:"Navigation",handler:()=>{window.location.href="/thoughts/"}},{id:"post-distributed-systems-lecture-1",title:"Distributed Systems - Lecture 1",description:"Distributed Systems Course at NYU Courant - Personal Notes 1",section:"Posts",handler:()=>{window.location.href="/blog/2026/ds1/"}},{id:"post-llmr-a1",title:"Llmr A1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/llmr-a1/"}},{id:"post-llmr-lecture-1",title:"LLMR - Lecture 1",description:"LLM Reasoners Course at NYU Courant - Personal Notes 1",section:"Posts",handler:()=>{window.location.href="/blog/2026/llmr1/"}},{id:"post-apache-flink",title:"Apache Flink",description:"Realtime and Big Data Analytics Course at NYU Courant - Personal Notes 10",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-11-flink/"}},{id:"post-apache-kafka",title:"Apache Kafka",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 9",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-10-kafka/"}},{id:"post-apache-zookeeper",title:"Apache ZooKeeper",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 8",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-9-zookeeper/"}},{id:"post-apache-hbase",title:"Apache HBase",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 7",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-8-hbase/"}},{id:"post-hive-amp-trino",title:"Hive &amp; Trino",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 6",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-7-hive/"}},{id:"post-mapreduce-design-patterns",title:"MapReduce Design Patterns",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 5",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-5-mr-dp/"}},{id:"post-big-data-processing-concepts-amp-mapreduce",title:"Big Data Processing Concepts &amp; MapReduce",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 4",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-4-mapreduce/"}},{id:"post-hadoop-distributed-file-system-hdfs",title:"Hadoop Distributed File System (HDFS)",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 3",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-3-hdfs/"}},{id:"post-reading-notes-from-aleksa-gordic-39-s-gpu-blogpost",title:"Reading Notes from Aleksa Gordic&#39;s GPU BlogPost",description:"Reading notes for my reference from Aleksa Gordic&#39;s GPU BlogPost",section:"Posts",handler:()=>{window.location.href="/blog/2025/aleksagordic-gpu-blog-notes/"}},{id:"post-mlp-standard-derivatives-derivation",title:"MLP Standard Derivatives Derivation",description:"MLP Standard Derivatives Derivation",section:"Posts",handler:()=>{window.location.href="/blog/2025/mlp-derivatives/"}},{id:"post-simple-mlp-forward-and-backward-pass-with-einsum-derivation",title:"Simple MLP - Forward and Backward Pass (With Einsum) Derivation",description:"Simple MLP - Forward and Backward Pass Derivation",section:"Posts",handler:()=>{window.location.href="/blog/2025/mlp-fw-bwd/"}},{id:"post-gpu-notes",title:"GPU Notes",description:"GPU Architecture and Programming Course at NYU Courant - Lecture and Conceptual Notes",section:"Posts",handler:()=>{window.location.href="/blog/2025/gpu-notes/"}},{id:"post-big-data-storage",title:"Big Data Storage",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 2",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-2-storage/"}},{id:"post-introduction-to-realtime-and-big-data-analytics",title:"Introduction to Realtime and Big Data Analytics",description:"Realtime and Big Data Analytics Course at NYU Courant - Conceptual Notes 1",section:"Posts",handler:()=>{window.location.href="/blog/2025/big-data-1-intro/"}},{id:"post-gpu-essentials-a-concise-technical-guide",title:"GPU Essentials - A Concise Technical Guide",description:"A concise, technical guide to GPU architecture and CUDA, showing how massive parallelism is achieved through threads, blocks, SMs, and memory hierarchies.",section:"Posts",handler:()=>{window.location.href="/blog/2025/GPU-Intro/"}},{id:"post-wrapping-up-our-ml-foundations-journey",title:"Wrapping Up Our ML Foundations Journey",description:"A reflection on our exploration of machine learning fundamentals, from mathematical prerequisites to gradient boosting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/wrapping-ml-basics/"}},{id:"post-gradient-boosting-in-practice",title:"Gradient Boosting in Practice",description:"Practical insights and regularization techniques to make gradient boosting robust, efficient, and generalize well in real-world applications.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gb-in-practice/"}},{id:"post-binomialboost",title:"BinomialBoost",description:"See how the gradient boosting framework naturally extends to binary classification using the logistic loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/binomial-boost/"}},{id:"post-gradient-boosting-quot-anyboost-quot",title:"Gradient Boosting / &quot;Anyboost&quot;",description:"A clear and intuitive walkthrough of gradient boosting as functional gradient descent, with detailed explanations of residuals, step directions, and algorithmic structure.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gradient-boosting/"}},{id:"post-forward-stagewise-additive-modeling",title:"Forward Stagewise Additive Modeling",description:"A clear walkthrough of FSAM and its role in boosting with exponential loss.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FSAM/"}},{id:"post-introduction-to-gradient-boosting",title:"Introduction to Gradient Boosting",description:"A beginner-friendly introduction to gradient boosting, connecting empirical risk minimization, adaptive basis functions, and the challenges of non-differentiable models like decision trees.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-gradient-boosting/"}},{id:"post-boosting-and-adaboost",title:"Boosting and AdaBoost",description:"This blog post provides an in-depth overview of boosting techniques, focusing on AdaBoost, explaining its key concepts, algorithm steps, and real-world applications in classification tasks.",section:"Posts",handler:()=>{window.location.href="/blog/2025/adaboost/"}},{id:"post-random-forests",title:"Random Forests",description:"Explore how Random Forests enhance Bagging by introducing randomness at each tree split, reducing correlation, and increasing diversity to build more accurate and stable prediction models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/random-forest/"}},{id:"post-bagging-bootstrap-aggregation",title:"Bagging - Bootstrap Aggregation",description:"Bagging (Bootstrap Aggregating) combines multiple high-variance models trained on different bootstrap samples to create a more stable, accurate, and lower-variance ensemble predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bagging/"}},{id:"post-introduction-to-ensemble-methods",title:"Introduction to Ensemble Methods",description:"A beginner&#39;s guide to ensemble methods in machine learning, explaining how averaging and bootstrapping reduce variance and improve model performance.",section:"Posts",handler:()=>{window.location.href="/blog/2025/intro-to-ensemble-methods/"}},{id:"post-decision-trees-for-classification",title:"Decision Trees for Classification",description:"Explains what makes a good split, how impurity is quantified using Gini, Entropy, and misclassification error, and why trees are both powerful and interpretable.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees-classification/"}},{id:"post-decision-trees-our-first-non-linear-classifier",title:"Decision Trees - Our First Non-Linear Classifier",description:"Learn how decision trees work for regression, including split criteria, overfitting control, and intuitive examples.",section:"Posts",handler:()=>{window.location.href="/blog/2025/decision-trees/"}},{id:"post-structured-perceptron-amp-structured-svm",title:"Structured Perceptron &amp; Structured SVM",description:"Understanding how Structured Perceptron and Structured SVM learn to predict structured outputs with interdependent components.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-perceptron-svm/"}},{id:"post-structured-prediction-and-multiclass-svm",title:"Structured Prediction and Multiclass SVM",description:"An in-depth yet intuitive walkthrough of structured prediction, covering sequence labeling, feature engineering, and scoring methods for complex outputs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/structured-prediction/"}},{id:"post-multiclass-classification-with-svm",title:"Multiclass Classification with SVM",description:"Learn how Support Vector Machines extend to multiclass classification with an intuitive breakdown of margin concepts, loss derivation, and the multiclass hinge loss formulation.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-svm/"}},{id:"post-multiclass-logistic-regression-amp-multiclass-perceptron-algorithm",title:"Multiclass Logistic Regression &amp; Multiclass Perceptron Algorithm",description:"Learn the essentials of multiclass classification, focusing on logistic regression, perceptron algorithms, and efficient model building techniques.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass-loss/"}},{id:"post-multiclass-classification-overview",title:"Multiclass Classification - Overview",description:"Learn how One-vs-All and One-vs-One extend binary classification to multiclass problems, their key differences, and best use cases.",section:"Posts",handler:()=>{window.location.href="/blog/2025/multiclass/"}},{id:"post-gaussian-regression-a-bayesian-approach-to-linear-regression",title:"Gaussian Regression - A Bayesian Approach to Linear Regression",description:"This guide explores Gaussian regression, deriving its closed-form posterior, linking MAP estimation to ridge regression, and explaining predictive uncertainty for Bayesian inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussian-regression/"}},{id:"post-my-understanding-of-quot-efficient-algorithms-for-online-decision-problems-quot-paper",title:"My Understanding of &quot;Efficient Algorithms for Online Decision Problems&quot; Paper",description:"A breakdown of Follow the Perturbed Leader (FPL) from Kalai &amp; Vempala\u2019s (2005) paper, &quot;Efficient Algorithms for Online Decision Problems.&quot; This blog explores how FPL improves online decision-making, minimizes regret, and extends to structured problems like shortest paths and adaptive Huffman coding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL-proof/"}},{id:"post-follow-the-leader-fl-and-follow-the-perturbed-leader-fpl-in-online-learning",title:"Follow the Leader (FL) and Follow the Perturbed Leader (FPL) in Online Learning...",description:"Discover how Follow the Leader (FL) and Follow the Perturbed Leader (FPL) work in online learning, their mathematical foundations, and how perturbations help achieve better stability and regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/FPL/"}},{id:"post-bayesian-conditional-models",title:"Bayesian Conditional Models",description:"Learn how Bayesian conditional models leverage prior knowledge, posterior updates, and predictive distributions to make principled, uncertainty-aware predictions in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-conditional-models/"}},{id:"post-on-line-to-batch-conversion",title:"On-line to Batch Conversion",description:"Understanding how online learning algorithms can be used to derive hypotheses with small generalization error in a stochastic setting.",section:"Posts",handler:()=>{window.location.href="/blog/2025/online-to-batch/"}},{id:"post-randomized-weighted-majority-algorithm",title:"Randomized Weighted Majority Algorithm",description:"Learn how the Randomized Weighted Majority (RWM) Algorithm leverages probabilistic prediction to minimize regret and defend against adversarial strategies in online learning environments.",section:"Posts",handler:()=>{window.location.href="/blog/2025/RWM/"}},{id:"post-bayesian-decision-theory-concepts-and-recap",title:"Bayesian Decision Theory - Concepts and Recap",description:"A comprehensive guide to Bayesian decision theory, exploring its key components, point estimation, loss functions, and connections to classical probability modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-decision-theory/"}},{id:"post-reinforcement-learning-an-introductory-guide",title:"Reinforcement Learning - An Introductory Guide",description:"Explore the foundations of intelligence, decision-making principles, and their application in reinforcement learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/rl-intro/"}},{id:"post-conjugate-priors-and-bayes-point-estimates",title:"Conjugate Priors and Bayes Point Estimates",description:"Learn how conjugate priors streamline Bayesian inference and discover  ways to summarize posterior distributions using Bayes point estimates.",section:"Posts",handler:()=>{window.location.href="/blog/2025/bayes-point-estimate/"}},{id:"post-doubling-trick-a-clever-strategy-to-handle-unknown-horizons",title:"Doubling Trick - A Clever Strategy to Handle Unknown Horizons",description:"Discover how the Doubling Trick enables online algorithms to adapt to unknown horizons, maintaining competitive regret bounds.",section:"Posts",handler:()=>{window.location.href="/blog/2025/doubling-trick/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"news-sharing-personal-reflections-thoughts-tab-thoughts",title:"Sharing personal reflections - [Thoughts Tab](/thoughts/)",description:"",section:"News"},{id:"news-wrapping-up-our-ml-foundations-journey-blog-2025-wrapping-ml-basics",title:"[Wrapping Up Our ML Foundations Journey](/blog/2025/wrapping-ml-basics/)",description:"",section:"News"},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-gaze-guided-reinforcement-learning-for-visual-search",title:"Gaze-Guided Reinforcement Learning for Visual Search",description:"Discover how gaze prediction from human eye-tracking enhances AI agents in object search tasks. By integrating visual attention into reinforcement learning through three novel methods, our approach enables faster, more effective navigation in simulated environments.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-understanding-swap-regret-2-0",title:"Understanding Swap Regret 2.0",description:"This blog post unpacks the &quot;Swap Regret 2.0&quot; paper through slide-by-slide insights, showing how the TreeSwap algorithm closes the gap between external and swap regret, advancing equilibrium computation in game theory and reinforcement learning.",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-smallgraphgcn-accelerating-gnn-training-on-batched-small-graphs",title:"SmallGraphGCN - Accelerating GNN Training on Batched Small Graphs",description:"Discover how fused-edge-centric CUDA kernels dramatically accelerate Graph Neural Network training on molecular datasets. By rethinking parallelism strategies for batched small graphs, our approach achieves up to 3.1\xd7 faster forward execution and 1.3\xd7 end-to-end training speedup over PyTorch Geometric.",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-from-baseline-to-deepseek-single-gpu-moe-training-efficiency",title:"From Baseline to DeepSeek - Single-GPU MoE Training Efficiency",description:"A systems-level analysis of training Mixture-of-Experts (MoE) Transformer models under single-GPU constraints. We compare naive PyTorch MoE, ScatterMoE, MegaBlocks, and DeepSeek-inspired architectures, revealing critical trade-offs between convergence behavior, memory footprint, and training throughput.",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>