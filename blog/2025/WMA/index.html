<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding the Weighted Majority Algorithm in Online Learning | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%A5&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2025/WMA/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding the Weighted Majority Algorithm in Online Learning</h1> <p class="post-meta"> Created in January 23, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> Math</a>   ·   <a href="/blog/category/adv-ml-nyu"> <i class="fa-solid fa-tag fa-sm"></i> ADV-ML-NYU</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>The Weighted Majority Algorithm: A Powerful Online Learning Technique</strong></p> <p>In the continuation of our exploration into online learning, we turn to the <strong>Weighted Majority Algorithm (WMA)</strong>, an influential approach introduced by Littlestone and Warmuth in 1988. This algorithm builds upon the foundational principles of online learning and offers remarkable theoretical guarantees for handling adversarial scenarios.</p> <p>Let’s dive into the workings of the Weighted Majority Algorithm, analyze its performance, and understand its strengths and limitations.</p> <h4 id="the-weighted-majority-algorithm"><strong>The Weighted Majority Algorithm</strong></h4> <p>The Weighted Majority Algorithm operates in a framework where predictions are made by combining the advice of multiple experts. Unlike the Halving Algorithm, which outright eliminates incorrect hypotheses, WMA assigns and updates weights to experts based on their performance, ensuring a more adaptive approach.</p> <h5 id="the-algorithm-steps"><strong>The Algorithm Steps</strong></h5> <ol> <li> <strong>Initialization</strong>: <ul> <li>Start with \(N\) experts, each assigned an initial weight of 1:<br> \(w_{1,i} = 1 \quad \text{for } i = 1, 2, \dots, N\)</li> </ul> </li> <li> <strong>Prediction</strong>: <ul> <li>At each time step \(t\): <ul> <li>Receive the instance \(x_t\).</li> <li>Predict the label \(\hat{y}_t\) using a <strong>weighted majority vote</strong>: \(\hat{y}_t = \begin{cases} 1 &amp; \text{if } \sum_{i: y_{t,i}=1}^{N} w_{t,i} &gt; \sum_{i: y_{t,i}=0}^{N} w_{t,i}, \\ 0 &amp; \text{otherwise.} \end{cases}\)</li> </ul> </li> </ul> </li> <li> <strong>Update Weights</strong>: <ul> <li>After receiving the true label \(y_t\), update the weights of the experts: <ul> <li>For each expert \(i\): \(w_{t+1,i} = \begin{cases} \beta w_{t,i} &amp; \text{if } y_{t,i} \neq y_t, \\ w_{t,i} &amp; \text{otherwise,} \end{cases}\) where \(\beta \in [0,1)\) is a parameter that reduces the weight of experts who make incorrect predictions.</li> </ul> </li> </ul> </li> </ol> <p>[The condition check matters here right??, 2 cases: 1. if the majority vote is correct, then no update for the experts that did mistake. 2. If the majoriy vote is wrong, then we update correctly for experts that are wrong. So, its better to update without checking if the majority vote gives correct result right? ]</p> <ol> <li> <strong>Termination</strong>: <ul> <li>After \(T\) iterations, return the final weights of all experts.</li> </ul> </li> </ol> <h4 id="theoretical-performance-of-the-weighted-majority-algorithm"><strong>Theoretical Performance of the Weighted Majority Algorithm</strong></h4> <h5 id="mistake-bound"><strong>Mistake Bound</strong></h5> <p><strong>Theorem:</strong> The Weighted Majority (WM) algorithm guarantees a bound on the number of mistakes it makes compared to the best expert. Let:</p> <ul> <li>\(m_t\): Total number of mistakes made by the WM algorithm up to time \(t\),</li> <li>\(m_t^*\): Number of mistakes made by the best expert up to time \(t\),</li> <li>\(N\): Total number of experts,</li> <li>\(\beta\): Parameter controlling the weight decay for incorrect experts.</li> </ul> <p>The mistake bound is given by:</p> \[m_t \leq \frac{\log N + m_t^* \log \frac{1}{\beta}}{\log \frac{2}{1+\beta}}\] <p><strong>Interpretation of the Bound:</strong></p> <ol> <li> <strong>First Term (\(\log N\))</strong>: <ul> <li>This term accounts for the initial uncertainty due to having \(N\) experts. The algorithm needs to explore to identify the best expert, and the logarithmic dependence on \(N\) ensures scalability.</li> </ul> </li> <li> <strong>Second Term (\(m_t^* \log \frac{1}{\beta}\))</strong>: <ul> <li>This term reflects the cost of following the best expert, scaled by \(\log \frac{1}{\beta}\). A smaller \(\beta\) increases the penalty for mistakes, leading to slower adaptation but potentially fewer overall mistakes. [<strong>Think it through, Why?</strong>]</li> </ul> </li> <li> <strong>Denominator (\(\log \frac{2}{1+\beta}\))</strong>: <ul> <li>This represents the efficiency of the weight adjustment. When \(\beta\) is close to 0 (as in the Halving Algorithm), the denominator becomes larger, leading to tighter bounds.</li> </ul> </li> </ol> <p><strong>Special Cases:</strong></p> <ol> <li> <strong>Realizable Case (\(m_t^* = 0\))</strong>: <ul> <li>If there exists an expert with zero mistakes, the bound simplifies to: \(m_t \leq \frac{\log N}{\log \frac{2}{1+\beta}}\) <ul> <li>For the Halving Algorithm (\(\beta = 0\)), this further simplifies to: \(m_t \leq \log N\)</li> </ul> </li> </ul> </li> <li> <strong>General Case</strong>: <ul> <li>When no expert is perfect (\(m_t^* &gt; 0\)), the algorithm incurs an additional cost proportional to \(m_t^* \log \frac{1}{\beta}\). This reflects the cost of distributing weights among experts.</li> </ul> </li> </ol> <p><strong>Intuition:</strong></p> <ul> <li>The Weighted Majority Algorithm balances exploration (trying all experts) and exploitation (focusing on the best expert). The logarithmic terms indicate that the algorithm adapts efficiently, even with a large number of experts.</li> <li>By tuning \(\beta\), the algorithm can trade off between faster adaptation and resilience to noise. A smaller \(\beta\) (e.g., \(\beta = 0\)) emphasizes rapid adaptation, while a larger \(\beta\) smoothens weight updates.</li> </ul> <p><strong>Note:</strong> If this isn’t clear, I can simplify it further, but this time, I encourage you to try and understand it on your own. There’s a reason behind this—it helps you build a mental model of how the algorithm works and strengthens your intuition. This kind of reinforcement is essential as we dive deeper into advanced ML concepts. I hope this makes sense. If you’re still struggling, consider using tools like ChatGPT or Perplexity to gain additional clarity.</p> <hr> <h4 id="proof-of-the-mistake-bound"><strong>Proof of the Mistake Bound</strong></h4> <p><mark>A general method for deducing bounds and guarantees involves defining a potential function, establishing both upper and lower bounds for it, and deriving results from the resulting inequality.</mark> This powerful approach is central to deducing several proofs. Specifically, the proof of the mistake bound relies on defining a potential function that tracks the total weight of all experts over time.</p> <h5 id="potential-function"><strong>Potential Function</strong></h5> <p>The potential function at time \(t\) is defined as:</p> \[\Phi_t = \sum_{i=1}^N w_{t,i},\] <p>where \(w_{t,i}\) is the weight of expert \(i\) at time \(t\).</p> <h5 id="upper-bound-on-potential"><strong>Upper Bound on Potential</strong></h5> <p>Initially, the weights of all \(N\) experts sum up to \(\Phi_0 = N\) since each expert starts with a weight of 1.</p> <p><strong>Step 1: Effect of a Mistake</strong></p> <p>When the Weighted Majority Algorithm makes a mistake, the weights of the experts who predicted incorrectly are reduced by a factor of \(\beta\), where \(0 &lt; \beta &lt; 1\). This means the total weight at the next time step, \(\Phi_{t+1}\), will be less than or equal to the weighted average of the weights of the correct and incorrect experts.</p> <p><strong>Step 2: Fraction of Correct and Incorrect Experts</strong></p> <p>Let’s say a fraction \(p\) of the total weight belongs to the correct experts, and a fraction \(1 - p\) belongs to the incorrect experts. After the mistake, the incorrect experts’ weights are scaled by \(\beta\). Thus, the new potential is:</p> \[\Phi_{t+1} = p \Phi_t + \beta (1 - p) \Phi_t\] <p><strong>Step 3: Simplifying the Expression</strong></p> <p>Factor out \(\Phi_t\) from the equation:</p> \[\Phi_{t+1} = \Phi_t \left[ p + \beta (1 - p) \right]\] <p>Rewriting \(p + \beta (1 - p)\):</p> \[\Phi_{t+1} = \Phi_t \left[ 1 - (1 - \beta)(1 - p) \right]\] <p>Since \(p + (1 - p) = 1\), this simplifies to:</p> \[\Phi_{t+1} \leq \Phi_t \left[ 1 + \frac{\beta}{2} \right]\] <p>This inequality holds because the worst-case scenario assumes \(p = \frac{1}{2}\), where half the weight comes from correct predictions and half from incorrect predictions.</p> <p><strong>Step 4: Over Multiple Mistakes</strong></p> <p>If the algorithm makes \(m_t\) mistakes, the inequality applies iteratively. After \(m_t\) mistakes, the potential becomes:</p> \[\Phi_t \leq \Phi_0 \left[ 1 + \frac{\beta}{2} \right]^{m_t}\] <p>Substituting \(\Phi_0 = N\) (the initial total weight):</p> \[\Phi_t \leq N \left[ 1 + \frac{\beta}{2} \right]^{m_t}\] <p><strong>Intuition:</strong> The factor \(1 + \frac{\beta}{2}\) reflects the reduction in potential after each mistake. As \(\beta\) decreases, the penalty for incorrect experts increases, leading to a faster reduction in \(\Phi_t\). This bound shows how the potential decreases exponentially with the number of mistakes \(m_t\).</p> <hr> <h5 id="lower-bound-on-potential"><strong>Lower Bound on Potential</strong></h5> <p>The <strong>lower bound</strong> on the potential is based on the performance of the best expert in the algorithm.</p> <p>Let’s define \(w_{t,i}\) as the weight of expert \(i\) at time \(t\). The total potential \(\Phi_t\) is the sum of the weights of all experts. Since the best expert is the one with the highest weight at any time, we can state that:</p> \[\Phi_t \geq w_{t,i^*}\] <p>where \(i^*\) is the index of the best expert.</p> <p>Now, the key point is that the weight of the best expert, \(w_{t,i^*}\), decays over time as it makes mistakes. Let \(m_t^*\) be the number of mistakes made by the best expert up to time \(t\). Since each mistake reduces the weight of the best expert by a factor of \(\beta\), the weight of the best expert at time \(t\) is given by:</p> \[w_{t,i^*} = \beta^{m_t^*}\] <p>Therefore, the potential at time \(t\) is at least the weight of the best expert:</p> \[\Phi_t \geq \beta^{m_t^*}\] <p>This provides a <strong>lower bound</strong> on the potential.</p> <h5 id="combining-the-upper-and-lower-bounds"><strong>Combining the Upper and Lower Bounds</strong></h5> <p>Now that we have both an upper bound and a lower bound on the potential, we can combine them to get a more useful inequality.</p> <p>From the upper bound, we know:</p> \[\Phi_t \leq \left[\frac{1 + \beta}{2}\right]^{m_t} N\] <p>From the lower bound, we know:</p> \[\Phi_t \geq \beta^{m_t^*}\] <p>By combining these two inequalities, we get:</p> \[\beta^{m_t^*} \leq \left[\frac{1 + \beta}{2}\right]^{m_t} N\] <p>This inequality tells us that the weight of the best expert at time \(t\), \(\beta^{m_t^*}\), is less than or equal to the total potential \(\Phi_t\) after \(m_t\) mistakes.</p> <p>To solve for \(m_t\), we take the logarithm of both sides of the inequality:</p> \[\log \left( \beta^{m_t^*} \right) \leq \log \left( \left[\frac{1 + \beta}{2}\right]^{m_t} N \right)\] <p>Using the logarithmic property \(\log(a^b) = b \log(a)\), we simplify both sides:</p> \[m_t^* \log \beta \leq m_t \log \left[\frac{1 + \beta}{2}\right] + \log N\] <p>Now, we want to isolate \(m_t\) on one side of the inequality. First, subtract \(\log N\) from both sides:</p> \[m_t^* \log \beta - \log N \leq m_t \log \left[\frac{1 + \beta}{2}\right].\] <p>Now, divide both sides by \(\log \left[\frac{1 + \beta}{2}\right]\). Note that \(\log \left[\frac{1 + \beta}{2}\right]\) is negative because \(\frac{1 + \beta}{2} &lt; 1\), so dividing by it reverses the inequality:</p> \[m_t \geq \frac{m_t^* \log \beta - \log N}{\log \left[\frac{1 + \beta}{2}\right]}.\] <p>We can simplify the expression further by recognizing that \(\log \frac{1}{\beta} = -\log \beta\). This gives us:</p> \[m_t \leq \frac{\log N + m_t^* \log \frac{1}{\beta}}{\log \frac{2}{1 + \beta}}.\] <p>This is the final inequality, which gives a bound on the number of mistakes \(m_t\) made by the algorithm in terms of the number of mistakes \(m_t^*\) made by the best expert, the total number of experts \(N\), and the factor \(\beta\).</p> <p><strong>Note:</strong> The <strong>less than or equal to (≤)</strong> sign appears because of the <strong>inequality reversal</strong> when dividing by a negative quantity. This is why the final inequality has the \(\leq\) sign instead of \(\geq\).</p> <p>This completes the proof of the mistake bound. The inequality shows that the number of mistakes \(m_t\) made by the algorithm is related to the mistakes \(m_t^*\) made by the best expert, and that the algorithm’s performance improves as \(\beta\) decreases.</p> <p>[Self - Understand it better, think it through]</p> <hr> <h5 id="strengths-and-weaknesses-of-the-weighted-majority-algorithm"><strong>Strengths and Weaknesses of the Weighted Majority Algorithm</strong></h5> <p><strong>Advantages</strong></p> <ul> <li> <strong>Strong Theoretical Bound</strong>: <ul> <li>The Weighted Majority Algorithm (WMA) achieves a remarkable theoretical bound on regret without requiring any assumptions about the data distribution or the performance of individual experts.</li> <li>This makes it robust, particularly in adversarial environments.</li> </ul> </li> </ul> <p><strong>Disadvantages</strong></p> <ul> <li> <strong>Limitation with Binary Loss</strong>: <ul> <li>For binary loss, no deterministic algorithm (including WMA) can achieve a regret \(R_T = o(T)\).</li> <li>This means deterministic WMA cannot guarantee sublinear regret in such settings.</li> </ul> </li> </ul> <p>In the context of binary loss, where predictions are either correct or incorrect (0 or 1), deterministic algorithms like the Weighted Majority Algorithm (WMA) face a fundamental limitation. Regret, which measures how much worse the algorithm performs compared to the best expert in hindsight, ideally should grow sublinearly with the number of rounds (\(T\)). However, deterministic WMA cannot achieve this in adversarial environments. The fixed and predictable nature of deterministic strategies allows adversaries to exploit the algorithm, forcing it into repeated mistakes. As a result, the regret \(R_T\) grows at least linearly with \(T\), meaning the algorithm’s performance does not improve relative to the best expert over time. This inability to achieve sublinear regret (\(R_T = o(T)\)) under binary loss is a significant disadvantage of deterministic WMA, necessitating alternative approaches like randomization to overcome this limitation.</p> <p>[Still, Not clear of this limitation, How and Why?]</p> <p>In the following cases, the Weighted Majority Algorithm offers improved guarantees:</p> <ol> <li> <strong>Randomization Improves Regret Bounds</strong>: <ul> <li> <strong>Randomized versions</strong> of WMA (e.g., RWMA) can improve the regret bound by introducing randomness, which helps the algorithm avoid getting stuck with poor-performing experts.</li> </ul> </li> <li> <strong>Extensions for Convex Losses</strong>: <ul> <li>WMA can be adapted to handle <strong>convex loss functions</strong>, such as in regression tasks. In these cases, the algorithm provides improved theoretical guarantees, ensuring more reliable and efficient performance.</li> </ul> </li> </ol> <hr> <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>The Weighted Majority Algorithm offers an elegant and efficient approach to handling adversarial settings. By adaptively updating the weights of experts, it ensures robust performance with minimal assumptions.</p> <p>In the next post, we’ll dive into alternative versions of WMA and explore powerful algorithms designed for online learning. Stay tuned!</p> <h5 id="references"><strong>References</strong></h5> <ul> <li> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-exponential-weighted-average-algorithm",title:"Exponential Weighted Average Algorithm",description:"Delve into the Exponential Weighted Average Algorithm, its regret bounds, and the mathematical proof ensuring efficient loss minimization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/EWA/"}},{id:"post-bayesian-machine-learning-mathematical-foundations",title:"Bayesian Machine Learning - Mathematical Foundations",description:"A beginner-friendly guide to Bayesian statistics, explaining priors, likelihoods, posteriors, and real-world examples like coin-flipping to build a clear and intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Bayesian-ML/"}},{id:"post-understanding-the-weighted-majority-algorithm-in-online-learning",title:"Understanding the Weighted Majority Algorithm in Online Learning",description:"Explore how the Weighted Majority Algorithm achieves robust bounds for adversarial settings by adapting expert weights with every mistake.",section:"Posts",handler:()=>{window.location.href="/blog/2025/WMA/"}},{id:"post-online-learning-in-ml-a-beginner-s-guide-to-adaptive-learning",title:"Online Learning in ML - A Beginner\u2019s Guide to Adaptive Learning",description:"Learn how online learning transforms machine learning by handling dynamic, real-time data and adversarial scenarios. Explore its advantages, real-world applications, and key concepts like regret minimization and the Halving Algorithm in this beginner-friendly guide to adaptive AI.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Online-Learning/"}},{id:"post-multivariate-gaussian-distribution-and-naive-bayes",title:"Multivariate Gaussian Distribution and Naive Bayes",description:"Dive into the multivariate Gaussian distribution, its role in probabilistic modeling, and how it powers Naive Bayes classifiers with practical insights and mathematical intuition.",section:"Posts",handler:()=>{window.location.href="/blog/2025/Multivariate-GNB/"}},{id:"post-gaussian-naive-bayes-a-natural-extension",title:"Gaussian Naive Bayes - A Natural Extension",description:"Explore how Gaussian Naive Bayes adapts to continuous inputs, including parameter estimation, decision boundaries, and its relation to logistic regression.",section:"Posts",handler:()=>{window.location.href="/blog/2025/NB-continuous-features/"}},{id:"post-an-introduction-to-generative-models-naive-bayes-for-binary-features",title:"An Introduction to Generative Models - Naive Bayes for Binary Features",description:"Learn the fundamentals of Naive Bayes, from its conditional independence assumption to the maximum likelihood estimation (MLE) of parameters, using a binary feature example.",section:"Posts",handler:()=>{window.location.href="/blog/2025/generative-models/"}},{id:"post-generalized-linear-models-explained-leveraging-mle-for-regression-and-classification",title:"Generalized Linear Models Explained - Leveraging MLE for Regression and Classification",description:"Explore how Maximum Likelihood Estimation (MLE) forms the backbone of generalized linear models, enabling robust solutions for regression, classification, and beyond.",section:"Posts",handler:()=>{window.location.href="/blog/2025/MLE/"}},{id:"post-unveiling-probabilistic-modeling",title:"Unveiling Probabilistic Modeling",description:"Explore the fundamentals of probabilistic modeling and how it enhances our understanding of linear regression, from parameter estimation to error distribution.",section:"Posts",handler:()=>{window.location.href="/blog/2025/probabilistic-modeling/"}},{id:"post-svm-solution-in-the-span-of-the-data",title:"SVM Solution in the Span of the Data",description:"This blog explores how the span property simplifies optimization in SVM and ridge regression, introduces the Representer Theorem, and highlights the computational benefits of kernelization.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-solution-span-of-data/"}},{id:"post-understanding-the-kernel-trick",title:"Understanding the Kernel Trick",description:"A step-by-step exploration of kernel methods, unraveling their role in enabling powerful nonlinear modeling through the elegance of the kernel trick.",section:"Posts",handler:()=>{window.location.href="/blog/2025/kernel-trick/"}},{id:"post-unleashing-the-power-of-linear-models-tackling-nonlinearity-with-feature-maps",title:"Unleashing the Power of Linear Models - Tackling Nonlinearity with Feature Maps",description:"Explore how feature maps transform inputs, handle nonlinearities, and expand the expressiveness of linear models with practical examples and intuitive solutions.",section:"Posts",handler:()=>{window.location.href="/blog/2025/feature-maps/"}},{id:"post-demystifying-svms-understanding-complementary-slackness-and-support-vectors",title:"Demystifying SVMs - Understanding Complementary Slackness and Support Vectors",description:"A deep dive into the complementary slackness conditions in SVMs, exploring their connection to margins, support vectors, and kernelized optimization for powerful classification.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm-dual-problem/"}},{id:"post-the-dual-problem-of-svm",title:"The Dual Problem of SVM",description:"An in-depth exploration of the dual problem in SVMs, covering its mathematical foundation, Lagrangian formulation, duality principles, and complementary slackness for intuitive understanding.",section:"Posts",handler:()=>{window.location.href="/blog/2025/dual-problem/"}},{id:"post-subgradient-and-subgradient-descent",title:"Subgradient and Subgradient Descent",description:"An deep dive into subgradients, subgradient descent, and their application in optimizing non-differentiable functions like SVMs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/subgradient/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"news-spring-2025-semester-update",title:"Spring 2025 Semester Update",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>