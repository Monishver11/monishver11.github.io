<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="9O0EoPaLhgFjSIvAkDDoQK0gr49C2Wuxtgl3c0bXObM"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Gradient Descent Convergence - Prerequisites and Detailed Derivation | Monishver Chandrasekaran </title> <meta name="author" content="Monishver Chandrasekaran"> <meta name="description" content="Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%A5&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://monishver11.github.io/blog/2024/gd-convergence/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class=" "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Monishver</span> Chandrasekaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Gradient Descent Convergence - Prerequisites and Detailed Derivation</h1> <p class="post-meta"> Created in December 29, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   ·   <a href="/blog/category/sample-posts"> <i class="fa-solid fa-tag fa-sm"></i> sample-posts</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>To understand the <strong>Convergence Theorem for Fixed Step Size</strong>, it is essential to grasp a few foundational concepts like <strong>Lipschitz continuity</strong> and <strong>convexity</strong>. This section introduces these concepts and establishes the necessary prerequisites.</p> <p><strong>Quick note:</strong> If you find yourself struggling with any part or step, don’t worry—just copy and paste it into ChatGPT or Perplexity for an explanation. In most cases, you’ll be able to grasp the concept and move forward. If you’re still stuck, feel free to ask for help. The key is not to let small obstacles slow you down—keep going and seek assistance when needed!</p> <hr> <h4 id="lipschitz-continuity"><strong>Lipschitz Continuity?</strong></h4> <p>At its core, Lipschitz continuity imposes a <strong>limit on how fast a function can change</strong>. Mathematically, a function \(g : \mathbb{R}^d \to \mathbb{R}\) is said to be <strong>Lipschitz continuous</strong> if there exists a constant \(L &gt; 0\) such that:</p> \[\|g(x) - g(x')\| \leq L \|x - x'\|, \quad \forall x, x' \in \mathbb{R}^d.\] <p>This means the function’s rate of change is bounded by \(L\). For differentiable functions, Lipschitz continuity is often applied to the gradient. If \(\nabla f(x)\) is Lipschitz continuous with constant \(L &gt; 0\), then:</p> \[\|\nabla f(x) - \nabla f(x')\| \leq L \|x - x'\|, \quad \forall x, x' \in \mathbb{R}^d.\] <p>This ensures the gradient does not change too rapidly, which is crucial for the convergence of optimization algorithms like gradient descent.</p> <h6 id="intuition-behind-lipschitz-continuity"><strong>Intuition Behind Lipschitz Continuity</strong></h6> <ol> <li> <strong>Bounding the Slope</strong>: Lipschitz continuity ensures that the slope of the function (or the steepness of the graph) is bounded by \(L\). You can think of it as saying, “No part of the function can change too steeply.”</li> <li> <strong>Gradient Smoothness</strong>: For \(\nabla f(x)\), Lipschitz continuity means the gradient varies smoothly between nearby points. This avoids abrupt jumps or erratic behavior in the optimization landscape.</li> </ol> <h6 id="visual-way-to-think-about-it"><strong>Visual Way to Think About It</strong></h6> <p>Imagine walking along a path represented by the graph of \(f(x)\). Lipschitz continuity guarantees:</p> <ul> <li>No sudden steep hills or cliffs.</li> <li>A smooth path where the steepness (gradient) is capped.</li> </ul> <p>Alternatively, picture a <strong>rubber band stretched smoothly over some pegs</strong>. The tension in the rubber band ensures there are no sharp kinks, making the graph smooth and predictable.</p> <h6 id="examples-of-lipschitz-continuous-functions"><strong>Examples of Lipschitz Continuous Functions</strong></h6> <ol> <li> <strong>Linear Function</strong>: \(f(x) = mx + b\) is Lipschitz continuous because the slope \(m\) is constant, and \(|f'(x)| = |m|\) is bounded.</li> <li> <strong>Quadratic Function</strong>: \(f(x) = x^2\) is \(L\)-smooth with \(L = 2\). Its gradient \(f'(x) = 2x\) satisfies:</li> </ol> \[|f'(x) - f'(x')| = |2x - 2x'| = 2|x - x'|.\] <ol> <li> <strong>Non-Lipschitz Example</strong>: \(f(x) = \sqrt{x}\) (for \(x &gt; 0\)) is <strong>not Lipschitz continuous</strong> at \(x = 0\) because the slope becomes infinitely steep as \(x \to 0\). (If you’re not getting this, just plot \(\sqrt{x}\) function in <a href="https://www.desmos.com/" rel="external nofollow noopener" target="_blank">Desmos</a> and you’ll get it.)</li> </ol> <h6 id="why-does-lipschitz-continuity-matter"><strong>Why Does Lipschitz Continuity Matter?</strong></h6> <ol> <li> <strong>Predictability</strong>: Lipschitz continuity ensures that a function behaves predictably, without sudden spikes or erratic changes.</li> <li> <strong>Gradient Descent</strong>: If \(\nabla f(x)\) is Lipschitz continuous, we can choose a step size \(\eta \leq \frac{1}{L}\) to ensure gradient descent converges smoothly without overshooting the minimum.</li> </ol> <p>But Why? We’ll see that in the Convergence Theorem down below. For now, lets equip ourselves with the next important concept needed.</p> <hr> <h4 id="2-convex-functions-and-convexity-condition"><strong>2. Convex Functions and Convexity Condition</strong></h4> <p>A function \(f : \mathbb{R}^d \to \mathbb{R}\) is <strong>convex</strong> if for any \(x, x' \in \mathbb{R}^d\) and \(\alpha \in [0, 1]\):</p> \[f(\alpha x + (1 - \alpha)x') \leq \alpha f(x) + (1 - \alpha)f(x').\] <p>Intuitively, the line segment between any two points on the graph of \(f\) lies above the graph itself.</p> <h6 id="convexity-condition-using-gradients"><strong>Convexity Condition Using Gradients</strong></h6> <p>If \(f\) is differentiable, convexity is equivalent to the following condition:</p> \[f(x') \geq f(x) + \langle \nabla f(x), x' - x \rangle, \quad \forall x, x' \in \mathbb{R}^d.\] <p>This means that the function lies above its tangent plane at any point.</p> <hr> <h4 id="3-l-smoothness"><strong>3. \(L\)-Smoothness</strong></h4> <p>A function \(f\) is said to be \(L\)-smooth if its gradient is Lipschitz continuous. This implies the following inequality:</p> \[f(x') \leq f(x) + \langle \nabla f(x), x' - x \rangle + \frac{L}{2} \|x' - x\|^2.\] <p>This property bounds the change in the function value using the gradient and the distance between \(x\) and \(x'\).</p> <hr> <h4 id="4-optimality-conditions-for-convex-functions"><strong>4. Optimality Conditions for Convex Functions</strong></h4> <p>For convex functions, the following is true:</p> <ul> <li>If \(x^*\) is a minimizer of \(f\), then:</li> </ul> \[\nabla f(x^*) = 0.\] <ul> <li>For any \(x\), the difference between \(f(x)\) and \(f(x^*)\) can be bounded using the gradient:</li> </ul> \[f(x) - f(x^*) \leq \langle \nabla f(x), x - x^* \rangle.\] <p>These conditions help in deriving the convergence results for gradient descent.</p> <hr> <p><strong>To quickly summarize, before we proceed further:</strong></p> <ol> <li> <strong>Lipschitz continuity</strong> ensures the gradient does not change too rapidly.</li> <li> <strong>Convexity</strong> guarantees that the function behaves well, with no local minima other than the global minimum.</li> <li> <strong>\(L\)-smoothness</strong> combines convexity and Lipschitz continuity to bound the function’s behavior using gradients.</li> </ol> <hr> <p>With these concepts in place, we can now proceed to derive the <strong>Convergence Theorem for Fixed Step Size</strong>.</p> <h4 id="convergence-of-gradient-descent-with-fixed-step-size"><strong>Convergence of Gradient Descent with Fixed Step Size</strong></h4> <h5 id="theorem"><strong>Theorem:</strong></h5> <p>Suppose the function \(f : \mathbb{R}^n \to \mathbb{R}\) is convex and differentiable, and its gradient is Lipschitz continuous with constant \(L &gt; 0\), i.e.,</p> \[\|\nabla f(x) - \nabla f(y)\|_2 \leq L \|x - y\|_2 \quad \text{for any} \quad x, y.\] <p>Then, if we run gradient descent for \(k\) iterations with a fixed step size \(t \leq \frac{1}{L}\), the solution \(x^{(k)}\) satisfies:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{\|x^{(0)} - x^*\|_2^2}{2 t k},\] <p>where \(f(x^*)\) is the optimal value.</p> <h5 id="proof"><strong>Proof:</strong></h5> <h6 id="step-1-lipschitz-continuity-and-smoothness"><strong>Step 1: Lipschitz Continuity and Smoothness</strong></h6> <p>From the Lipschitz continuity of \(\nabla f\), the function \(f\) satisfies the following inequality for any \(x, y \in \mathbb{R}^n\):</p> \[f(y) \leq f(x) + \nabla f(x)^T (y - x) + \frac{L}{2} \|y - x\|_2^2.\] <p>This inequality allows us to bound how the function \(f\) changes as we move from \(x\) to \(y\), given the Lipschitz constant \(L\).</p> <h6 id="step-2-gradient-descent-update"><strong>Step 2: Gradient Descent Update</strong></h6> <p>The gradient descent update step is defined as:</p> \[x^{+} = x - t \nabla f(x),\] <p>where \(t\) is the step size. Letting \(y = x^+\) in the smoothness inequality gives:</p> \[f(x^+) \leq f(x) + \nabla f(x)^T (x^+ - x) + \frac{L}{2} \|x^+ - x\|_2^2.\] <h6 id="step-3-substituting-the-update-rule"><strong>Step 3: Substituting the Update Rule</strong></h6> <p>Substituting \(x^+ - x = -t \nabla f(x)\), we get:</p> \[f(x^+) \leq f(x) + \nabla f(x)^T (-t \nabla f(x)) + \frac{L}{2} \| -t \nabla f(x)\|_2^2.\] <p>Simplifying each term:</p> <ul> <li>The second term simplifies to:</li> </ul> \[\nabla f(x)^T (-t \nabla f(x)) = -t \|\nabla f(x)\|_2^2.\] <ul> <li>The third term simplifies to:</li> </ul> \[\frac{L}{2} \| -t \nabla f(x)\|_2^2 = \frac{L t^2}{2} \|\nabla f(x)\|_2^2.\] <p>Combining these, we have:</p> \[f(x^+) \leq f(x) - t \|\nabla f(x)\|_2^2 + \frac{L t^2}{2} \|\nabla f(x)\|_2^2.\] <p>Factoring out \(\|\nabla f(x)\|_2^2\):</p> \[f(x^+) \leq f(x) - \left( t - \frac{L t^2}{2} \right) \|\nabla f(x)\|_2^2.\] <h6 id="step-4-ensuring-decrease-in-fx"><strong>Step 4: Ensuring Decrease in \(f(x)\)</strong></h6> <p>To ensure that the function value decreases at each iteration, the coefficient \(t - \frac{L t^2}{2}\) must be non-negative. This holds when \(t \leq \frac{1}{L}\). Substituting \(t = \frac{1}{L}\), we verify:</p> \[t - \frac{L t^2}{2} = \frac{1}{L} - \frac{L}{2} \cdot \frac{1}{L^2} = \frac{1}{L} - \frac{1}{2L} = \frac{1}{2L}.\] <p>Thus, with \(t \leq \frac{1}{L}\), the function value strictly decreases:</p> \[f(x^+) \leq f(x) - \frac{t}{2} \|\nabla f(x)\|_2^2.\] <h6 id="step-5-bounding-fx---fx"><strong>Step 5: Bounding \(f(x^+) - f(x^*)\)</strong></h6> <p>From the convexity of \(f\), we know:</p> \[f(x^*) \geq f(x) + \nabla f(x)^T (x^* - x).\] <p>Rearranging: \(f(x) \leq f(x^*) + \nabla f(x)^T (x - x^*).\)</p> <p>Substituting this into the inequality for \(f(x^+)\):</p> \[f(x^+) \leq f(x^*) + \nabla f(x)^T (x - x^*) - \frac{t}{2} \|\nabla f(x)\|_2^2.\] <p>Rearranging terms:</p> \[f(x^+) - f(x^*) \leq \frac{1}{2t} \left( \|x - x^*\|_2^2 - \|x^+ - x^*\|_2^2 \right).\] <p>This shows how the objective value at \(x^+\) is related to the distance between \(x\) and the optimal solution \(x^*\).</p> <h6 id="step-6-summing-over-k-iterations"><strong>Step 6: Summing Over \(k\) Iterations</strong></h6> <p>Let \(x^{(i)}\) denote the iterate after \(i\) steps. Applying the inequality iteratively, we have:</p> \[f(x^{(i)}) - f(x^*) \leq \frac{1}{2t} \left( \|x^{(i-1)} - x^*\|_2^2 - \|x^{(i)} - x^*\|_2^2 \right).\] <p>Summing over \(i = 1, 2, \dots, k\):</p> \[\sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right) \leq \frac{1}{2t} \sum_{i=1}^k \left( \|x^{(i-1)} - x^*\|_2^2 - \|x^{(i)} - x^*\|_2^2 \right).\] <h6 id="step-7-telescoping-sum"><strong>Step 7: Telescoping Sum</strong></h6> <p>The terms on the right-hand side form a telescoping sum:</p> \[\sum_{i=1}^k \left( \|x^{(i-1)} - x^*\|_2^2 - \|x^{(i)} - x^*\|_2^2 \right) = \|x^{(0)} - x^*\|_2^2 - \|x^{(k)} - x^*\|_2^2.\] <p>Thus, we have:</p> \[\sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right) \leq \frac{1}{2t} \left( \|x^{(0)} - x^*\|_2^2 - \|x^{(k)} - x^*\|_2^2 \right).\] <p>Since \(f(x^{(i)})\) is decreasing with each iteration, the largest term dominates the average:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{1}{k} \sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right).\] <p>But, why is the above inequality right? Let’s find out:</p> <p>The inequality</p> \[f(x^{(k)}) - f(x^*) \leq \frac{1}{k} \sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right)\] <p>is derived based on the property that \(f(x^{(i)})\) is <strong>monotonically decreasing</strong> during gradient descent. Let’s break it down step by step.</p> <ul> <li> <strong>Key Property: Monotonic Decrease</strong>: In gradient descent, the function value decreases with each iteration due to the fixed step size \(t \leq \frac{1}{L}\). This means:</li> </ul> \[f(x^{(1)}) \geq f(x^{(2)}) \geq \cdots \geq f(x^{(k)}).\] <p>Thus, the latest value \(f(x^{(k)})\) is the smallest among all iterations.</p> <ul> <li> <strong>Averaging the Function Values</strong>: The sum of the differences \(f(x^{(i)}) - f(x^*)\) over all \(k\) iterations can be written as:</li> </ul> \[\frac{1}{k} \sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right),\] <p>which represents the average difference between the function values at each iteration and the optimal value \(f(x^*)\).</p> <ul> <li> <strong>Bounding the Smallest Term by the Average</strong>: Since \(f(x^{(k)})\) is the smallest value (due to monotonic decrease), it cannot exceed the average value. In mathematical terms:</li> </ul> \[f(x^{(k)}) - f(x^*) \leq \frac{1}{k} \sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right).\] <ul> <li> <p><strong>Intuition Behind the Inequality</strong>: This inequality reflects a simple fact: the smallest value in a decreasing sequence of numbers is less than or equal to their average. For example, if we have values \(10, 8, 7, 6\), the smallest value (6) will always be less than or equal to the average of these values.</p> </li> <li> <p><strong>Significance in Gradient Descent</strong>: This inequality is important because it allows us to bound the final iterate \(f(x^{(k)})\) using the sum of all previous iterations.</p> </li> </ul> <h6 id="step-8-final-substitution-to-derive-the-convergence-result"><strong>Step 8: Final Substitution to Derive the Convergence Result</strong></h6> <p>From the telescoping sum, we have:</p> \[\sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right) \leq \frac{1}{2t} \left( \|x^{(0)} - x^*\|_2^2 - \|x^{(k)} - x^*\|_2^2 \right).\] <p>Using the inequality:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{1}{k} \sum_{i=1}^k \left( f(x^{(i)}) - f(x^*) \right),\] <p>we substitute the bound on the sum into this expression:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{1}{k} \cdot \frac{1}{2t} \left( \|x^{(0)} - x^*\|_2^2 - \|x^{(k)} - x^*\|_2^2 \right).\] <p>Since \(\|x^{(k)} - x^*\|_2^2 \geq 0\), we drop this term to get the worst-case bound:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{\|x^{(0)} - x^*\|_2^2}{2tk}.\] <h5 id="conclusion"><strong>Conclusion</strong></h5> <p>We have derived the convergence guarantee for gradient descent with a fixed step size \(t \leq \frac{1}{L}\). The final result:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{\|x^{(0)} - x^*\|_2^2}{2 t k},\] <p>shows that the function value \(f(x^{(k)})\) decreases towards the optimal value \(f(x^*)\) at a rate proportional to \(O(1/k)\). This rate depends on the step size \(t\) and the initial distance \(\|x^{(0)} - x^*\|_2^2\).</p> <p>The result highlights that gradient descent converges reliably under the conditions of convexity, differentiability, and Lipschitz continuity of the gradient. As \(k \to \infty\), the function value approaches the optimal value, demonstrating the effectiveness of gradient descent for optimization problems with these properties.</p> <hr> <p>Next,</p> <ul> <li>Convergence of gradient descent with adaptive step size</li> <li>Strongly convex - “linear convergence” rate</li> </ul> <h4 id="convergence-of-gradient-descent-with-adaptive-step-size"><strong>Convergence of gradient descent with adaptive step size</strong></h4> <p>In the above section, we derived the convergence rate for gradient descent with a <strong>fixed step size</strong>. In this part, we extend this analysis to the case where the step size is chosen adaptively using a <strong>backtracking line search</strong>. This method ensures that the step size decreases as necessary to guarantee sufficient decrease in the objective function at each iteration.</p> <h6 id="step-1-setup-and-assumptions"><strong>Step 1: Setup and Assumptions</strong></h6> <p>Consider a differentiable convex function \(f: \mathbb{R}^n \to \mathbb{R}\) with a <strong>Lipschitz continuous gradient</strong>. That is, for any two points \(x, y \in \mathbb{R}^n\),</p> \[\|\nabla f(x) - \nabla f(y)\|_2 \leq L \|x - y\|_2,\] <p>where \(L\) is the <strong>Lipschitz constant</strong> of the gradient.</p> <p>Let \(x^*\) be the minimizer of \(f\), and let \(x^{(i)}\) represent the iterates of gradient descent. The update rule for gradient descent with backtracking line search is:</p> \[x^{(i+1)} = x^{(i)} - t_i \nabla f(x^{(i)}),\] <p>where \(t_i\) is the step size at iteration \(i\), chosen adaptively using the backtracking procedure.</p> <h6 id="step-2-descent-lemma"><strong>Step 2: Descent Lemma</strong></h6> <p>In the case of gradient descent with a <strong>fixed step size</strong> \(t\), we know from the <strong>descent lemma</strong> (for smooth convex functions) that:</p> \[f(x^{(i+1)}) \leq f(x^{(i)}) - t \|\nabla f(x^{(i)})\|_2^2 + \frac{L}{2} t^2 \|\nabla f(x^{(i)})\|_2^2.\] <p>This inequality states that at each iteration, the function value decreases by a term proportional to the gradient’s squared norm, and this decrease depends on the step size \(t\).</p> <h6 id="step-3-backtracking-line-search"><strong>Step 3: Backtracking Line Search</strong></h6> <p>With <strong>backtracking line search</strong>, the step size \(t_i\) is chosen at each iteration to ensure sufficient decrease in the function value. Specifically, the step size is selected such that:</p> \[f(x^{(i+1)}) \leq f(x^{(i)}) + \alpha t_i \nabla f(x^{(i)})^T \nabla f(x^{(i)}),\] <p>where \(0 &lt; \alpha &lt; 1\) is a constant. The backtracking line search ensures that \(t_i\) satisfies the condition:</p> \[t_i \leq \frac{1}{L}.\] <p>Thus, the step size at each iteration is bounded by \(\frac{1}{L}\), which prevents the gradient from changing too rapidly and ensures that the update does not overshoot the optimal point.</p> <p><strong>Why “Adaptive”?</strong></p> <p>The step size is called <strong>adaptive</strong> because it changes at each iteration depending on the function’s behavior. If the function is steep or the gradient is large, the backtracking line search may choose a smaller step size to avoid overshooting. If the function is shallow or the gradient is small, it might allow a larger step size. This adaptive process uses a parameter \(\beta\) to control how the step size is reduced when the decrease condition is not met.</p> <h6 id="step-4-backtracking-process-and-beta"><strong>Step 4: Backtracking Process and \(\beta\)</strong></h6> <p>The process of backtracking works as follows:</p> <ul> <li> <p><strong>Initial Step Size</strong>: Start with an initial guess for the step size, typically \(t_0 = 1\).</p> </li> <li> <p><strong>Condition Check</strong>: Check whether the condition</p> </li> </ul> \[f(x^{(i+1)}) \leq f(x^{(i)}) + \alpha t_i \nabla f(x^{(i)})^T \nabla f(x^{(i)})\] <p>holds. If it does, accept \(t_i\); if not, reduce the step size.</p> <ul> <li> <strong>Reduce Step Size</strong>: If the condition is not satisfied, reduce the step size \(t_i\) by a factor \(\beta\):</li> </ul> \[t_{i+1} = \beta t_i,\] <p>where \(\beta\) is a constant between 0 and 1 (usually around 0.5 or 0.8). This step size reduction continues until the condition is met.</p> <ul> <li> <strong>Accept the Step Size</strong>: Once the condition is satisfied, the current \(t_i\) is accepted for the update.</li> </ul> <p>The use of \(\beta\) helps to ensure that the step size does not become too large, allowing the algorithm to converge smoothly without overshooting.</p> <h6 id="step-5-bounding-the-convergence"><strong>Step 5: Bounding the Convergence</strong></h6> <p>Now, let’s derive the convergence bound for gradient descent with backtracking line search. From the descent lemma, the change in the function value at each iteration can be bounded as:</p> \[f(x^{(i+1)}) - f(x^{(i)}) \leq - t_i \|\nabla f(x^{(i)})\|_2^2 \left( 1 - \frac{L}{2} t_i \right).\] <p>Because the backtracking line search ensures that \(t_i \leq t_{\text{min}} = \min\left( 1, \frac{\beta}{L} \right)\), we can bound the function value decrease as:</p> \[f(x^{(i+1)}) - f(x^{(i)}) \leq - t_{\text{min}} \|\nabla f(x^{(i)})\|_2^2 \left( 1 - \frac{L}{2} t_{\text{min}} \right).\] <p>This shows that the function value decreases at each iteration, with the step size \(t_{\text{min}}\) controlling the rate of decrease.</p> <p>Now, if you observe carefully, the equation above closely resembles the one we encountered in the fixed step size proof. The only minor difference is that \(t\) has been replaced with \(t_{\text{min}}\). Therefore, we can follow the same steps as in the fixed step size case and eventually arrive at the following result:</p> \[f(x^{(k)}) - f(x^*) \leq \frac{\|x^{(0)} - x^*\|_2^2}{2 t_{\text{min}} k}.\] <p>This shows that by adaptively choosing the step size, we can achieve a convergence rate similar to that of the fixed step size approach, but without needing to manually set a fixed value for ( t ).</p> <p><strong>Quick Note:</strong> I’m still not completely satisfied with the proof for Adaptive Step Size. I’ll be working on refining the explanation further and will update you with any improvements.</p> <h5 id="and-finally"><strong>And finally…</strong></h5> <p>We’ve reached the end of this blog post! A huge kudos to you for making it all the way through and sticking with me. The reason we went through all of this is that understanding such proofs will lay the foundation for exploring the intricate details that drive machine learning and produce its remarkable results. To truly dive into ML research, we need to immerse ourselves in these depths and make it happen.</p> <p>So, take a well-deserved break, and in the next post, we’ll delve into the tips and tricks of SGD that are widely practiced in the industry. Until then, take care and see you soon!</p> <h5 id="references"><strong>References:</strong></h5> <ul> <li><a href="https://nyu-cs2565.github.io/mlcourse-public/2024-fall/lectures/lec02/gradient_descent_converge.pdf" rel="external nofollow noopener" target="_blank"> Gradient Descent: Convergence Analysis - Ryan Tibshirani</a></li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Monishver Chandrasekaran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1HD0LJE1KY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1HD0LJE1KY");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-support-vector-machines-svm-from-hinge-loss-to-optimization",title:"Support Vector Machines(SVM) - From Hinge Loss to Optimization",description:"Demystifying Support Vector Machines (SVM) - A step-by-step exploration of hinge loss, optimization, and gradient mechanics.",section:"Posts",handler:()=>{window.location.href="/blog/2025/svm/"}},{id:"post-understanding-the-maximum-margin-classifier",title:"Understanding the Maximum Margin Classifier",description:"An engaging walkthrough of maximum margin classifiers, exploring their foundations, geometric insights, and the transition to support vector machines.",section:"Posts",handler:()=>{window.location.href="/blog/2025/max-margin-classifier/"}},{id:"post-l1-and-l2-regularization-nuanced-details",title:"L1 and L2 Regularization - Nuanced Details",description:"A detailed explanation of L1 and L2 regularization, focusing on their theoretical insights, geometric interpretations, and practical implications for machine learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2025/l1-l2-reg-indepth/"}},{id:"post-regularization-balancing-model-complexity-and-overfitting",title:"Regularization - Balancing Model Complexity and Overfitting",description:"Discover how regularization controls model complexity, reduces overfitting, and enhances generalization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/regularization/"}},{id:"post-loss-functions-regression-and-classification",title:"Loss Functions - Regression and Classification",description:"Exploring regression and classification loss functions, with a deep dive into logistic regression and its role in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2025/loss-functions/"}},{id:"post-optimizing-stochastic-gradient-descent-key-recommendations-for-effective-training",title:"Optimizing Stochastic Gradient Descent - Key Recommendations for Effective Training",description:"A comprehensive collection of expert recommendations to enhance the performance and reliability of Stochastic Gradient Descent, ensuring smoother and faster convergence during training.",section:"Posts",handler:()=>{window.location.href="/blog/2025/sgd-tips/"}},{id:"post-gradient-descent-and-second-order-optimization-a-thorough-comparison",title:"Gradient Descent and Second-Order Optimization - A Thorough Comparison",description:"An in-depth exploration of Gradient Descent (GD) and Second-Order Gradient Descent (2GD), focusing on convergence behavior, mathematical derivations, and performance differences.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-tips/"}},{id:"post-gradient-descent-convergence-prerequisites-and-detailed-derivation",title:"Gradient Descent Convergence - Prerequisites and Detailed Derivation",description:"Understanding the convergence of gradient descent with a fixed step size and proving its rate of convergence for convex, differentiable functions.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gd-convergence/"}},{id:"post-understanding-stochastic-gradient-descent-sgd",title:"Understanding Stochastic Gradient Descent (SGD)",description:"A detailed guide to gradient descent variants, highlighting the mechanics, trade-offs, and practical insights of Stochastic Gradient Descent (SGD).",section:"Posts",handler:()=>{window.location.href="/blog/2024/SGD/"}},{id:"post-gradient-descent-a-detailed-walkthrough",title:"Gradient Descent - A Detailed Walkthrough",description:"An in-depth exploration of gradient descent, including its convergence and step size considerations.",section:"Posts",handler:()=>{window.location.href="/blog/2024/gradient-descent/"}},{id:"post-empirical-risk-minimization-erm",title:"Empirical Risk Minimization (ERM)",description:"Exploring Empirical Risk Minimization - Balancing approximation, estimation, and optimization errors to build effective supervised learning models.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ERM/"}},{id:"post-understanding-the-supervised-learning-setup",title:"Understanding the Supervised Learning Setup",description:"An in-depth exploration of the supervised learning setup, covering key concepts like prediction functions, loss functions, risk evaluation, and the Bayes optimal predictor.",section:"Posts",handler:()=>{window.location.href="/blog/2024/supervised-learning/"}},{id:"post-timeline-of-machine-learning-history",title:"Timeline of Machine Learning History",description:"A concise timeline of machine learning&#39;s history, showcasing key milestones and breakthroughs that shaped the field.",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-history/"}},{id:"post-advanced-probability-concepts-for-machine-learning",title:"Advanced Probability Concepts for Machine Learning",description:"This blog explores key probability theory concepts, from distributions and Bayes&#39; Theorem to covariance and the Central Limit Theorem, emphasizing their critical application in machine learning and statistical modeling.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-2/"}},{id:"post-understanding-the-basics-of-probability-theory-for-machine-learning",title:"Understanding the Basics of Probability Theory for Machine Learning",description:"This blog explores essential probability concepts and their significance in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/probability-1/"}},{id:"post-linear-algebra-prerequisites-for-machine-learning",title:"Linear Algebra - Prerequisites for Machine Learning",description:"This blog post covers the key linear algebra concepts and their applications in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/linear-algebra/"}},{id:"post-multivariate-calculus-prerequisites-for-machine-learning",title:"Multivariate Calculus - Prerequisites for Machine Learning",description:"This blog post explores key multivariate calculus concepts essential for understanding optimization in machine learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate-calculus/"}},{id:"post-introduction-to-machine-learning-ml",title:"Introduction to Machine Learning(ML)",description:"An easy guide to machine learning, its applications, and how it connects to AI and human learning.",section:"Posts",handler:()=>{window.location.href="/blog/2024/intro-to-ml/"}},{id:"post-preface-amp-introduction",title:"Preface &amp; Introduction",description:"First blog post\u2014setting the stage for the journey ahead.",section:"Posts",handler:()=>{window.location.href="/blog/2024/preface-ml/"}},{id:"projects-mta-transit-time-prediction",title:"MTA Transit Time Prediction",description:"Leveraging real-time data and machine learning to predict bus arrival times in New York City with route-based and grid-based approaches.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6D%6F%6E%69%73%68%76%65%72%63%68%61%6E%64%72%61%73%65%6B%61%72%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Monishver11","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/monishver","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>